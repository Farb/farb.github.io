[{"content":"2025读书清单 我这一辈子 ——老舍 C#并发编程经典实例2015 ——Stephen Cleary 四世同堂 ——老舍 茶馆 ——老舍 ","date":"2025-12-18T00:00:00Z","permalink":"https://farb.github.io/p/books_read/","title":"读书清单"},{"content":"1. 字符串统计题 某外企一面编码题目。\nGiven two strings s and t, return true if t is an anagram of s, and false otherwise. An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once.\nExample 1: Input: s = \u0026ldquo;anagram\u0026rdquo;, t = \u0026ldquo;nagaram\u0026rdquo; Output: true\nExample 2: Input: s = \u0026ldquo;rat\u0026rdquo;, t = \u0026ldquo;car\u0026rdquo; Output: false\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 internal class Program { private static void Main(string[] args) { Console.WriteLine(IsAnag(\u0026#34;anagram\u0026#34;, \u0026#34;nagaram\u0026#34;)); Console.WriteLine(IsAnag(\u0026#34;rat\u0026#34;, \u0026#34;car\u0026#34;)); } private static bool IsAnag(string s1, string s2) { var dict1= GetAnagDict(s1); var dict2= GetAnagDict(s2); foreach (var entry in dict1) { bool isMatch = dict2.ContainsKey(entry.Key) \u0026amp;\u0026amp; dict2[entry.Key] == entry.Value; if (!isMatch) { return false; } } return true; } private static Dictionary\u0026lt;char, int\u0026gt; GetAnagDict(string s1) { Dictionary\u0026lt;char, int\u0026gt; dict = new(); for (int i = 0; i \u0026lt; s1.Length; i++) { if (dict.ContainsKey(s1[i])) { dict[s1[i]]++; } else { dict.Add(s1[i], 1); } } return dict; } } 2. 杨辉三角问题 题目描述： 杨辉三角是我国古代一个重要的数学成就 。\n如上图，杨辉三角是一个满足以下条件的几何排列：\n1、每个数等于它上方两数之和。 2、每行数字左右对称，由1开始逐渐变大。 第 n 行的数字有 n 项。\n请编写一个程序，按题目要求输出杨辉三角中第 n 行第 m 个数字。\n输入\n第一行，两个数字 n 和 m ，表示需要输出的数字在杨辉三角上的位置，行列均从 1 开始，（1\u0026lt;=n,m\u0026lt;=10000），以空格分隔。\n输出\n仅包含一个整数，即杨辉三角中第 n 行第 m 列处的数字。\n输入示例 7 5\n输出示例 15\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 using YangHuiTriangleDemo; /// \u0026lt;summary\u0026gt; /// 题目5：杨辉三角 /// \u0026lt;/summary\u0026gt; internal class Program { private static void Main(string[] args) { string tips = \u0026#34;\u0026#34;\u0026#34; Please input 2 integers to get the result of YangHui triangle. The 2 integers represents the row number and column number seperately. For example, if you input 3 2, the result will be 2. The range of row number is 1 to 10000, and the range of column number is 1 to 10000. Press Ctrl+C to exit. \u0026#34;\u0026#34;\u0026#34;; Console.WriteLine(tips); Console.WriteLine(); YangHuiTriangle yangHuiTriangle = new YangHuiTriangle(); while (true) { Console.WriteLine(\u0026#34;Please input 2 integers:\u0026#34;); string input = Console.ReadLine(); if (input == null) { break; } (bool isOk,int row, int column) = ParseRowColumn(input); if (!isOk) { Console.WriteLine(\u0026#34;Only 2 integers is allowed and they are seperated with one blank space.\u0026#34;); continue; } if (row\u0026gt;10000|| column\u0026gt;10000) { Console.WriteLine(\u0026#34;The range of row number is 1 to 10000, and the range of column number is 1 to 10000.\u0026#34;); continue; } int result = yangHuiTriangle.GetNumber(row, column); Console.WriteLine(result); } } private static (bool isOk,int row, int column) ParseRowColumn(string input) { string[] inputArray = input.Split(\u0026#39; \u0026#39;); if (inputArray.Length!=2) { return (false,default,default); } bool isRowOk = int.TryParse(inputArray[0],out int row); bool isColumnOk = int.TryParse(inputArray[1],out int column); return (isRowOk \u0026amp;\u0026amp; isColumnOk,row,column); } } namespace YangHuiTriangleDemo; public class YangHuiTriangle { // 当前内存中杨辉三角数组的最大行数 private int _maxNumRows; private int[,] _arr; public int GetNumber(int row, int col) { GenerateYanghuiTriangle(row); return _arr[row - 1, col - 1]; } /// \u0026lt;summary\u0026gt; /// 生成杨辉三角 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;numRows\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private void GenerateYanghuiTriangle(int numRows) { // 如果当前内存中已经存储了足够的杨辉三角行数，直接返回 if (numRows \u0026lt;= _maxNumRows) { return; } // 创建二维数组来存储杨辉三角形 int[,] arr = new int[numRows, numRows]; // 扩容数组，补充还没生成的杨辉三角部分 if (_maxNumRows \u0026gt; 0) { CopyJaggedArray(_arr, arr); } // 按照杨辉三角形的规律填充数组元素 for (int i = _maxNumRows; i \u0026lt; numRows; i++) { for (int j = 0; j \u0026lt;= i; j++) { if (j == 0 || j == i) { arr[i, j] = 1; } else { arr[i, j] = arr[i - 1, j - 1] + arr[i - 1, j]; } } } _maxNumRows = numRows; _arr = arr; } /// \u0026lt;summary\u0026gt; /// 拷贝交错数组 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;oldArr\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;newArr\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private void CopyJaggedArray(int[,] oldArr, int[,] newArr) { for (int i = 0; i \u0026lt; oldArr.GetLength(0); i++) { for (int j = 0; j \u0026lt; oldArr.GetLength(1); j++) { newArr[i, j] = oldArr[i, j]; } } } } 3. 数据可视化 编程语言：不限\n题目描述：有句话是这么说的：“文不如表，表不如图”。形象地描述了图表在传达信息时，给接收者带来的截然不同的效率和体验。因此，在计算机计算能力、数据规模和决策需求都不断提升的当下，数据可视化的应用也越来越普遍。\n数据可视化的范围很广，涉及到数据的获取、加工、建模、图形学，人机交互等很多概念和领域，想更快上手，获得更好的体验，使用DragonFly BI这样的专业工具和服务是更明智的选择。\n今天，我们通过一个简化的命题，来亲手实现简单的数据可视化。编写一个程序，对于给定的一组数据和要求，输出一个以字符组成的柱状图。\n输入\n第一行，一个整数 N（1 \u0026lt;=n\u0026lt;=20），表示这组数据的条目数。 第二行，两个字符串，用于表示数据展示在柱状图上的排序方式。第一个字符串是“Name” 或者 “Value”，表示排序的依据是数据条目的名称亦或数值；第二个字符串是 “ASC” 或者 “DESC”，表示升序或降序。 随后的 N 行，每行包含一个字符串 S 和一个数字 V，以空格分隔，表示一条数据。S 即数据条目的名称，仅包含小写字母，V 即对应的数值，是一个整数，(0\u0026lt;=V\u0026lt;=1,000,000)\u0026lt; /P\u0026gt;\n输出\n图表外框转角符号：\n“┌”（\\u250c） “┐”（\\u2510） “└”（\\u2514） “┘”（\\u2518） 图表中的横、竖线：\n“─”（\\u2500） “│”（\\u2502） 图表中的各种交叉线：\n“├”（\\u251c） “┤”（\\u2524） “┬”（\\u252c） “┴”（\\u2534） “┼”（\\u253c） 用来拼柱子的字符：\n“█”（\\u2588） 图表中的空格：\n“ ”（\\u0020） 图表中名称区域的宽度，由这组数据中名称的最大长度决定，所有名称向右对齐， 图表中柱的最大长度为 20，每个柱的长度由该柱对应数据和这组数据中最大值（此值一定大于 0）的比值与 20 相乘获得，不足一格的部分舍去。\n输入示例\n3 Value DESC apple 5 pen 3 pineapple 10\n输出示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 namespace DataVisualizationDemo; /// \u0026lt;summary\u0026gt; /// 题目2：数据可视化 /// \u0026lt;/summary\u0026gt; internal class Program { static void Main(string[] args) { DataProcessor processor = new(); while (true) { Console.WriteLine(\u0026#34;Please input your data:\u0026#34;); IList\u0026lt;Product\u0026gt; products = processor.Parse(); products=processor.ProcessData(products); processor.PrintData(products); } } } namespace DataVisualizationDemo; public class Product { public string Name { get; set; } public int Value { get; set; } } using System.Text; namespace DataVisualizationDemo; internal class DataProcessor { private string orderField; private bool isAsc; public IList\u0026lt;Product\u0026gt; Parse() { if (!int.TryParse(Console.ReadLine(), out int lineCount)) { return new List\u0026lt;Product\u0026gt;(); } string sortDesc = Console.ReadLine(); string[] arr = sortDesc.Split(\u0026#34; \u0026#34;); orderField = arr[0]; isAsc = arr[1].Equals(\u0026#34;ASC\u0026#34;, StringComparison.CurrentCultureIgnoreCase); IList\u0026lt;Product\u0026gt; products = new List\u0026lt;Product\u0026gt;(); for (int i = 0; i \u0026lt; lineCount; i++) { string line = Console.ReadLine(); string[] lineArray = line.Split(\u0026#34; \u0026#34;); if (lineArray.Length != 2) { continue; } string name = lineArray[0]; int value = int.Parse(lineArray[1]); products.Add(new Product { Name = name, Value = value }); } return products; } public IList\u0026lt;Product\u0026gt; ProcessData(IList\u0026lt;Product\u0026gt; products) { if (\u0026#34;name\u0026#34;.Equals(orderField, StringComparison.CurrentCultureIgnoreCase)) { products = isAsc ? products.OrderBy(p =\u0026gt; p.Name).ToList() : products.OrderByDescending(p =\u0026gt; p.Name).ToList(); } else { products = isAsc ? products.OrderBy(p =\u0026gt; p.Value).ToList() : products.OrderByDescending(p =\u0026gt; p.Value).ToList(); } return products; } public void PrintData(IList\u0026lt;Product\u0026gt; products) { int maxNameLength = products.Max(p =\u0026gt; p.Name.Length); int maxValueLength = products.Max(p =\u0026gt; p.Value); int maxValueThreshold = Console.WindowWidth - maxNameLength - 4; PrintHeader(maxNameLength, maxValueLength, maxValueThreshold); StringBuilder sb = new(); for (int i = 0; i \u0026lt; products.Count; i++) { PrintDataLine(products[i], maxNameLength, maxValueLength, sb, maxValueThreshold); if (i == products.Count - 1) { PrintFooter(maxNameLength, maxValueLength, maxValueThreshold); break; } Console.Write(\u0026#34;├\u0026#34;); PrintNameRowSpliter(maxNameLength); Console.Write(\u0026#34;┼\u0026#34;); PrintValueRowSpliter(maxValueLength, maxValueThreshold); Console.WriteLine(\u0026#34;┤\u0026#34;); } } private void PrintDataLine(Product product, int maxNameLength, int maxValueLength, StringBuilder sb, int maxValueThreshold) { int actualWidth = maxValueLength \u0026lt; maxValueThreshold ? maxValueLength : maxValueThreshold; List\u0026lt;string\u0026gt; formatedValue = GenerateFormatedValue(sb, product.Value, maxValueThreshold); for (int i = 0; i \u0026lt; formatedValue.Count; i++) { if (i == 0) { Console.WriteLine($\u0026#34;│{product.Name.PadLeft(maxNameLength)}│{formatedValue[i].PadRight(actualWidth)}│\u0026#34;); continue; } else { Console.WriteLine($\u0026#34;│{string.Empty.PadLeft(maxNameLength)}│{formatedValue[i].PadRight(actualWidth)}│\u0026#34;); } } } /// \u0026lt;summary\u0026gt; /// 生成格式化的值字符串 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sb\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;productValue\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;maxValueThreshold\u0026#34;\u0026gt;值的一行最大的字符数\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private List\u0026lt;string\u0026gt; GenerateFormatedValue(StringBuilder sb, int productValue, int maxValueThreshold) { sb.Clear(); // 当value很大时，需要换行，所以需要计算行数 int valueLineCount = (int)Math.Ceiling(productValue * 1.0d / maxValueThreshold); List\u0026lt;string\u0026gt; result = new List\u0026lt;string\u0026gt;(valueLineCount); int actualWidth = productValue \u0026lt; maxValueThreshold ? productValue : maxValueThreshold; for (int i = 0; i \u0026lt; productValue; i++) { sb.Append(\u0026#34;█\u0026#34;); if (sb.Length == maxValueThreshold) { result.Add(sb.ToString()); sb.Clear(); } } if (sb.Length \u0026gt; 0) { // 拼上最后一行 result.Add(sb.ToString()); } return result; } private static void PrintHeader(int maxNameLength, int maxValueLength, int maxValueThreshold) { Console.Write(\u0026#34;┌\u0026#34;); PrintNameRowSpliter(maxNameLength); Console.Write(\u0026#34;┬\u0026#34;); PrintValueRowSpliter(maxValueLength, maxValueThreshold); Console.WriteLine(\u0026#34;┐\u0026#34;); } private static void PrintFooter(int maxNameLength, int maxValueLength, int maxValueThreshold) { Console.Write(\u0026#34;└\u0026#34;); PrintNameRowSpliter(maxNameLength); Console.Write(\u0026#34;┴\u0026#34;); PrintValueRowSpliter(maxValueLength, maxValueThreshold); Console.WriteLine(\u0026#34;┘\u0026#34;); } private static void PrintValueRowSpliter(int maxValueLength, int maxValueThreshold) { int actualWidth = maxValueLength \u0026lt; maxValueThreshold ? maxValueLength : maxValueThreshold; for (int i = 0; i \u0026lt; actualWidth; i++) { Console.Write(\u0026#34;─\u0026#34;); } } private static void PrintNameRowSpliter(int maxNameLength) { for (int i = 0; i \u0026lt; maxNameLength; i++) { Console.Write(\u0026#34;─\u0026#34;); } } } ","date":"2024-12-24T00:00:00Z","permalink":"https://farb.github.io/p/c%23_interview/","title":"C#面试题"},{"content":"安装步骤 先安装elasticsearch，作为skywalking的存储 再安装oap-server，作为skywalking的服务端 最后安装ui，作为skywalking的前端 涉及三个镜像服务，使用dockercompose来部署比较方便。\n创建dockercompose文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 services: elasticsearch: # image: docker.elastic.co/elasticsearch/elasticsearch-oss:${ES_VERSION} image: elasticsearch:7.9.0 container_name: elasticsearch # --restart=always ： 开机启动，失败也会一直重启； # --restart=on-failure:10 ： 表示最多重启10次 restart: always ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; healthcheck: test: [ \u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl --silent --fail localhost:9200/_cluster/health || exit 1\u0026#34; ] interval: 30s timeout: 10s retries: 3 start_period: 10s environment: - discovery.type=single-node # 锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高； - bootstrap.memory_lock=true # 设置时区 - TZ=Asia/Shanghai # - \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; ulimits: memlock: soft: -1 hard: -1 oap: image: apache/skywalking-oap-server:8.9.1 container_name: oap restart: always # 设置依赖的容器 depends_on: elasticsearch: condition: service_healthy # 关联ES的容器，通过容器名字来找到相应容器，解决IP变动问题 links: - elasticsearch # 端口映射 ports: - \u0026#34;11800:11800\u0026#34; - \u0026#34;12800:12800\u0026#34; # 监控检查 healthcheck: test: [ \u0026#34;CMD-SHELL\u0026#34;, \u0026#34;/skywalking/bin/swctl ch\u0026#34; ] # 每间隔30秒执行一次 interval: 30s # 健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败； timeout: 10s # 当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 retries: 3 # 应用的启动的初始化时间，在启动过程中的健康检查失效不会计入，默认 0 秒。 start_period: 10s environment: # 指定存储方式 SW_STORAGE: elasticsearch # 指定存储的地址 SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 SW_HEALTH_CHECKER: default SW_TELEMETRY: prometheus TZ: Asia/Shanghai # JAVA_OPTS: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; ui: image: apache/skywalking-ui:8.9.1 container_name: skywalking-ui restart: always depends_on: oap: condition: service_healthy links: - oap ports: - \u0026#34;8088:8080\u0026#34; environment: SW_OAP_ADDRESS: http://oap:12800 TZ: Asia/Shanghai 执行dockercompose 执行成功后，可以看到如下输出：\n1 2 3 4 5 6 7 # 如果文件名是标准的docker-compose.yml，直接执行docker-compose up -d即可 PS C:\\Users\\farbg\\Desktop\u0026gt; docker-compose -f .\\skywalking_docker-compose2.yml up -d [+] Running 4/4 ✔ Network desktop_default Created 0.0s ✔ Container elasticsearch Healthy 30.9s ✔ Container oap Healthy 61.7s ✔ Container skywalking-ui Started 验证容器是否启动成功 访问 http://localhost:8088/ ，可以看到skywalking管理界面。\n安装及配置探针 agent 下载地址： https://skywalking.apache.org/downloads/#Agents\nidea中在对应的服务配置jvm参数如下：\n1 2 3 -javaagent:D:\\ArchitectPracticer\\MicroServiceTools\\apache-skywalking-java-agent-9.3.0\\skywalking-agent\\skywalking-agent.jar -Dskywalking.agent.service_name=FirstServiceDemo -Dskywalking.collector.backend_service=127.0.0.1:11800 -javaagent:D:\\ArchitectPracticer\\MicroServiceTools\\apache-skywalking-java-agent-9.3.0\\skywalking-agent\\skywalking-agent.jar：指定Skywalking代理（Java探针）的路径，它负责收集应用程序的性能指标和调用链路数据。 -Dskywalking.agent.service_name=FirstServiceDemo：设置当前Java应用在Skywalking中的服务名称为“FirstServiceDemo”，便于在监控界面中识别和区分不同服务。 -Dskywalking.collector.backend_service=127.0.0.1:11800：配置Skywalking后端Collector服务地址和端口，该Java应用通过此地址将收集到的数据上报至Skywalking OAP Server进行分析和存储。这里设置的是本地回环地址（localhost），端口号为11800。\n测试接口 简单写了一个接口，查询一个用户信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @RestController public class TestController { private final IUserAccountService userAccountService; public TestController(IUserAccountService userAccountService) { this.userAccountService = userAccountService; } @GetMapping(\u0026#34;/test\u0026#34;) public String test() { return test2(); } @GetMapping(\u0026#34;/test2\u0026#34;) public String test2() { return this.userAccountService.getById(1).toString(); } } 可以在 追踪菜单中查看到调用链路 点击某个链路，还能看到具体的详情，比如可以看到查询的sql 还可以查看拓扑图 参考文章 https://blog.51cto.com/u_16213348/12680103 https://blog.csdn.net/qq_31762741/article/details/136778188 https://blog.csdn.net/Li_WenZhang/article/details/140992333 ","date":"2024-12-20T00:00:00Z","permalink":"https://farb.github.io/p/skywalking_docker_installation/","title":"基于Docker安装SkyWalking"},{"content":"1. SkyWalking启动报错 Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: elasticsearch/localhost:9200 skywalking源码地址：https://github.com/apache/skywalking\n经调查，发现是skywalking和elasticsearch的版本不匹配，需要修改skywalking的版本，或者修改elasticsearch的版本。\nelasticsearch只是skywalking的一种存储方式，所以，skywalking需要适配es。所以不是每个版本的skywalking和es都能正常工作。\n报错的docker_compose.yml为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 services: elasticsearch: # image: docker.elastic.co/elasticsearch/elasticsearch-oss:${ES_VERSION} image: elasticsearch:8.16.1 container_name: elasticsearch # --restart=always ： 开机启动，失败也会一直重启； # --restart=on-failure:10 ： 表示最多重启10次 restart: always ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; healthcheck: test: [ \u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl --silent --fail localhost:9200/_cluster/health || exit 1\u0026#34; ] interval: 30s timeout: 10s retries: 3 start_period: 10s environment: - discovery.type=single-node # 锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高； - bootstrap.memory_lock=true # 设置时区 - TZ=Asia/Shanghai # - \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; ulimits: memlock: soft: -1 hard: -1 oap: image: apache/skywalking-oap-server:10.1.0 container_name: oap restart: always # 设置依赖的容器 depends_on: elasticsearch: condition: service_healthy # 关联ES的容器，通过容器名字来找到相应容器，解决IP变动问题 links: - elasticsearch # 端口映射 ports: - \u0026#34;11800:11800\u0026#34; - \u0026#34;12800:12800\u0026#34; # 监控检查 healthcheck: test: [ \u0026#34;CMD-SHELL\u0026#34;, \u0026#34;/skywalking/bin/swctl ch\u0026#34; ] # 每间隔30秒执行一次 interval: 30s # 健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败； timeout: 10s # 当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 retries: 3 # 应用的启动的初始化时间，在启动过程中的健康检查失效不会计入，默认 0 秒。 start_period: 10s environment: # 指定存储方式 SW_STORAGE: elasticsearch # 指定存储的地址 SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 SW_HEALTH_CHECKER: default SW_TELEMETRY: prometheus TZ: Asia/Shanghai # JAVA_OPTS: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; ui: image: apache/skywalking-ui:10.1.0 container_name: skywalking-ui restart: always depends_on: oap: condition: service_healthy links: - oap ports: - \u0026#34;8088:8080\u0026#34; environment: SW_OAP_ADDRESS: http://oap:12800 TZ: Asia/Shanghai 可以正常工作的docker_compose.yml为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 services: elasticsearch: # image: docker.elastic.co/elasticsearch/elasticsearch-oss:${ES_VERSION} image: elasticsearch:7.9.0 container_name: elasticsearch # --restart=always ： 开机启动，失败也会一直重启； # --restart=on-failure:10 ： 表示最多重启10次 restart: always ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; healthcheck: test: [ \u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl --silent --fail localhost:9200/_cluster/health || exit 1\u0026#34; ] interval: 30s timeout: 10s retries: 3 start_period: 10s environment: - discovery.type=single-node # 锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高； - bootstrap.memory_lock=true # 设置时区 - TZ=Asia/Shanghai # - \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; ulimits: memlock: soft: -1 hard: -1 oap: image: apache/skywalking-oap-server:8.9.1 container_name: oap restart: always # 设置依赖的容器 depends_on: elasticsearch: condition: service_healthy # 关联ES的容器，通过容器名字来找到相应容器，解决IP变动问题 links: - elasticsearch # 端口映射 ports: - \u0026#34;11800:11800\u0026#34; - \u0026#34;12800:12800\u0026#34; # 监控检查 healthcheck: test: [ \u0026#34;CMD-SHELL\u0026#34;, \u0026#34;/skywalking/bin/swctl ch\u0026#34; ] # 每间隔30秒执行一次 interval: 30s # 健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败； timeout: 10s # 当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 retries: 3 # 应用的启动的初始化时间，在启动过程中的健康检查失效不会计入，默认 0 秒。 start_period: 10s environment: # 指定存储方式 SW_STORAGE: elasticsearch # 指定存储的地址 SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 SW_HEALTH_CHECKER: default SW_TELEMETRY: prometheus TZ: Asia/Shanghai # JAVA_OPTS: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; ui: image: apache/skywalking-ui:8.9.1 container_name: skywalking-ui restart: always depends_on: oap: condition: service_healthy links: - oap ports: - \u0026#34;8088:8080\u0026#34; environment: SW_OAP_ADDRESS: http://oap:12800 TZ: Asia/Shanghai 执行成功后，可以看到如下输出：\n1 2 3 4 5 6 PS C:\\Users\\farbg\\Desktop\u0026gt; docker-compose -f .\\skywalking_docker-compose2.yml up -d [+] Running 4/4 ✔ Network desktop_default Created 0.0s ✔ Container elasticsearch Healthy 30.9s ✔ Container oap Healthy 61.7s ✔ Container skywalking-ui Started ","date":"2024-12-19T00:00:00Z","permalink":"https://farb.github.io/p/skywalking_error_notes/","title":"SkyWalking 报错记录集"},{"content":"安装步骤 创建网络 1 2 3 # 因为需要部署kibana容器，因此需要让es和kibana容器互联。 PS C:\\Users\\farbg\u0026gt; docker network create es-net 800d4c36198d27f6a96d08e27f7b7f08123e25eb2c3ec354ab9f03b629975248 拉取镜像 1 2 # 注意：这里必须指定一个存在的版本号，否则可能会报一些奇怪的错。 docker pull elasticsearch:8.16.1 启动容器 1 2 3 4 PS C:\\Users\\farbg\u0026gt; docker run -itd --restart=always --name es --network es-net -p 9200:9200 -p 9300:9300 --privileged -v D:\\ArchitectPracticer\\ElasticSearch/data:/usr/share/elasticsearch/data -v D:\\ArchitectPracticer\\ElasticSearch/plugins:/usr/share/elasticsearch/plugins -e \u0026#34;discovery.type=single-node\u0026#34; -e \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; -e xpack.security.enabled=false elasticsearch:8.16.1 cebcc742cb1e857cec7ac96e0d58e7d7fe95a223b10713a811dcd96c3ff4fa06 命令各参数含义分析\ndocker run -itd： -i 表示以交互模式运行容器，让容器的标准输入保持打开状态；-t 则是分配一个伪终端，通常二者配合使用可以方便进入容器内部进行交互操作。-d 是让容器在后台运行（\u0026ndash;detach 的缩写），这样容器启动后不会占据当前终端，而是在后台默默运行，并且返回容器的 ID。 \u0026ndash;restart=always： 设置容器的重启策略为始终重启。意味着无论容器因为何种原因退出（比如意外崩溃、手动停止等），Docker 都会自动重新启动该容器，有助于保证 Elasticsearch 服务的持续可用性，这对于生产环境或需要长时间稳定运行的场景很重要。 \u0026ndash;name es： 给创建的容器指定一个名称为 “es”，后续对该容器进行操作（如查看状态、停止、启动、进入等）时，可以直接使用这个名称来指代容器，相较于使用容器 ID 更加方便易记。 \u0026ndash;network es-net： 将容器连接到名为 “es-net” 的网络中。如果这个网络不存在，Docker 会自动创建它。自定义网络方便容器之间进行通信，并且可以更灵活地配置网络相关的规则和参数，例如在构建 Elasticsearch 集群等场景下，多个相关容器可通过此网络相互交互。 -p 9200:9200 -p 9300:9300： 这是端口映射的设置，-p （\u0026ndash;publish 的缩写）。前面的数字代表主机（即运行 Docker 的物理机或虚拟机）上的端口，后面的数字代表容器内部的端口。所以 9200:9200 表示将容器内 Elasticsearch 用于 HTTP 通信的 9200 端口映射到主机的 9200 端口，方便外部客户端通过主机的 9200 端口访问容器内的 Elasticsearch 服务；9300:9300 则是把容器内用于节点间通信的 9300 端口映射到主机的 9300 端口，在集群模式下节点间通过这个端口进行交互，即便这里配置的是单节点模式，该端口映射也是必要的。 \u0026ndash;privileged： 赋予容器特权模式，使得容器内的进程拥有和主机 root 用户几乎相同的权限。不过使用这个选项要谨慎，因为它会带来一定的安全风险，一般在需要容器访问主机某些底层设备或执行特殊系统调用等情况下才使用，比如 Elasticsearch 可能需要更高权限来进行一些诸如内存映射等底层操作时可能会用到。 -v D:\\ArchitectPracticer\\ElasticSearch/data:/usr/share/elasticsearch/data： 这是数据卷挂载的配置，-v （\u0026ndash;volume 的缩写）。它将主机上的 D:\\ArchitectPracticer\\ElasticSearch/data 目录挂载到容器内的 /usr/share/elasticsearch/data 目录，目的是实现数据的持久化存储。这样即使容器被删除、重新创建等情况发生，Elasticsearch 存储的数据（比如索引数据等）依然保留在主机对应的目录中，不会丢失。 -v D:\\ArchitectPracticer\\ElasticSearch/plugins:/usr/share/elasticsearch/plugins： 同样是数据卷挂载操作，把主机的 D:\\ArchitectPracticer\\ElasticSearch/plugins 目录挂载到容器内的 /usr/share/elasticsearch/plugins 目录，方便对 Elasticsearch 插件进行管理和安装，插件相关的数据也能持久化保存在主机指定目录里。 -e \u0026ldquo;discovery.type=single-node\u0026rdquo;： 通过环境变量（-e，\u0026ndash;env 的缩写）来设置 Elasticsearch 的发现类型为单节点模式。在这种模式下，Elasticsearch 不会去主动寻找其他节点来组成集群，适合在开发、测试环境或者简单的单机使用场景中应用，简化了配置和运行过程。 -e \u0026ldquo;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026rdquo;： 也是设置环境变量，用于指定 Elasticsearch 运行时 Java 虚拟机（JVM）的参数。这里将 JVM 的初始堆内存大小（-Xms）和最大堆内存大小（-Xmx）都设置为 512m，即 512MB，以此来控制 Elasticsearch 在运行过程中的内存使用情况，避免因内存占用过高或过低而出现问题。 -e xpack.security.enabled=false： 关闭Elasticsearch 的安全功能，默认为 true，表示启用安全功能，需要配置用户名密码等安全机制。 elasticsearch:8.16.1： 明确指定要运行的 Docker 镜像名称及版本号，这里表示运行 Elasticsearch 的 Docker 镜像，版本为 8.16.1。 验证安装结果 浏览器访问http://localhost:9200，看到如下结果，说明安装成功。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \u0026#34;name\u0026#34;: \u0026#34;4d3e2d770e4a\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;docker-cluster\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;aUomG6AvRBanbkaizGncKA\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;8.16.1\u0026#34;, \u0026#34;build_flavor\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;ffe992aa682c1968b5df375b5095b3a21f122bf3\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2024-11-19T16:00:31.793213192Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;9.12.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34;: \u0026#34;7.17.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34;: \u0026#34;7.0.0\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; } 基于Docker安装Kibana 拉取镜像\n1 PS C:\\Users\\farbg\u0026gt; docker pull kibana:8.16.1 运行容器\n1 docker run -itd --restart=always --name kibana --network es-net -p 5601:5601 -e ELASTICSEARCH_HOSTS=http://es:9200 kibana:8.16.1 验证安装结果 访问http://localhost:5601/，发现可以正常打开Kibana。\n基于Docker安装IK分词器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 PS C:\\Users\\farbg\u0026gt; docker exec -it es /bin/bash elasticsearch@4d3e2d770e4a:~$ bin/elasticsearch-plugin install https://get.infini.cloud/elasticsearch/analysis-ik/8.16.1 -\u0026gt; Installing https://get.infini.cloud/elasticsearch/analysis-ik/8.16.1 -\u0026gt; Downloading https://get.infini.cloud/elasticsearch/analysis-ik/8.16.1 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ * java.net.SocketPermission * connect,resolve See https://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html for descriptions of what these permissions allow and the associated risks. Continue with installation? [y/N]y -\u0026gt; Installed analysis-ik -\u0026gt; Please restart Elasticsearch to activate any plugins installed 参考文章 基于Docker安装Elasticsearch【保姆级教程、内含图解】 https://blog.csdn.net/Acloasia/article/details/130683934\n","date":"2024-12-15T00:00:00Z","permalink":"https://farb.github.io/p/elasticsearch_docker_installation/","title":"基于Docker安装ElasticSearch"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code\n单体架构、SOA与微服务 单体架构 一个系统的所有模块在一个工程中开发，部署时将所有代码打包。\n优点：业务初期，功能简单，开发成本低，效率高。\n缺点：随着业务量不断增大，会出现如下问题：\n代码复杂度高：所有代码杂糅在一起，依赖紧密，修改一处可能导致其他地方出现问题。 体积大，部署慢：假设一个完整的包是500M，如果只改了一行代码，也需要重新部署整个包。 程序出错影响服务稳定性：某个功能的bug可能导致整个进程的崩溃，影响服务可用性。 阻碍技术的更新：一般来说单体架构只能使用同一个技术栈，比如纯java或纯c#。 集群扩容不合理：因为单体架构所有模块一起部署，假如只是用户模块需要扩容，但是其他模块也跟着扩容，造成资源浪费，而且扩容时间较长。 SOA （Service Oriented Architecture） 微服务是SOA体系结构不断演进的结果。SOA和微服务本质上都在拆分服务，为了降低耦合，提升代码的复用性。但微服务更突出服务的独立性，是更细粒度地划分服务。拆分粒度没有统一标准，需要自己权衡利弊。\n微服务 微服务是一种架构风格，它把一个复杂的系统拆分成多个小的服务，每个服务只做一件事情，服务之间互相调用。\n优点：\n代码复杂度低：根据业务细粒度拆分成多个小服务，业务功能清晰，代码体积小，便于理解维护。 技术选型不受限：单个服务可以根据自身业务选择合适的技术栈。 独立部署：如果修改一个后台服务，修改完毕后只需要部署这一个服务即可，其他服务不动，影响范围小，也减少了测试和部署的时间。 服务的可伸缩性：根据业务发展，哪个服务承载量到达了上限，就多部署一些节点，反之，哪些业务量不大，就减少一些节点。 错误隔离：当某个服务出现故障时，不会影响其他服务，不会影响整个系统。比如后台管理服务出现故障，不会影响用户服务。 容易分库：每个服务独立部署，也可以独立连接一个数据库，省去单体架构的分库成本。 缺点：\n万事万物都是一分为二的，有好必然有坏。\n构建微服务系统复杂：构建微服务系统需要很多技术，比如注册中心、配置中心、服务调用、服务网关、消息总线、监控中心、分布式事务等。需要考虑网络延迟和网络故障的影响。 服务依赖：假如三个服务A、B、C,A调用B,B调用C，如果C不得已必须修改，可能B要修改，A可能也因为B的修改也要修改。 数据一致性问题：各个服务都是独立的进程，传统的数据库事务失效，假设A调用B，恰好遇到网络延迟或网络抖动等网络故障，A服务数据回滚，而B数据可能已经修改保存。 排除故障困难：微服务调用链较长，可能涉及跨多个服务，因此要定位线上问题，不得不同时查看多个服务问题。 运维和部署：要检查和监控多个服务的健康状态，快速部署多个服务，以及根据服务的负载情况进行动态伸缩，都是不小的挑战。 微服务所需要的技术栈 服务注册与发现：当调用接口服务时，首先从服务注册中心获取被调用服务的真实地址，然后调用具体某个服务，调用方不需要知道真实地址。这样很容易实现目标服务的负载均衡，服务之间也实现了解耦。 服务调用：调用方真正调用目标服务的技术（HTTP,RPC） 服务熔断、限流、降级：保证服务的稳定性。 负载均衡：决定调用服务集群中的哪个服务。 配置中心：集中式管理项目的配置，方便修改，解决重复配置，实时生效。 消息队列：服务之间可以异步、解耦，减少调用链路。 服务网关：可以用来做认证，灰度发布等。 服务监控：监控服务的健康状态 消息总线：事件传播与通知，解耦微服务依赖关系，数据一致性维护，异步通信等 分布式链路追踪：查看接口调用链路，排除故障 自动化构建部署：CI/CD Spring Cloud Alibaba是什么？ 引用官网的一段话：https://sca.aliyun.com/docs/2023/overview/what-is-sca\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。\nSpring Cloud Alibaba 提供的主要组件包括：\nNacos：服务注册中心、配置中心、服务元数据存储中心。 Sentinel：流量控制、熔断降级、系统负载保护。 Seata：分布式事务解决方案。 dubbo：远程调用RPC框架。 RocketMQ：阿里的开源分布式消息中间件，高性能、高可用、高吞吐量的金融级消息中间件。 OSS(收费): 文件存储服务 ScheduleX(收费)：分布式任务调度。 SMS(收费): 短信服务。 Spring Cloud 微服务体系 Spring Cloud 是分布式微服务架构的一站式解决方案，它提供了一套简单易用的编程模型，使我们能在 Spring Boot 的基础上轻松地实现微服务系统的构建。 Spring Cloud 提供以微服务为核心的分布式系统构建标准。\nSpring Cloud 本身并不是一个开箱即用的框架，它是一套微服务规范，共有两代实现。\nSpring Cloud Netflix 是 Spring Cloud 的第一代实现，主要由 Eureka、Ribbon、Feign、Hystrix 等组件组成。 Spring Cloud Alibaba 是 Spring Cloud 的第二代实现，主要由 Nacos、Sentinel、Seata 等组件组成。 Spring Cloud Alibaba 定位 Spring Cloud Alibaba 是阿里巴巴结合自身丰富的微服务实践而推出的微服务开发的一站式解决方案，是 Spring Cloud 第二代实现的主要组成部分。吸收了 Spring Cloud Netflix 微服务框架的核心架构思想，并进行了高性能改进。自 Spring Cloud Netflix 进入停更维护后，Spring Cloud Alibaba 逐渐代替它成为主流的微服务框架。\n同时 Spring Cloud Alibaba 也是国内首个进入 Spring 社区的开源项目。2018 年 7 月，Spring Cloud Alibaba 正式开源，并进入 Spring Cloud 孵化器中孵化；2019 年 7 月，Spring Cloud 官方宣布 Spring Cloud Alibaba 毕业，并将仓库迁移到 Alibaba Github OSS 下。\n关于Spring Cloud Alibaba各个组件的版本兼容问题 https://sca.aliyun.com/docs/2023/overview/version-explain\nSpring Cloud Alibaba 快速开始 安装运行Nacos服务 根据官网文档，下载压缩包或者直接使用docker镜像都可以。 https://nacos.io/download/nacos-server/\n然后以standalone的方式运行Nacos服务，我这里以官方bat脚本运行，传入参数standalone，运行成功如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 D:\\ArchitectPracticer\\MicroServiceTools\\nacos-server-2.4.3\\nacos\\bin\u0026gt;startup.cmd -m standalone \u0026#34;nacos is starting with standalone\u0026#34; ,--. ,--.\u0026#39;| ,--,: : | Nacos 2.4.3 ,`--.\u0026#39;`| \u0026#39; : ,---. Running in stand alone mode, All function modules | : : | | \u0026#39; ,\u0026#39;\\ .--.--. Port: 8848 : | \\ | : ,--.--. ,---. / / | / / \u0026#39; Pid: 22544 | : \u0026#39; \u0026#39;; | / \\ / \\. ; ,. :| : /`./ Console: http://192.168.31.227:8848/nacos/index.html \u0026#39; \u0026#39; ;. ;.--. .-. | / / \u0026#39;\u0026#39; | |: :| : ;_ | | | \\ | \\__\\/: . .. \u0026#39; / \u0026#39; | .; : \\ \\ `. https://nacos.io \u0026#39; : | ; .\u0026#39; ,\u0026#34; .--.; |\u0026#39; ; :__| : | `----. \\ | | \u0026#39;`--\u0026#39; / / ,. |\u0026#39; | \u0026#39;.\u0026#39;|\\ \\ / / /`--\u0026#39; / \u0026#39; : | ; : .\u0026#39; \\ : : `----\u0026#39; \u0026#39;--\u0026#39;. / ; |.\u0026#39; | , .-./\\ \\ / `--\u0026#39;---\u0026#39; \u0026#39;---\u0026#39; `--`---\u0026#39; `----\u0026#39; 2024-12-06 21:27:26,565 INFO Tomcat initialized with port(s): 8848 (http) 2024-12-06 21:27:26,977 INFO Root WebApplicationContext: initialization completed in 3424 ms 2024-12-06 21:27:31,041 INFO Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@4cad79bc, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@2c63762b, org.springframework.security.web.context.SecurityContextPersistenceFilter@726934e2, org.springframework.security.web.header.HeaderWriterFilter@1163a27, org.springframework.security.web.csrf.CsrfFilter@3b55dd15, org.springframework.security.web.authentication.logout.LogoutFilter@3f6bf8aa, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@e280403, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@42f85fa4, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@7a9eccc4, org.springframework.security.web.session.SessionManagementFilter@92d1782, org.springframework.security.web.access.ExceptionTranslationFilter@28a9494b] 2024-12-06 21:27:31,288 INFO Adding welcome page: class path resource [static/index.html] 2024-12-06 21:27:31,783 INFO Exposing 1 endpoint(s) beneath base path \u0026#39;/actuator\u0026#39; 2024-12-06 21:27:31,789 WARN You are asking Spring Security to ignore Ant [pattern=\u0026#39;/**\u0026#39;]. This is not recommended -- please use permitAll via HttpSecurity#authorizeHttpRequests instead. 2024-12-06 21:27:31,805 INFO Will not secure Ant [pattern=\u0026#39;/**\u0026#39;] 2024-12-06 21:27:31,805 WARN You are asking Spring Security to ignore Mvc [pattern=\u0026#39;/prometheus\u0026#39;]. This is not recommended -- please use permitAll via HttpSecurity#authorizeHttpRequests instead. 2024-12-06 21:27:31,805 INFO Will not secure Mvc [pattern=\u0026#39;/prometheus\u0026#39;] 2024-12-06 21:27:31,805 WARN You are asking Spring Security to ignore Mvc [pattern=\u0026#39;/prometheus/namespaceId/{namespaceId}\u0026#39;]. This is not recommended -- please use permitAll via HttpSecurity#authorizeHttpRequests instead. 2024-12-06 21:27:31,805 INFO Will not secure Mvc [pattern=\u0026#39;/prometheus/namespaceId/{namespaceId}\u0026#39;] 2024-12-06 21:27:31,805 WARN You are asking Spring Security to ignore Mvc [pattern=\u0026#39;/prometheus/namespaceId/{namespaceId}/service/{service}\u0026#39;]. This is not recommended -- please use permitAll via HttpSecurity#authorizeHttpRequests instead. 2024-12-06 21:27:31,805 INFO Will not secure Mvc [pattern=\u0026#39;/prometheus/namespaceId/{namespaceId}/service/{service}\u0026#39;] 2024-12-06 21:27:31,867 INFO Tomcat started on port(s): 8848 (http) with context path \u0026#39;/nacos\u0026#39; 2024-12-06 21:27:31,867 INFO No TaskScheduler/ScheduledExecutorService bean found for scheduled processing 2024-12-06 21:27:31,901 INFO Nacos started successfully in stand alone mode. use embedded storage 2024-12-06 21:27:42,783 INFO Initializing Servlet \u0026#39;dispatcherServlet\u0026#39; 2024-12-06 21:27:42,785 INFO Completed initialization in 1 ms 然后可以浏览器中打开 http://192.168.31.227:8848/nacos或localhost:8848/nacos 查看Nacos管理界面是否可以查看。\n创建微服务 接下来就是创建微服务，启动，查看服务是否注册。\n我这里使用的是当前最新的SpringCloudAlibaba依赖版本2023.0.3.2，支持的springboot版本是3.2.4。\n创建一个父模块SpringCloudAlibabaPractice，只管理公共pom配置，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;top.farb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;SpringCloudAlibabaPractice\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;SpringCloudAlibabaPractice\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;SpringCloudAlibabaPractice\u0026lt;/description\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;spring-boot.version\u0026gt;3.2.4\u0026lt;/spring-boot.version\u0026gt; \u0026lt;spring-cloud-alibaba.version\u0026gt;2023.0.3.2\u0026lt;/spring-cloud-alibaba.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!-- 后面所有演示模块都会以子模块的形式加入--\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;FirstServiceDemo\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; \u0026lt;!-- 这里加一下子模块基本都会使用的依赖，避免子模块重复添加--\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2023.0.3.2\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;17\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;17\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 然后，创建一个子模块，例如FirstServiceDemo，只有一个Springboot启动类就行，再加一个application.yml如下：\n1 2 3 4 5 6 7 8 9 10 server: port: 8080 spring: application: name: first-service cloud: nacos: discovery: server-addr: localhost:8848 # nacos注册中心地址 namespace: # 如果为空，则使用public命名空间，否则需要配置nacos的命名空间id 启动应用，可以到nacos控制台页面看到服务已经注册成功。\n至此，基本的框架就搭建好了。后面的实战会以这个作为基础。\n","date":"2024-12-07T00:00:00Z","permalink":"https://farb.github.io/p/springcloudalibaba_01_introduction/","title":"SpringCloud Alibaba 入门实战"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code\n微服务和SpringCloud相关概念 传统架构和微服务的比较 传统架构：所有模块都是集中开发，集中部署，集中运行的，耦合度比较高，模块之间通过代码直接调用，数据库和缓存也属于整个系统，包括所有模块的数据。\n微服务：每个模块都是单独开发，单独部署，单独运行的，解耦度较高，模块之间通过接口调用，数据库和缓存也属于每个模块，每个模块的数据也只属于自己。整个系统的扩展能力较强，能用较小的代价扩展新的功能模块。\n微服务和SpringCloud的相关概念 微服务是一种设计风格，有不同的实现方式，而SpringCould是一个微服务框架，它提供了一系列的解决方案，如服务注册中心、配置中心、路由、网关、负载均衡、断路器、监控、网关限流等。\nGateway：网关，用于实现服务间的路由，负载均衡，限流等。\nConfig：配置中心，用于管理配置文件，包括配置文件的版本控制，配置文件的发布等。\nBus：消息总线，用于实现服务间的通信，包括服务间的消息发布，服务间的消息订阅等。\nSleuth：分布式追踪，用于实现服务间的调用链路追踪，包括调用链路追踪的记录，调用链路追踪的日志等。\nCircuit Breaker：断路器，用于实现服务间的容错，包括服务间的调用超时，服务间的调用失败等。\nSecurity：安全中心，用于实现服务间的安全认证，包括服务间的用户认证，服务间的角色认证等。\nLoadBalancer：负载均衡，用于实现服务间的负载均衡，包括服务间的轮询，随机等。\nDiscovery：服务发现，用于实现服务间的服务发现，包括服务间的服务注册，服务间的服务发现等。\nSpringCloud的常用组件如下：\n组件 功能 JPA ORM框架 Eureka 服务治理组件，通过该组件，系统可以动态地实现微服务组件治理 Hystrix 容错保护组件，能提供自动熔断和限流等方面的功能 Ribbon 负载均衡组件，能够把请求均衡地分摊到各服务组件上，包括轮询、随机、一致性哈希等 Zuul 网关组件，能够实现服务间的路由 Spring Cloud Config 配置中心组件，能够实现配置文件的管理 多模块整合Redis，构建微服务体系 用Docker准备Redis和MySQL集群环境 创建一个一主一从的Redis集群环境:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 PS C:\\Users\\farbg\u0026gt; docker run -itd --name master-redis -p 6379:6379 redis 6c0478e385052a2bb2547e3436e236258cd3c7b75c4af234cede446b9987b39f PS C:\\Users\\farbg\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; master-redis 172.17.0.4 PS C:\\Users\\farbg\u0026gt; docker run -itd --name slave-redis -p 6380:6380 redis 81441fe049dda8b567bfef6235f7a9bc760cb383cbd4a77c0461ee164dcc28d7 PS C:\\Users\\farbg\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; slave-redis 172.17.0.2 PS C:\\Users\\farbg\u0026gt; docker exec -it slave-redis bash root@4cc2ca237b09:/data# redis-cli 127.0.0.1:6379\u0026gt; SLAVEOF 172.17.0.4 6379 OK 127.0.0.1:6379\u0026gt; info replication # Replication role:slave master_host:172.17.0.4 master_port:6379 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_read_repl_offset:14 slave_repl_offset:14 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:cc12d98a9045805969db2fa546a002bb35234c53 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:14 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:14 root@6c0478e38505:/data# redis-cli 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=172.17.0.2,port=6379,state=online,offset=112,lag=1 master_failover_state:no-failover master_replid:cc12d98a9045805969db2fa546a002bb35234c53 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:112 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:112 # 验证主从模式是否正常工作 # 在主节点set 127.0.0.1:6379\u0026gt; set hello world OK # 在从节点get 127.0.0.1:6379\u0026gt; get hello \u0026#34;world\u0026#34; 搭建一个一主一从的MySQL集群环境：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 本机中新建mysql的配置文件 D:\\ArchitectPracticer\\Redis\\MySql\\MasterMySql\\conf\\my.cnf ，内容如下： [mysqld] pid-file=/var/run/mysqld/mysqld.pid socket=/var/run/mysqld/mysqld.sock datadir=/var/lib/mysql server-id=1 # 主服务器的id，这个id不能重复 log-bin=mysql-master-bin # 启动主服务器，设置环境变量，MYSQL_ROOT_PASSWORD为root用户的密码，同时挂载配置文件目录和数据目录 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name master-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v D:\\ArchitectPracticer\\Redis\\MySql\\MasterMySql\\conf:/etc/mysql/conf.d -v D:\\ArchitectPracticer\\Redis\\MySql\\MasterMySql\\data:/var/lib/mysql mysql 05e2c449e667b7fbd6898f9e84306440d1afff5c7e75624a438af082157ca75d # 查看运行的容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7b1067615f0d mysql \u0026#34;docker-entrypoint.s…\u0026#34; About a minute ago Up About a minute 0.0.0.0:3306-\u0026gt;3306/tcp, 33060/tcp master-mysql # 获取主服务器的IP地址 D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect master-mysql -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; 172.17.0.3 # 登录主服务器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it master-mysql bash bash-5.1# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; SHOW BINARY LOG STATUS; +-------------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------------+----------+--------------+------------------+-------------------+ | mysql-master-bin.000007 | 158 | | | | +-------------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 创建从数据库：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 # mysql从服务器的配置文件如下 [mysqld] pid-file=/var/run/mysqld/mysqld.pid socket=/var/run/mysqld/mysqld.sock datadir=/var/lib/mysql server-id=2 # 从服务器的id，这个id不能和主服务器的一致 log-bin=mysql-slave-bin # 二进制文件的名字 # 启动从服务器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name slave-mysql -p 3316:3306 -e MYSQL_ROOT_PASSWORD=123456 -v D:\\ArchitectPracticer\\Redis\\MySql\\SlaveMySql\\conf:/etc/mysql/conf.d -v D:\\ArchitectPracticer\\Redis\\MySql\\SlaveMySql\\data:/var/lib/mysql mysql PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it slave-mysql /bin/bash # 确认可以在从服务器的容器中连接到主服务器 bash-5.1# mysql -h 172.17.0.3 -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 18 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. # exit退出主服务器的连接 mysql\u0026gt; exit Bye # 连接到从服务器 bash-5.1# mysql -h localhost -u root -p mysql: [Warning] World-writable config file \u0026#39;/etc/mysql/conf.d/my.cnf\u0026#39; is ignored. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 11 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. # 配置主从关系，这里注意`change master to`已经在MySql8中被`CHANGE REPLICATION SOURCE TO`取代。每个字段的意思很明显，主要是`SOURCE_log_pos`和`SOURCE_log_file`要和上面`show binary log status;`的结果一致。` mysql\u0026gt; CHANGE REPLICATION SOURCE TO SOURCE_host=\u0026#39;172.17.0.3\u0026#39;,SOURCE_port=3306,SOURCE_user=\u0026#39;root\u0026#39;,SOURCE_password=\u0026#39;123456\u0026#39;,SOURCE_log_pos=158,SOURCE_log_file=\u0026#39;mysql-master-bin.000007\u0026#39;; Query OK, 0 rows affected, 2 warnings (0.04 sec) # start slave;也变成了start replica; 详见 https://dev.mysql.com/doc/refman/8.4/en/start-replica.html mysql\u0026gt; start replica; Query OK, 0 rows affected (0.01 sec) # 查看主从复制状态，命令结尾符\\G是以垂直列表的形式显示。看到Replica_IO_Running: Yes 和 Replica_SQL_Running: Yes，说明配置主从复制成功 mysql\u0026gt; show replica status\\G; *************************** 1. row *************************** Replica_IO_State: Waiting for source to send event Source_Host: 172.17.0.2 Source_User: root Source_Port: 3306 Connect_Retry: 60 Source_Log_File: mysql-master-bin.000002 Read_Source_Log_Pos: 158 Relay_Log_File: 0f827dad7de8-relay-bin.000003 Relay_Log_Pos: 335 Relay_Source_Log_File: mysql-master-bin.000002 Replica_IO_Running: Yes Replica_SQL_Running: Yes ... 省略一部分输出 1 row in set (0.00 sec) ERROR: No query specified # 回到主服务器，创建数据库 mysql\u0026gt; create database RiskDb; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; use RiskDb; Database changed mysql\u0026gt; create table riskinfo (id int not null primary key,level varchar(20),userId varchar(20)); Query OK, 0 rows affected (0.02 sec) # 表示用户id为003的用户有高危风险,不能下单 mysql\u0026gt; insert into riskinfo (id,level,userid) values(1,\u0026#39;High\u0026#39;,\u0026#39;003\u0026#39;); Query OK, 1 row affected (0.01 sec) # 可以看到主服务器中有新建的数据库 RiskDb mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | MasterSlaveDemo | | mysql | | performance_schema | | redisDemo | | RiskDb | | sys | +--------------------+ 7 rows in set (0.00 sec) # 再去从服务器中查看，检查是否同步成功，结果发现同步成功 mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | MasterSlaveDemo | | mysql | | performance_schema | | redisDemo | | RiskDb | | sys | +--------------------+ 7 rows in set (0.00 sec) 至此，一主一从的Redis和MySQL主从复制搭建完成。\nDocker容器名 IP和端口 说明 master-mysql 172.17.0.3:3306 MySQL主服务器 slave-mysql 172.17.0.5:3316 MySQL从服务器 master-redis 172.17.0.4:6379 Redis主服务器 slave-redis 172.17.0.2:6380 Redis从服务器 包含Redis和Eureka的架构图 开发Eureka服务端 新建一个SpringBoot项目，添加依赖，pom.xml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;farb.top\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;EurekaServer\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;EurekaServer\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;EurekaServer\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;2023.0.2\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; EurekaServerApplication.java代码如下：\n1 2 3 4 5 6 7 8 9 @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } application.yml配置如下：\n1 2 3 4 5 6 7 8 9 10 server: port: 8888 eureka: instance: hostname: localhost client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka 运行EurekaServerApplication，访问http://localhost:8888/，可以看到如下界面，说明Eureka服务端已经启动成功。\n开发Eureka客户端 新建一个SpringBoot项目EurekaClientRiskApp，作为风险模块，添加依赖，pom.xml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;farb.top\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;EurekaClientRiskApp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;EurekaClientRiskApp\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;EurekaClientRiskApp\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;2023.0.2\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.43\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 下面是具体代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @EnableDiscoveryClient @SpringBootApplication public class EurekaClientRiskAppApplication { public static void main(String[] args) { SpringApplication.run(EurekaClientRiskAppApplication.class, args); } } @RestController public class RiskController { private final RiskService riskService; @Value(\u0026#34;${server.port}\u0026#34;) private String port; public RiskController(RiskService riskService) { this.riskService = riskService; } @GetMapping(\u0026#34;hello\u0026#34;) public String hello() { return \u0026#34;hello,this is Risk Service\u0026#34;; } @GetMapping(\u0026#34;getRiskLevel/{userId}\u0026#34;) public String getRiskLevel(@PathVariable String userId) { System.out.println(\u0026#34;当前端口号为：\u0026#34; + this.port); return riskService.getRiskLevel(userId); } } @Entity @Table(name = \u0026#34;riskinfo\u0026#34;) @Data @AllArgsConstructor @NoArgsConstructor public class Risk { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private int id; private String level; private String userid; } @Repository public class RedisRiskRepo { @Autowired private RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; public void saveRiskLevel(String key, int expireTime, Risk risk) { redisTemplate.opsForValue().set(key, JSON.toJSONString(risk), expireTime, TimeUnit.MINUTES); } public Risk getRiskLevel(String key) { String json = redisTemplate.opsForValue().get(key); return JSON.parseObject(json, Risk.class); } } @Repository public interface RiskRepo extends JpaRepository\u0026lt;Risk, Long\u0026gt; { Risk getRiskByUserid(String userid); } @Service public class RiskService { private static final String RISK_KEY_PREFIX = \u0026#34;risk_\u0026#34;; @Autowired private RiskRepo riskRepo; @Autowired private RedisRiskRepo redisRiskRepo; public String getRiskLevel(String userId) { Risk risk = redisRiskRepo.getRiskLevel(RISK_KEY_PREFIX + userId); if (risk != null) { System.out.println(\u0026#34;从redis获取数据\u0026#34;); return risk.getLevel(); } risk = riskRepo.getRiskByUserid(userId); System.out.println(\u0026#34;从mysql获取数据\u0026#34;); if (risk != null) { redisRiskRepo.saveRiskLevel(RISK_KEY_PREFIX + userId, 60, risk); return risk.getLevel(); } return \u0026#34;\u0026#34;; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 server: port: 1111 spring: application: name: RiskService data: redis: host: localhost port: 6379 eureka: client: service-url: defaultZone: http://localhost:8888/eureka fetch-registry: true register-with-eureka: true 复制一个项目EurekaClientRiskApp2，只修改yml中的端口号为1222，用来区分负载均衡生效。\n新建一个SpringBoot项目EurekaClientOrderApp，作为订单模块，添加依赖，pom.xml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;farb.top\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;EurekaClientOrderApp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;EurekaClientOrderApp\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;EurekaClientOrderApp\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;2023.0.2\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @SpringBootApplication @EnableDiscoveryClient public class EurekaClientOrderAppApplication { public static void main(String[] args) { SpringApplication.run(EurekaClientOrderAppApplication.class, args); } } @RestController public class HelloController { @LoadBalanced @Resource private RestTemplate restTemplate; @Resource private DiscoveryClient discoveryClient; @GetMapping(\u0026#34;hello\u0026#34;) public String hello() { // 一个服务可能在多个服务器节点上运行，所以一个服务可能对应多个实列 List\u0026lt;ServiceInstance\u0026gt; serviceInstances = discoveryClient.getInstances(\u0026#34;RiskService\u0026#34;); if (!serviceInstances.isEmpty()) { return restTemplate.getForObject(\u0026#34;http://RiskService/hello\u0026#34;, String.class); } return \u0026#34;RiskService not found\u0026#34;; } @GetMapping(\u0026#34;getRiskInfo\u0026#34;) public String getRiskInfo() { // 一个服务可能在多个服务器节点上运行，所以一个服务可能对应多个实列 List\u0026lt;ServiceInstance\u0026gt; serviceInstances = discoveryClient.getInstances(\u0026#34;RiskService\u0026#34;); if (!serviceInstances.isEmpty()) { return restTemplate.getForObject(\u0026#34;http://RiskService/getRiskLevel/003\u0026#34;, String.class); } return \u0026#34;RiskService not found\u0026#34;; } } @Configuration public class AppConfig { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } 1 2 3 4 5 6 7 8 9 10 11 spring: application: name: OrderService eureka: client: fetch-registry: true register-with-eureka: true service-url: defaultZone: http://localhost:8888/eureka server: port: 2222 分别运行两个服务RiskService和OrderService，然后访问OrderService的接口http://localhost:2222/hello，会自动调用RiskService的接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 PS C:\\Users\\farbg\u0026gt; curl http://host.docker.internal:2222/hello StatusCode : 200 StatusDescription : Content : hello,this is Risk Service RawContent : HTTP/1.1 200 Content-Length: 26 Content-Type: text/plain;charset=UTF-8 Date: Mon, 25 Nov 2024 15:19:23 GMT hello,this is Risk Service Forms : {} Headers : {[Content-Length, 26], [Content-Type, text/plain;charset=UTF-8], [Date, Mon, 25 Nov 2024 15:19:23 G MT]} Images : {} InputFields : {} Links : {} ParsedHtml : mshtml.HTMLDocumentClass RawContentLength : 26 # 返回的结果会在下面两种结果轮询 hello,this is Risk Service hello,this is Risk Service,and this is node 2 hello,this is Risk Service hello,this is Risk Service,and this is node 2 Redis与Ribbon集成 复制一个RiskService模块，将配置文件的端口修改如下，其他都不变：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 server: port: 1222 spring: application: name: RiskService data: redis: host: localhost port: 6379 eureka: client: service-url: defaultZone: http://localhost:8888/eureka fetch-registry: true register-with-eureka: true 然后再修改一下控制器，目的是能区分出响应是从哪个节点返回的：\n1 2 3 4 5 6 7 @RestController public class RiskController { @GetMapping(\u0026#34;hello\u0026#34;) public String hello() { return \u0026#34;hello,this is Risk Service,and this is node 2\u0026#34;; } } 启动两个服务，然后查看Eureka服务器的实例列表如下：\n然后访问http://host.docker.internal:2222/getRiskInfo，会自动调用RiskService的接口，因为Ribbon默认是轮询的方式，所以每次访问结果都不一样。\n1 2 3 4 5 6 7 8 9 10 11 12 # 返回的结果会在两个服务节点切换，而且一开始是从mysql获取数据，以后从redis获取数据 当前端口号为：1222 从mysql获取数据 当前端口号为：1222 从redis获取数据 当前端口号为：1222 从redis获取数据 当前端口号为：1111 从redis获取数据 当前端口号为：1111 从redis获取数据 ","date":"2024-11-24T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_13_redis_springcloud/","title":"基于Docker的Redis实战-Redis与SpringCloud微服务整合"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code\n在SpringBoot框架引入Redis 准备MySQL数据库和数据表 创建MySQL的镜像容器并进入容器 1 2 3 4 PS C:\\Users\\farbg\u0026gt; docker run -itd -p 3306:3306 --name mysqlSpringBoot -e MYSQL_ROOT_PASSWORD=123456 mysql 324a64cbc2c9b36dca5f08fd86f301bd6cf55b6fcfa403536d538537e660c68c PS C:\\Users\\farbg\u0026gt; docker exec -it mysqlSpringBoot bash 登录mysql数据库，并创建数据库和数据表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 bash-5.1# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; use stockDB; Database changed mysql\u0026gt; create table stock(id int not null primary key,name varchar(20),num int); Query OK, 0 rows affected (0.02 sec) # 查看数据表结构 mysql\u0026gt; desc stock; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int | NO | PRI | NULL | | | name | varchar(20) | YES | | NULL | | | num | int | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 3 rows in set (0.00 sec) # 插入数据 mysql\u0026gt; insert into stock(id,name,num) values (1,\u0026#39;Computer\u0026#39;,10); Query OK, 1 row affected (0.00 sec) # 查看数据 mysql\u0026gt; select * from stock; +----+----------+------+ | id | name | num | +----+----------+------+ | 1 | Computer | 10 | +----+----------+------+ 1 row in set (0.00 sec) 搭建SpringBoot项目 新建一个Maven项目SpringBootForRedis，并添加依赖如下: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.0\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;blog.farb.top\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;SpringBootForRedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;SpringBootForRedis\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;SpringBootForRedis\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.43\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.34\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 代码结构目录如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 │ SpringBootForRedisApplication.java │ ├─controller │ StockController.java │ ├─entity │ Stock.java │ ├─repo │ StockRedisRepo.java │ StockRepo.java │ └─service StockService.java StockServiceImpl.java StockController.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package blog.farb.top.springbootforredis.controller; import blog.farb.top.springbootforredis.entity.Stock; import blog.farb.top.springbootforredis.service.StockService; import jakarta.annotation.Resource; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController public class StockController { @Resource private StockService stockService; @GetMapping(\u0026#34;/stock/{id}\u0026#34;) public Stock getStockById(@PathVariable int id) { return stockService.getStockById(id); } } StockServiceImpl.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package blog.farb.top.springbootforredis.service; import blog.farb.top.springbootforredis.entity.Stock; import blog.farb.top.springbootforredis.repo.StockRedisRepo; import blog.farb.top.springbootforredis.repo.StockRepo; import jakarta.annotation.Resource; import org.springframework.stereotype.Service; @Service public class StockServiceImpl implements StockService { private static final String REDIS_KEY_PREFIX = \u0026#34;stock:\u0026#34;; @Resource private StockRedisRepo stockRedisRepo; @Resource private StockRepo stockRepo; @Override public Stock getStockById(int id) { String key = REDIS_KEY_PREFIX + id; Stock stock = stockRedisRepo.getStockById(key); if (stock != null) { System.out.println(\u0026#34;Get stock from Redis\u0026#34;); return stock; } System.out.println(\u0026#34;Get stock from DB\u0026#34;); stock = stockRepo.findById(id).orElse(null); stockRedisRepo.addStock(key, stock, 1000 * 60 * 10); return stock; } } StockRedisRepo.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package blog.farb.top.springbootforredis.repo; import blog.farb.top.springbootforredis.entity.Stock; import com.alibaba.fastjson2.JSON; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Repository; @Repository public class StockRedisRepo { @Autowired private RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; public Stock getStockById(String key) { String jsonStr = redisTemplate.opsForValue().get(key); return JSON.parseObject(jsonStr, Stock.class); } public void addStock(String key, Stock stock, int expireSeconds) { redisTemplate.opsForValue().set(key, JSON.toJSONString(stock), expireSeconds); } } StockRepo.java\n1 2 3 4 5 6 7 8 9 10 11 12 package blog.farb.top.springbootforredis.repo; import blog.farb.top.springbootforredis.entity.Stock; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.stereotype.Repository; import java.util.Optional; @Repository public interface StockRepo extends JpaRepository\u0026lt;Stock, Integer\u0026gt; { Optional\u0026lt;Stock\u0026gt; findById(int id); } Stock.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package blog.farb.top.springbootforredis.entity; import jakarta.persistence.Entity; import jakarta.persistence.GeneratedValue; import jakarta.persistence.GenerationType; import jakarta.persistence.Id; import lombok.Data; @Entity @Data public class Stock { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String name; private String num; } 运行结果可知，首次先从数据库查询，然后把数据存入Redis，第二次直接从Redis中获取数据。\n1 2 3 Get stock from DB Hibernate: select s1_0.id,s1_0.name,s1_0.num from stock s1_0 where s1_0.id=? Get stock from Redis 在SpringBoot中实现秒杀案例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 BuyController.java @RestController public class BuyController { private final SellService sellService; public BuyController(SellService sellService) { this.sellService = sellService; } @GetMapping(\u0026#34;/quickBuy/{item}/{buyer}\u0026#34;) public String quickBuy(@PathVariable String item, @PathVariable String buyer) { String res = sellService.quickBuy(item, buyer); return res.equals(\u0026#34;1\u0026#34;) ? buyer + \u0026#34; Success\u0026#34; : buyer + \u0026#34;Fail\u0026#34;; } @GetMapping(\u0026#34;/quickBuy/benchMark\u0026#34;) public String benchMark() { for (int i = 0; i \u0026lt; 15; i++) { new BenchMarkTest().start(); } return \u0026#34;Success\u0026#34;; } } SellService.java @Service public class SellService { private final RedisTemplate redisTemplate; public SellService(RedisTemplate redisTemplate) { this.redisTemplate = redisTemplate; } public String quickBuy(String item, String buyer) { String luaScript = \u0026#34;\u0026#34;\u0026#34; local buyer=ARGV[1]; local productName=KEYS[1]; local leftCount=tonumber(redis.call(\u0026#39;get\u0026#39;,productName)); if(leftCount\u0026lt;=0) then return 0 else redis.call(\u0026#39;decrby\u0026#39;,productName,1); redis.call(\u0026#39;rpush\u0026#39;,\u0026#34;buyerList\u0026#34;,buyer) return 1 end \u0026#34;\u0026#34;\u0026#34;; // 如果这里不设置序列化器，会使用默认的Jdk会序列器，导致key和value有乱码,而且会导致上面的lua脚本查询不到数据。 // 当然这里的代码可以移到配置文件中 redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new StringRedisSerializer()); // 注意，这里必须使用Long返回类型，因为redis中的Integer对应java中的Long RedisScript\u0026lt;Long\u0026gt; defaultRedisScript = new DefaultRedisScript\u0026lt;\u0026gt;(luaScript, Long.class); Object res = redisTemplate.execute(defaultRedisScript, Collections.singletonList(item), buyer); return res.toString(); } } BenchMarkTest.java public class BenchMarkTest extends Thread { @Override public void run() { new QuickBuyClient().quickBuy(\u0026#34;Gold\u0026#34;, \u0026#34;buyer\u0026#34; + Thread.currentThread().getName()); } } QuickBuyClient.java public class QuickBuyClient { private final RestTemplate restTemplate = new RestTemplate(); public void quickBuy(String item, String buyer) { String res = restTemplate.getForObject(\u0026#34;http://localhost:8080/quickBuy/{item}/{buyer}\u0026#34;, String.class, item, buyer); System.out.println(\u0026#34;秒杀结果：\u0026#34; + res); } } 调用秒杀接口前，先设置一下redis中的数据，如下：\n1 2 3 4 127.0.0.1:6379\u0026gt; set Gold 10 ex 3600 OK 127.0.0.1:6379\u0026gt; del buyerList (integer) 1 调用模拟秒杀接口 http://localhost:8080/quickBuy/benchMark，测试结果如下：\n可以看到，一共10件库存，但是有15个线程模拟15个人同时去抢，结果只成功了10个，其余5个失败。可见没有发生超卖现象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 秒杀结果：buyerThread-24 Fail 秒杀结果：buyerThread-23 Success 秒杀结果：buyerThread-28 Fail 秒杀结果：buyerThread-22 Fail 秒杀结果：buyerThread-18 Success 秒杀结果：buyerThread-30 Success 秒杀结果：buyerThread-27 Success 秒杀结果：buyerThread-25 Success 秒杀结果：buyerThread-16 Fail 秒杀结果：buyerThread-17 Success 秒杀结果：buyerThread-29 Success 秒杀结果：buyerThread-19 Success 秒杀结果：buyerThread-20 Success 秒杀结果：buyerThread-21 Success 秒杀结果：buyerThread-26 Fail ","date":"2024-11-22T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_12_redis_springboot/","title":"基于Docker的Redis实战-Redis与SpringBoot整合"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code 注：由于微信公众号后台编辑器不支持markdown格式，本人使用的三方网站转换的markdown格式，所以发现代码有混乱的情况，请查看我的博客，https://blog.farb.top/p/redis_in_action_11_lua/\n在Redis中调用Lua脚本 引入Lua脚本的场景 重复执行相同类型的命令，比如缓存1到1000到内存中 在高并发场景下减少网络调用的开销，比如将多条redis命令放到一个Lua脚本中执行，只需要一次网络调用开销即可 Redis会把lua脚本当作一个整体执行，天然具有原子性。 注意：如果运行的lua脚本没有响应或不返回值，就会阻塞整个redis服务，并且运行lua脚本时很难调试，故lua脚本的代码要尽量简洁清晰\n通过redis-cli命令运行lua脚本 lua脚本如下：\n1 2 3 4 // 先在本地路径D:\\ArchitectPracticer\\Redis\\lua 创建一个SimpleRedis.lua文件，代码如下： redis.call(\u0026#39;set\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;farb\u0026#39;) // lua脚本里使用redis.call()方法调用redis命令，第一个参数是Redis命令，后面是命令的参数 bash脚本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 启动一个redis容器，将本地磁盘的D:\\ArchitectPracticer\\Redis\\lua路径挂载到容器的/luaScript目录下 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-lua -v D:\\ArchitectPracticer\\Redis\\lua:/luaScript:rw -p 6379:6379 redis:latest c9900020aba5110bb43cf2ac6f1774f03a74940ff02690bdb3bf357222dfaff1 # 启动一个容器的交互式shell PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-lua bash # 使用--eval参数执行lua脚本，该脚本没有返回值，所以返回nil root@c9900020aba5:/data# redis-cli --eval /luaScript/SimpleRedis.lua (nil) # 可以通过get命令查看是否写入成功 root@c9900020aba5:/data# redis-cli 127.0.0.1:6379\u0026gt; get name \u0026#34;farb\u0026#34; # 如果是Redis低版本，修改了lua脚本，需要重启容器，否则不会生效；我当前的Redis版本是7.2.5,不需要重启docker容器就能生效 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker restart redis-lua redis-lua PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-lua bash root@c9900020aba5:/data# redis-cli --eval /luaScript/SimpleRedis.lua (nil) root@c9900020aba5:/data# redis-cli 127.0.0.1:6379\u0026gt; get name \u0026#34;Jack\u0026#34; 直接通过eval 命令执行lua脚本 实际项目中，如果lua脚本里包含的语句较多，则通过lua脚本文件的方式执行会比较方便。如果语句很少，则可以直接通过eval命令执行lua脚本\n1 2 3 4 5 6 7 8 # script是双引号括起来的脚本，numkeys是key的数量，这两个参数是必须的 eval script numkeys [key [key ...]] [arg [arg ...]] root@c9900020aba5:/data# redis-cli 127.0.0.1:6379\u0026gt; eval \u0026#34;redis.call(\u0026#39;set\u0026#39;,\u0026#39;age\u0026#39;,18)\u0026#34; 0 (nil) 127.0.0.1:6379\u0026gt; get age \u0026#34;18\u0026#34; 通过return返回脚本运行结果 新建一个ReturnRedisResult.lua文件，代码如下：return 1\n1 2 3 4 5 6 7 # 执行lua脚本，返回1 root@c9900020aba5:/data# redis-cli --eval /luaScript/ReturnRedisResult.lua (integer) 1 # 修改ReturnRedisResult.lua为return redis.call(\u0026#34;set\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;HanMeimei\u0026#34;)，直接返回OK root@c9900020aba5:/data# redis-cli --eval /luaScript/ReturnRedisResult.lua OK Redis中和lua相关的命令 使用Script Load \u0026lt;script\u0026gt;事先装载lua脚本，然后使用evalsha命令多次运行该脚本。 使用Script Flush清空Redis服务器的所有lua脚本。 使用Script Kill终止正在运行的lua脚本。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # evalsha命令:sha1是lua脚本的sha1值，numkeys是key的数量 evalsha sha1 numkeys [key [key ...]] [arg [arg ...]] PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-lua bash root@c9900020aba5:/data# redis-cli # 将lua脚本加载到redis服务器，返回值是sha1值 127.0.0.1:6379\u0026gt; script load \u0026#34;return 1\u0026#34; \u0026#34;e0e1f9fabfc9d4800c877a703b823ac0578ff8db\u0026#34; # 使用evalsha sha1值调用lua脚本，返回值是1，可重复调用 127.0.0.1:6379\u0026gt; evalsha e0e1f9fabfc9d4800c877a703b823ac0578ff8db 0 (integer) 1 127.0.0.1:6379\u0026gt; evalsha e0e1f9fabfc9d4800c877a703b823ac0578ff8db 0 (integer) 1 # 删除缓存中的所有lua脚本 127.0.0.1:6379\u0026gt; script flush OK # 再次执行lua脚本时报错 127.0.0.1:6379\u0026gt; evalsha e0e1f9fabfc9d4800c877a703b823ac0578ff8db 0 (error) NOSCRIPT No matching script. Please use EVAL. 观察Lua脚本阻塞redis的效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 执行一个死循环的lua脚本,由于redis的执行引擎是单线程的，因此整个Redis服务都会被阻塞，导致其他命令无法执行 127.0.0.1:6379\u0026gt; eval \u0026#34;while true do end\u0026#34; 0 # 使用ctrl + c 退出,重新连接一个客户端 ^Croot@c9900020aba5:/data# redis-cli 127.0.0.1:6379\u0026gt; get name # 提示Redis正在忙于执行一个脚本，只能使用Script Kill终止正在执行的脚本或者shutdown nosave来停止服务 (error) BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE. 127.0.0.1:6379\u0026gt; script kill OK # 终止运行的脚本后，可以正常访问redis了。 127.0.0.1:6379\u0026gt; get name \u0026#34;HanMeimei\u0026#34; 因此使用lua脚本需要格外小心，执行时间不能过长，否则不仅redis服务器阻塞，所有请求的线程也会阻塞，如果并发量巨大，会导致大量线程阻塞，最终系统瘫痪无法对外服务，这是很严重的事故。因此lua脚本要尽量保持短小，其次，逻辑不要太复杂，否则可能出现bug导致长时间运行，如果很复杂，需要充分测试。\nRedis整合lua高级实战 通过KEYS和ARGV传递参数 KEYS和ARGV通过都是数组传参，KEYS是传入redis命令需要的参数，ARGV是传入自定义的参数，但是下标是从1开始的。且eval命令传入的参数个数表示的KEYS的参数个数，不包括ARGV的参数个数。\n1 2 3 4 5 6 7 8 9 10 root@c9900020aba5:/data# redis-cli # 1表示key的数量，key1是key的名称，one是参数1，two是参数2 127.0.0.1:6379\u0026gt; eval \u0026#34;return {KEYS[1],ARGV[1],ARGV[2]}\u0026#34; 1 key1 one two 1) \u0026#34;key1\u0026#34; 2) \u0026#34;one\u0026#34; 3) \u0026#34;two\u0026#34; # 2表示key的数量，key1是key的名称，读取第二个参数时发现是ARGV而不是KEY类型的，所以抛弃，two是参数2 127.0.0.1:6379\u0026gt; eval \u0026#34;return {KEYS[1],ARGV[1],ARGV[2]}\u0026#34; 2 key1 one two 1) \u0026#34;key1\u0026#34; 2) \u0026#34;two\u0026#34; 再看一个通过lua脚本传参的例子：\n新建一个lua脚本KeysAndArgs.lua文件，代码如下：\n1 2 3 redis.call(\u0026#39;set\u0026#39;,\u0026#39;val\u0026#39;,KEYS[1]) redis.call(\u0026#39;set\u0026#39;,\u0026#39;argv\u0026#39;,ARGV[1]) return ARGV[2]; 在redis命令行中执行：\n1 2 3 4 root@c9900020aba5:/data# redis-cli --eval /luaScript/KeysAndArgv.lua 1 2 3 (error) ERR Lua redis lib command arguments must be strings or integers script: 3d8e39570f8dcd82458229647a72152f68fd74b7, on @user_script:2. # 报错的原因是：脚本的第二行有错误，因为redis的命令传参只能使用KEYS，而不能用ARGV。 修正lua脚本再次执行：\n1 2 3 redis.call(\u0026#39;set\u0026#39;,\u0026#39;val\u0026#39;,KEYS[1]); redis.call(\u0026#39;set\u0026#39;,\u0026#39;argv\u0026#39;,KEYS[2]); return {KEYS[1],ARGV[1]}; 执行lua脚本：\n1 2 3 4 5 6 7 8 # 这里有个坑人的地方，就是keys和argv的参数必须通过逗号隔开，而且每个传递的参数直接必须有空格，这一点格外注意 root@c9900020aba5:/data# redis-cli --eval /luaScript/KeysAndArgv.lua 1 2,3 1) \u0026#34;1\u0026#34; root@c9900020aba5:/data# redis-cli --eval /luaScript/KeysAndArgv.lua 1 2, 3 1) \u0026#34;1\u0026#34; root@c9900020aba5:/data# redis-cli --eval /luaScript/KeysAndArgv.lua 1 2 , 3 1) \u0026#34;1\u0026#34; 2) \u0026#34;3\u0026#34; 在脚本中引入分支语句 新建一个IfDemo.lua的脚本：\n1 2 3 4 5 6 -- 注意语法，if then else end关键字 if redis.call(\u0026#34;exists\u0026#34;,\u0026#34;Name\u0026#34;)==1 then return \u0026#34;Existed\u0026#34; else return \u0026#34;No Name\u0026#34; end 执行bash脚本\n1 2 3 4 5 6 7 8 root@c9900020aba5:/data# redis-cli --eval /luaScript/IfDemo.lua \u0026#34;No Name\u0026#34; root@c9900020aba5:/data# redis-cli 127.0.0.1:6379\u0026gt; set Name FARB OK 127.0.0.1:6379\u0026gt; exit root@c9900020aba5:/data# redis-cli --eval /luaScript/IfDemo.lua \u0026#34;Existed\u0026#34; 在脚本中引入循环语句 新建一个whileDemo.lua的脚本：\n1 2 3 4 5 6 7 8 local times=0 while(time\u0026lt;100) do -- 循环向redis中存1:1 到99：99的数据 redis.call(\u0026#34;set\u0026#34;,times,times) times++ end return \u0026#39;Success\u0026#39; 执行lua脚本：\n1 2 3 4 5 6 7 root@c9900020aba5:/data# redis-cli --eval /luaScript/WhileDemo.lua \u0026#34;Success\u0026#34; root@c9900020aba5:/data# redis-cli 127.0.0.1:6379\u0026gt; get 1 \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; get 99 \u0026#34;99\u0026#34; 在脚本中引入for循环语句 新建ForDemo.lua的脚本：\n1 2 3 4 5 -- 初始值i=0,结束值为100（不包括），步长为1 for i=0,100,1 do redis.call(\u0026#39;del\u0026#39;,i) end return \u0026#39;Success\u0026#39; 执行lua脚本：\n1 2 3 4 5 6 7 8 root@c9900020aba5:/data# redis-cli --eval /luaScript/ForDemo.lua \u0026#34;Success\u0026#34; root@c9900020aba5:/data# redis-cli # 可以看到，上面的循环已经把1到99的数据删除了 127.0.0.1:6379\u0026gt; get 1 (nil) 127.0.0.1:6379\u0026gt; get 99 (nil) 在Java程序中调用Redis脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class InvokeLua { /** * 主程序入口 * 本程序演示了如何使用Jedis客户端与Redis服务器交互，执行Lua脚本 * * @param args 命令行参数 * @throws Exception 如果与Redis服务器的连接或执行脚本时发生错误 */ public static void main(String[] args) throws Exception { // 连接Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); // 定义Lua脚本，该脚本将两个键分别设置为两个值，并返回第一个参数 String script = \u0026#34;redis.call(\u0026#39;set\u0026#39;,\u0026#39;k1\u0026#39;,KEYS[1]);redis.call(\u0026#39;set\u0026#39;,\u0026#39;k2\u0026#39;,KEYS[2]);return ARGV[1];\u0026#34;; // 执行Lua脚本，传递键值和参数 // 这里使用eval命令执行脚本，keys参数指定脚本中使用的键，argv参数指定脚本中的参数 String result = jedis.eval(script, List.of(\u0026#34;v1\u0026#34;, \u0026#34;v2\u0026#34;), List.of(\u0026#34;arg1\u0026#34;)).toString(); // 输出执行结果 arg1 System.out.println(result); } } 可以看到redis中也已经生效：\n1 2 3 4 127.0.0.1:6379\u0026gt; get k1 \u0026#34;v1\u0026#34; 127.0.0.1:6379\u0026gt; get k2 \u0026#34;v2\u0026#34; lua脚本有错，还会执行吗？ 经实验，redis.call()命令一旦发生错误，就会导致整个脚本的停止，已经执行的命令不会回滚。redis.pcall()命令执行报错时，会继续执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * LuaWithError 类用于演示在 Redis 中使用 Lua 脚本时的错误处理 * 该类通过 Jedis 客户端与 Redis 进行交互，并尝试执行一个包含错误的 Lua 脚本 */ public class LuaWithError { /** * 主函数执行一个包含错误的 Lua 脚本 * 该脚本试图在 Redis 中设置三个键值对，其中一个操作故意省略了值参数以引发错误 * * @param args 命令行参数，未使用 */ public static void main(String[] args) { // 创建 Jedis 实例，连接到本地 Redis 服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); // 定义一个包含错误的 Lua 脚本，故意在第二个 set 操作中省略了值参数 String script = \u0026#34;redis.call(\u0026#39;set\u0026#39;,\u0026#39;Name\u0026#39;,\u0026#39;Farb\u0026#39;);redis.call(\u0026#39;set\u0026#39;,\u0026#39;Error\u0026#39;);redis.call(\u0026#39;set\u0026#39;,\u0026#39;Next\u0026#39;,\u0026#39;Next\u0026#39;);\u0026#34;; // 执行 Lua 脚本并打印结果，预期会遇到错误 System.out.println(jedis.eval(script)); } } 报错信息如下：\n1 2 3 4 5 6 7 8 9 10 Exception in thread \u0026#34;main\u0026#34; redis.clients.jedis.exceptions.JedisDataException: ERR Wrong number of args calling Redis command from script script: b9b88af25b4f44f74fda6dc5189e405306db5a5f, on @user_script:1. at redis.clients.jedis.Protocol.processError(Protocol.java:132) at redis.clients.jedis.Protocol.process(Protocol.java:166) at redis.clients.jedis.Protocol.read(Protocol.java:220) at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:278) at redis.clients.jedis.Connection.getOne(Connection.java:256) at redis.clients.jedis.Jedis.getEvalResult(Jedis.java:2883) at redis.clients.jedis.Jedis.eval(Jedis.java:2861) at redis.clients.jedis.Jedis.eval(Jedis.java:2874) at chapter11.LuaWithError.main(LuaWithError.java:22) 1 2 3 4 5 # 可以看到，redis.call()命令执行时，已经执行了第一个set操作，但是第二个set操作执行时出错，导致整个脚本的停止。 127.0.0.1:6379\u0026gt; get Name \u0026#34;Farb\u0026#34; 127.0.0.1:6379\u0026gt; get Next (nil) 将上面代码中的redis.call改为redis.pcall()，可以避免脚本停止运行。程序没有抛出异常，打印返回nil\n1 2 3 4 5 6 7 8 public static void main(String[] args) { // 创建 Jedis 实例，连接到本地 Redis 服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); // 定义一个包含错误的 Lua 脚本，故意在第二个 set 操作中省略了值参数 String script = \u0026#34;redis.pcall(\u0026#39;set\u0026#39;,\u0026#39;Name\u0026#39;,\u0026#39;Farb\u0026#39;);redis.pcall(\u0026#39;set\u0026#39;,\u0026#39;Error\u0026#39;);redis.pcall(\u0026#39;set\u0026#39;,\u0026#39;Next\u0026#39;,\u0026#39;Next\u0026#39;);\u0026#34;; // 执行 Lua 脚本并打印结果，预期会遇到错误 System.out.println(jedis.eval(script, 0)); } 1 2 3 4 5 # 可以看到，redis.pcall()命令执行时，已经执行了第一个set操作，但是第二个set操作执行时出错，但是并没有导致整个脚本的停止，第三个set操作执行成功。 127.0.0.1:6379\u0026gt; get Name \u0026#34;Farb\u0026#34; 127.0.0.1:6379\u0026gt; Get Next \u0026#34;Next\u0026#34; Redis整合lua脚本实战 以计数模式实现限流效果 限流是指某应用模块需要限制指定IP（或指定模块、指定应用）在单位时间内的访问次数。\nlua脚本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- 从 KEYS 数组中获取模块名 local moduleName=KEYs[1] -- 将限流次数从字符串转换为数字 local limitCount=tonumber(ARGV[1]) -- 获取当前模块的计数，如果不存在则默认为0 local current=tonumber(redis.call(\u0026#39;get\u0026#39;,moduleName) or \u0026#34;0\u0026#34;) -- 检查当前计数是否超过了限流次数 if(current+1\u0026gt;limitCount) then -- 如果超过，则返回0表示操作失败 return 0 else -- 如果未超过，则增加模块的计数 redis.call(\u0026#39;incrby\u0026#39;,moduleName,1) -- 更新模块的过期时间 redis.call(\u0026#39;expire\u0026#39;,moduleName,tonumber(ARGV[2])) -- 返回增加后的计数 return current+1 end java代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 public class LimitByCount { /** * 判断是否可以访问 * 通过Redis和Lua脚本确保在限定时间内访问次数不超过限定次数 * * @param jedis Redis客户端，用于执行Redis命令 * @param moduleName 模块名称，用于在Redis中区分不同的模块 * @param limitTime 限定时间，单位为秒，在这个时间内访问次数不能超过limitNum * @param limitNum 限定次数，在limitTime内允许的最大访问次数 * @return 如果当前访问未超过限制，则返回true，否则返回false */ public static boolean canVisit(Jedis jedis, String moduleName, int limitTime, int limitNum) { // Lua脚本，用于在Redis中执行逻辑判断和数据更新 // 这段脚本的作用是检查和更新模块的访问次数，确保在限定时间内访问次数不超过限定次数 String luaScript = \u0026#34;local moduleName=KEYs[1]\\n\u0026#34; + \u0026#34;local limitCount=tonumber(ARGV[1])\\n\u0026#34; + \u0026#34;local current=tonumber(redis.call(\u0026#39;get\u0026#39;,moduleName) or \\\u0026#34;0\\\u0026#34;)\\n\u0026#34; + \u0026#34;if(current+1\u0026gt;limitCount) then\\n\u0026#34; + \u0026#34; return 0\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34; redis.call(\u0026#39;incrby\u0026#39;,moduleName,1)\\n\u0026#34; + \u0026#34; redis.call(\u0026#39;expire\u0026#39;,moduleName,tonumber(ARGV[2]))\\n\u0026#34; + \u0026#34; return current+1\\n\u0026#34; + \u0026#34;end\u0026#34;; // 执行Lua脚本，判断返回值,如果不为0，则表示可以访问 String result = jedis.eval(luaScript, 1, moduleName, String.valueOf(limitNum), String.valueOf(limitTime)).toString(); return !result.equals(\u0026#34;0\u0026#34;); } } /** * LuaLimitByCountThread 类继承自 Thread 类，用于演示如何通过 Redis 限流 * 它在每个线程中检查是否可以访问某个资源，基于计数的限流策略 */ public class LuaLimitByCountThread extends Thread { /** * 线程的入口点 * 它创建一个 Jedis 实例来与 Redis 通信，并循环检查当前线程是否可以访问资源 * @see Thread#run() */ @Override public void run() { // 创建 Jedis 实例，连接到本地 Redis 服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); // 循环 5 次，检查是否可以访问资源 for (int i = 0; i \u0026lt; 5; i++) { // 调用 LimitByCount 的 canVisit 方法，判断当前线程是否可以访问资源 boolean canVisit = LimitByCount.canVisit(jedis, Thread.currentThread().getName(), 10, 3); // 根据 canVisit 的结果，打印是否可以访问 if (canVisit) { System.out.println(Thread.currentThread().getName() + \u0026#34; can visit\u0026#34;); } else { System.out.println(Thread.currentThread().getName() + \u0026#34; can not visit\u0026#34;); } } } /** * 程序的入口点 * 它创建并启动多个 LuaLimitByCountThread 线程，以演示多线程环境下的限流效果 * @param args 命令行参数 */ public static void main(String[] args) { // 循环 3 次，创建并启动 3 个线程 for (int i = 0; i \u0026lt; 3; i++) { new LuaLimitByCountThread().start(); } } } 如预期，每个模块只允许10秒内被访问3次，超过次数的线程会被拒绝访问。运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Thread-1 can visit Thread-2 can visit Thread-0 can visit Thread-0 can visit Thread-2 can visit Thread-1 can visit Thread-0 can visit Thread-2 can visit Thread-1 can visit Thread-0 can not visit Thread-2 can not visit Thread-1 can not visit Thread-2 can not visit Thread-1 can not visit Thread-0 can not visit lua脚本防止超卖 超卖是指在某一时间段内，销售数量超过库存数量。\nlua脚本具有天然原子性，redis的读写是单线程的，所以使用lua脚本可以防止超卖。\nlua脚本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 -- 从 Redis 中获取指定键的当前值，并将其转换为数字 local left = tonumber(redis.call(\u0026#39;get\u0026#39;,KEYS[1]) or \u0026#39;0\u0026#39;) -- 检查当前值是否小于等于0 if(left\u0026lt;=0) then -- 如果值小于等于0，返回0 return 0 else -- 如果值大于0，将键的值减少1，并返回减少前的值 redis.call(\u0026#39;decrby\u0026#39;,KEYS[1],1) return left end java代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 /** * OverSellCheck 类用于检查是否可以购买商品，以防止过量销售 */ public class OverSellCheck { /** * 检查用户是否可以购买商品 * * @param jedis Redis 客户端实例，用于与 Redis 数据库交互 * @param goodsKey 商品键值 * @return boolean 表示是否可以购买商品，true 表示可以购买，false 表示不可以购买 */ public static boolean canBuy(Jedis jedis, String goodsKey) { // Lua 脚本用于原子操作，以防止并发条件下的超卖现象 String lua = \u0026#34;local left = tonumber(redis.call(\u0026#39;get\u0026#39;,KEYS[1]))\\n\u0026#34; + \u0026#34;if(left\u0026lt;=0) then\\n\u0026#34; + \u0026#34;\\treturn 0\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34; redis.call(\u0026#39;decrby\u0026#39;,KEYS[1],1)\\n\u0026#34; + \u0026#34;\\treturn left\\n\u0026#34; + \u0026#34;end\u0026#34;; // 执行 Lua 脚本，判断商品是否还可以购买 String result = jedis.eval(lua, 1, goodsKey).toString(); // 如果返回结果不为 \u0026#34;0\u0026#34;，则表示还可以购买商品 return !result.equals(\u0026#34;0\u0026#34;); } } /** * OverSellDemo 类用于演示在多线程环境下可能出现的超卖问题 * 它通过多个线程模拟高并发场景下的商品购买行为 */ public class OverSellDemo extends Thread { // 商品的键，用于在Redis中标识商品 private final static String GOODS_KEY = \u0026#34;goods:1\u0026#34;; /** * 程序的入口点 * 初始化商品库存，并启动多个线程模拟购买行为 * @param args 命令行参数 */ public static void main(String[] args) { // 连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); // 设置商品库存为5，过期时间为10秒 jedis.setex(GOODS_KEY, 10, \u0026#34;5\u0026#34;); // 启动10个线程模拟购买行为 for (int i = 0; i \u0026lt; 10; i++) { new OverSellDemo().start(); } } /** * 线程的运行方法 * 每个线程尝试购买商品，并打印购买结果 */ @Override public void run() { // 连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); // 检查当前是否可以购买商品 boolean canBuy = OverSellCheck.canBuy(jedis, GOODS_KEY); if (canBuy) { // 如果可以购买，打印线程名称和购买结果 System.out.println(Thread.currentThread().getName() + \u0026#34; can buy\u0026#34;); } else { // 如果不可以购买，打印线程名称和购买结果 System.out.println(Thread.currentThread().getName() + \u0026#34; can not buy\u0026#34;); } } } 可以看到，在多线程环境下，虽然有10个线程尝试购买商品，但只有5个线程可以购买成功，其余线程因为库存不足而被拒绝购买。 运行结果如下：\n1 2 3 4 5 6 7 8 9 10 Thread-2 can not buy Thread-7 can buy Thread-1 can buy Thread-9 can buy Thread-5 can not buy Thread-0 can not buy Thread-8 can not buy Thread-3 can buy Thread-6 can not buy Thread-4 can buy ","date":"2024-11-05T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_11_lua/","title":"基于Docker的Redis实战-Redis整合Lua脚本"},{"content":"1. docker: Error response from daemon: Ports are not available 1 2 3 D:\\DevTools\\java\\Mycat-Server-1.6.76-release-2020-11-2\\target\u0026gt;docker run --name mycat -p 8066:8066 -p 9066:9066 -v /usr/local/mycat/conf/:/usr/local/mycat/conf/ -v /usr/local/mycat/logs/:/usr/local/mycat/logs/ -d mycat:1.6.7.6 0d1c9dad51d7147e31ec0fdf42480bd5bf2c0d798507ee20f41b130184ff9a66 docker: Error response from daemon: Ports are not available: exposing port TCP 0.0.0.0:8066 -\u0026gt; 0.0.0.0:0: listen tcp 0.0.0.0:8066: bind: An attempt was made to access a socket in a way forbidden by its access permissions. 解决方法：使用netstat -aon | findstr 查看并没有占用\n1 2 3 4 5 # 使用管理员权限打开cmd net stop winnat net start winnat # 然后重新创建并运行容器即可 ","date":"2024-09-08T00:00:00Z","permalink":"https://farb.github.io/p/docker_error_notes/","title":"Docker报错记录集"},{"content":"1. [Warning] World-writable config file \u0026lsquo;/etc/mysql/conf.d/my.cnf\u0026rsquo; is ignored. 警告任何用户都可以修改配置文件，太不安全，所以Mysql把这个配置文件忽略了。 文件权限太高，需要降低文件权限。本错误是在docker容器中出现的，所以需要进入docke容器中执行以下命令。\n1 2 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it myMasterMysql bash bash-5.1# chmod 644 /etc/mysql/conf.d/my.cnf 2. mysql\u0026gt; show master status; 命令报错语法错误 报错如下：\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026lsquo;master status\u0026rsquo; at line 1\n困扰了很久，最终找到了原因，是mysql版本问题，我使用的是mysql 8.4，show master status;已经被废弃，使用SHOW BINARY LOG STATUS;代替 具体查看官方说明，https://dev.mysql.com/doc/refman/8.4/en/show-master-status.html\n3. mysql\u0026gt; change master to master_host=\u0026lsquo;172.17.0.2\u0026rsquo;,master_port=3306,master_user=\u0026lsquo;root\u0026rsquo;,master_password=\u0026lsquo;123456\u0026rsquo;,master_log_pos=158,master_log_file=\u0026lsquo;mysql-master-bin.000002\u0026rsquo;; 设置主从关系时报语法错误 错误提示如下：\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026lsquo;master to master_host=\u0026lsquo;172.17.0.2\u0026rsquo;,master_port=3306,master_user=\u0026lsquo;root\u0026rsquo;,master_pa\u0026rsquo; at line 1\n经查阅，也是版本问题，change master to已经在MySql8中被CHANGE REPLICATION SOURCE TO取代，https://dev.mysql.com/doc/refman/8.4/en/replication-howto-slaveinit.html。\n4. (HTTP code 500) server error - Ports are not available: exposing port TCP 0.0.0.0:3316 -\u0026gt; 0.0.0.0:0: listen tcp 0.0.0.0:3316: bind: An attempt was made to access a socket in a way forbidden by its access permissions. 5. Public Key Retrieval is not allowed 使用数据库客户端DBeaver连接mysql时，报错如下：Public Key Retrieval is not allowed。\n“Public Key Retrieval is not allowed” 错误是由于 MySQL 连接驱动程序的默认行为更改所引起的。在 MySQL 8.0 版本及更新版本中，默认情况下禁用了通过公钥检索用户密码的功能。\n在旧版本的 MySQL 中，客户端连接到服务器时，可以使用公钥来检索用户密码。这种机制称为 “public key retrieval”，它允许客户端使用公钥来解密在服务器端加密的密码。\n然而，为了提高安全性，MySQL 开发团队在较新的版本中禁用了这个功能。禁用公钥检索可以防止恶意用户通过获取公钥来获取用户密码。相反，客户端必须使用其他安全的方法来进行身份验证，例如使用预共享密钥或使用 SSL/TLS 连接。\n解决方式1. 修改DBeaver中的驱动属性的参数为allowPublicKeyRetrieval=true 参考https://blog.csdn.net/qq_33472553/article/details/139107958：。但是这种方式会导致主从模式的数据库集群同步失败，报错见第6点，也即是认证需要安全连接。\n6. 从数据库没有同步主数据库的数据，通过show replica status\\G发现报错： Last_IO_Error: Error connecting to source \u0026lsquo;root@172.17.0.2:3306\u0026rsquo;. This was attempt 10/10, with a delay of 60 seconds between attempts. Message: Authentication plugin \u0026lsquo;caching_sha2_password\u0026rsquo; reported error: Authentication requires secure connection. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 停止从节点 mysql\u0026gt; stop replica; Query OK, 0 rows affected (0.00 sec) # 重置从库配置 mysql\u0026gt; reset replica all; Query OK, 0 rows affected (0.02 sec) # 重新配置主从配置关系，主要是最后一句GET_SOURCE_PUBLIC_KEY=1 mysql\u0026gt; CHANGE REPLICATION SOURCE TO SOURCE_host=\u0026#39;172.17.0.2\u0026#39;,SOURCE_port=3306,SOURCE_user=\u0026#39;root\u0026#39;,SOURCE_password=\u0026#39;123456\u0026#39;,SOURCE_log_pos=158,SOURCE_log_file=\u0026#39;mysql-master-bin.000004\u0026#39;,GET_SOURCE_PUBLIC_KEY=1; Query OK, 0 rows affected, 2 warnings (0.04 sec) # 启动从节点 mysql\u0026gt; start replica; Query OK, 0 rows affected (0.01 sec) # 再次查看从节点状态，发现没有错误了 mysql\u0026gt; show replica status\\G; *************************** 1. row *************************** Replica_IO_State: Waiting for source to send event Source_Host: 172.17.0.2 Source_User: root Source_Port: 3306 Connect_Retry: 60 Source_Log_File: mysql-master-bin.000004 Read_Source_Log_Pos: 158 Relay_Log_File: 0f827dad7de8-relay-bin.000002 Relay_Log_Pos: 335 Relay_Source_Log_File: mysql-master-bin.000004 Replica_IO_Running: Yes Replica_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Source_Log_Pos: 158 Relay_Log_Space: 553 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Source_SSL_Allowed: No Seconds_Behind_Source: 0 Source_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Source_Server_Id: 1 Source_UUID: 8e3f2ec2-5fbf-11ef-a070-0242ac110002 Source_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Replica_SQL_Running_State: Replica has read all relay log; waiting for more updates Source_Retry_Count: 10 7. MySql主从集群，从服务器同步报错: Coordinator stopped because there were error(s) in the worker(s). The most recent failure being: Worker 1 failed executing transaction \u0026lsquo;ANONYMOUS\u0026rsquo; at source log mysql-master-bin.000004, end_log_pos 35 当前我的分析及解决步骤如下：\n查看从节点的日志文件，发现报错信息如下： 1 2 2024-08-27 22:46:06 2024-08-27T14:46:06.499064Z 7 [ERROR] [MY-010584] [Repl] Replica SQL for channel \u0026#39;\u0026#39;: Worker 1 failed executing transaction \u0026#39;ANONYMOUS\u0026#39; at source log mysql-master-bin.000004, end_log_pos 354; Error \u0026#39;Can\u0026#39;t drop database \u0026#39;redisdemo\u0026#39;; database doesn\u0026#39;t exist\u0026#39; on query. Default database: \u0026#39;redisdemo\u0026#39;. Query: \u0026#39;drop database redisDemo\u0026#39;, Error_code: MY-001008 2024-08-27 22:46:06 2024-08-27T14:46:06.499234Z 6 [ERROR] [MY-010586] [Repl] Error running query, replica SQL thread aborted. Fix the problem, and restart the replica SQL thread with \u0026#34;START REPLICA\u0026#34;. We stopped at log \u0026#39;mysql-master-bin.000004\u0026#39; position 158 观察到报错信息，发现报错信息提示，删除数据库数据库不存在。因为第一次实践时，创建数据库redisDemo时没有同步成功，所以在主节点执行了drop database redisDemo。 为了保持数据操作同步，需要将之前创建的语句手动在从节点执行一下create database redisDemo;。 创建数据库之后，stop replica;关闭主从同步，然后再start replica;开启主从同步，即可解决从节点同步报错的问题。show replica status\\G;查看从节点正常。 8. ERROR 1872 (HY000): Replica failed to initialize applier metadata structure from the repository 解决办法： 参考：https://blog.csdn.net/m0_66011019/article/details/136429224\n1 2 mysql\u0026gt; reset replica; Query OK, 0 rows affected (0.04 sec) ","date":"2024-08-21T00:00:00Z","permalink":"https://farb.github.io/p/mysql_error_notes/","title":"MySql报错记录集"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code\nRedis整合MySql主从集群 用docker搭建MySql一主一从集群 在主Mysql服务器的操作会自动同步到从Mysql服务器，比如插入数据，删除数据，更新数据和新建数据库等都会同步到从服务器，通过这种同步的动作，主从服务器之间可以保持数据一致性。 一般项目都是向主服务器写数据，从“从服务器”读数据，这种读写分离的方式可以提升数据库的性能。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 拉取镜像 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker pull mysql # 本机中新建mysql的配置文件 D:\\ArchitectPracticer\\Redis\\MySql\\MasterMySql\\conf\\my.cnf ，内容如下： [mysqld] pid-file=/var/run/mysqld/mysqld.pid socket=/var/run/mysqld/mysqld.sock datadir=/var/lib/mysql server-id=1 # 主服务器的id，这个id不能重复 log-bin=mysql-master-bin # 启动主服务器，设置环境变量，MYSQL_ROOT_PASSWORD为root用户的密码，同时挂载配置文件目录和数据目录 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name myMasterMysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v D:\\ArchitectPracticer\\Redis\\MySql\\MasterMySql\\conf:/etc/mysql/conf.d -v D:\\ArchitectPracticer\\Redis\\MySql\\MasterMySql\\data:/var/lib/mysql mysql 7b1067615f0d6a663d38d1191544d3d4d394bc5768bb37a25109b7073cd5e06b # 查看运行的容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7b1067615f0d mysql \u0026#34;docker-entrypoint.s…\u0026#34; About a minute ago Up About a minute 0.0.0.0:3306-\u0026gt;3306/tcp, 33060/tcp myMasterMysql # 获取主服务器的IP地址 D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect myMasterMysql -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; 172.17.0.2 # 登录主服务器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it myMasterMysql bash bash-5.1# mysql -u root -p # 这句告警说明配置文件没有生效，需要手动在容器中修改权限， bash-5.1# chmod 644 /etc/mysql/conf.d/my.cnf mysql: [Warning] World-writable config file \u0026#39;/etc/mysql/conf.d/my.cnf\u0026#39; is ignored. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. # 查看主服务器的bin log, 主要关注前2列，主从集群同步所用到的日志文件名和当前同步的位置。 # 注意：show master status;已经被废弃，使用SHOW BINARY LOG STATUS;代替 mysql\u0026gt; SHOW BINARY LOG STATUS; +-------------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------------+----------+--------------+------------------+-------------------+ | mysql-master-bin.000002 | 158 | | | | +-------------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 新开一个命令行窗口继续设置从服务器：\n1 2 3 4 5 6 7 # mysql从服务器的配置文件如下 [mysqld] pid-file=/var/run/mysqld/mysqld.pid socket=/var/run/mysqld/mysqld.sock datadir=/var/lib/mysql server-id=2 # 从服务器的id，这个id不能和主服务器的一致 log-bin=mysql-slave-bin # 二进制文件的名字 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 # 启动从服务器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name mySlaveMysql -p 3316:3306 -e MYSQL_ROOT_PASSWORD=123456 -v D:\\ArchitectPracticer\\Redis\\MySql\\SlaveMySql\\conf:/etc/mysql/conf.d -v D:\\ArchitectPracticer\\Redis\\MySql\\SlaveMySql\\data:/var/lib/mysql mysql PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it mySlaveMysql /bin/bash # 确认可以在从服务器的容器中连接到主服务器 bash-5.1# mysql -h 172.17.0.2 -u root -p mysql: [Warning] World-writable config file \u0026#39;/etc/mysql/conf.d/my.cnf\u0026#39; is ignored. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 18 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. # exit退出主服务器的连接 mysql\u0026gt; exit Bye # 连接到从服务器 bash-5.1# mysql -h localhost -u root -p mysql: [Warning] World-writable config file \u0026#39;/etc/mysql/conf.d/my.cnf\u0026#39; is ignored. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 11 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. # 配置主从关系，这里注意`change master to`已经在MySql8中被`CHANGE REPLICATION SOURCE TO`取代。每个字段的意思很明显，主要是`SOURCE_log_pos`和`SOURCE_log_file`要和上面`show binary log status;`的结果一致。` mysql\u0026gt; CHANGE REPLICATION SOURCE TO SOURCE_host=\u0026#39;172.17.0.2\u0026#39;,SOURCE_port=3306,SOURCE_user=\u0026#39;root\u0026#39;,SOURCE_password=\u0026#39;123456\u0026#39;,SOURCE_log_pos=158,SOURCE_log_file=\u0026#39;mysql-master-bin.000002\u0026#39;; Query OK, 0 rows affected, 2 warnings (0.04 sec) # start slave;也变成了start replica; 详见 https://dev.mysql.com/doc/refman/8.4/en/start-replica.html mysql\u0026gt; start replica; Query OK, 0 rows affected (0.01 sec) # 启动主从复制 mysql\u0026gt; start replica; Query OK, 0 rows affected (0.01 sec) # 查看主从复制状态，命令结尾符\\G是以垂直列表的形式显示。看到Replica_IO_Running: Yes 和 Replica_SQL_Running: Yes，说明配置主从复制成功 mysql\u0026gt; show replica status\\G; *************************** 1. row *************************** Replica_IO_State: Waiting for source to send event Source_Host: 172.17.0.2 Source_User: root Source_Port: 3306 Connect_Retry: 60 Source_Log_File: mysql-master-bin.000002 Read_Source_Log_Pos: 158 Relay_Log_File: 0f827dad7de8-relay-bin.000003 Relay_Log_Pos: 335 Relay_Source_Log_File: mysql-master-bin.000002 Replica_IO_Running: Yes Replica_SQL_Running: Yes ... 省略一部分输出 1 row in set (0.00 sec) ERROR: No query specified # 回到主服务器，创建数据库 mysql\u0026gt; create database MasterSlaveDemo; Query OK, 1 row affected (0.00 sec) # 可以看到主服务器中有新建的数据库MasterSlaveDemo mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | MasterSlaveDemo | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.00 sec) # 再去从服务器中查看，检查是否同步成功，结果发现同步成功 mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | MasterSlaveDemo | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.00 sec) 准备数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 创建数据库 mysql\u0026gt; create database redisDemo; Query OK, 1 row affected (0.01 sec) # 切换到数据库 mysql\u0026gt; use redisDemo; Database changed # 创建表 mysql\u0026gt; create table student ( -\u0026gt; id int not null primary key auto_increment, -\u0026gt; name varchar(20), -\u0026gt; age int, -\u0026gt; score float -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) # 插入数据 mysql\u0026gt; insert into student (name,age,score) values(\u0026#39;Peter\u0026#39;,18,100); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert into student (name,age,score) values(\u0026#39;Tom\u0026#39;,17,98),(\u0026#39;John\u0026#39;,17,99); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; insert into student(name,age,score) values(\u0026#39;farb\u0026#39;,26,96); Query OK, 1 row affected (0.01 sec) 创建java项目，用java读写mysql集群和redis 向主数据库写数据，这些数据会自动同步到从数据库。 读数据时，先从redis中读，可以提升性能。如果redis中没有，再从从数据库中读，最后再写redis。 读写分离方式也可以提升性能。\n确保pom.xml中添加了redis和mysql的依赖 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 高并发的场景里，至少会用到MySql的主从复制集群，无论是性能还是可用性都比单机版MySql好。在此基础上再引入Redis作为缓存服务器，能进一步提升数据库服务的性能。 Java代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 public class MySqlClusterDemo { PreparedStatement masterPreparedStatement; PreparedStatement slavePreparedStatement; private Jedis jedis; private Connection masterConnection; private Connection slaveConnection; /** * 程序入口 * @param args 命令行参数 */ public static void main(String[] args) { // 创建示例对象 MySqlClusterDemo demo = new MySqlClusterDemo(); // 初始化数据库连接 demo.init(); // 插入示例数据 demo.insert(); // 场景1：从数据库查询ID为1的名称并打印 System.out.println(demo.getNameById(1)); // 场景2：从redis缓存再次查询并打印，用于验证数据一致性 System.out.println(demo.getNameById(1)); } /** * 初始化数据库和Redis连接 * 该方法在类初始化时调用，负责建立到MySQL主从数据库的连接以及到Redis服务器的连接 */ private void init() { // MySQL主库连接URL String mysqlMasterUrl = \u0026#34;jdbc:mysql://127.0.0.1:3306/redisDemo\u0026#34;; // MySQL从库连接URL String mysqlSlaveUrl = \u0026#34;jdbc:mysql://127.0.0.1:3316/redisDemo\u0026#34;; // 数据库用户名 String user = \u0026#34;root\u0026#34;; // 数据库密码 String password = \u0026#34;123456\u0026#34;; try { // 建立到MySQL主库的连接 masterConnection = DriverManager.getConnection(mysqlMasterUrl, user, password); // 建立到MySQL从库的连接 slaveConnection = DriverManager.getConnection(mysqlSlaveUrl, user, password); } catch (SQLException e) { // 如果发生SQL异常，则抛出运行时异常 throw new RuntimeException(e); } // 建立到Redis服务器的连接 jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); } /** * 插入学生数据的方法 * 该方法用于向学生表中插入一条新的学生记录，包括姓名、年龄和分数 * 由于数据库操作可能存在异常，故在此方法中进行了异常捕获和处理 */ private void insert() { try { // 准备插入语句，将预设的学生数据插入到主数据库中 masterPreparedStatement = masterConnection.prepareStatement(\u0026#34;insert into student(name,age,score) values (\u0026#39;Frank\u0026#39;,18,95)\u0026#34;); // 执行插入操作 masterPreparedStatement.executeUpdate(); } catch (SQLException e) { // 捕获SQL异常，避免程序因未处理的异常而中断 throw new RuntimeException(e); } } /** * 根据学生ID获取学生姓名 * 首先检查Redis中是否存在该数据，如果存在，则直接返回，以提高查询效率 * 如果Redis中不存在，则从数据库中查询，并将结果存储到Redis中，以便后续查询 * * @param id 学生ID * @return 学生姓名，如果找不到则返回空字符串 */ private String getNameById(int id) { // 构造Redis的键 String key = \u0026#34;student:\u0026#34; + id; // 初始化姓名为空字符串 String name = \u0026#34;\u0026#34;; // 检查Redis中是否存在该键 if (jedis.exists(key)) { // 如果存在，则打印消息并从Redis中获取姓名 System.out.println(\u0026#34;从redis中获取数据:id=\u0026#34; + id + \u0026#34;存在于数据库\u0026#34;); name = jedis.get(key); // 打印获取到的姓名 System.out.println(\u0026#34;Name is \u0026#34; + name); // 返回获取到的姓名 return name; } // 尝试从数据库中获取姓名 try { // 准备数据库查询语句 slavePreparedStatement = slaveConnection.prepareStatement(\u0026#34;select name from student where id = ?\u0026#34;); // 设置查询参数为学生ID slavePreparedStatement.setInt(1, id); // 执行查询并获取结果集 ResultSet resultSet = slavePreparedStatement.executeQuery(); // 如果结果集中有数据 if (resultSet.next()) { // 获取姓名 name = resultSet.getString(\u0026#34;name\u0026#34;); // 打印从数据库中获取数据的消息 System.out.println(\u0026#34;从数据库中获取数据:id=\u0026#34; + id + \u0026#34;存在于数据库\u0026#34;); } // 将姓名存储到Redis中,并设置300s过期时间，如果没有找到数据，缓存为空值，防止缓存穿透 SetParams params = SetParams.setParams().ex(300); jedis.set(key, name, params); // 返回获取到的姓名 return name; } catch (SQLException e) { // 如果发生SQL异常，则抛出运行时异常 throw new RuntimeException(e); } } } mysql主从集群整合redis主从集群 搭建一主一从的mysql集群，一主一从的Redis集群，如下图： 主从模式的MySQL集群上面已经配置，接下来重新复习一下配置一主一从的Redis集群，最终配置一览表如下：\ndocker容器名 IP地址和端口 说明 myMasterMysql 127.0.0.1:3306 MySQL主节点 mySlaveMysql 127.0.0.1:3316 MySQL从节点 redis-master 127.0.0.1:6379 Redis主节点 redis-slave 127.0.0.1:6380 Redis从节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 启动redis主服务器容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-master -p 6379:6379 redis 7766df2403d2da7852380710245441da684a5aa19b040995dbd1606e78b6855f # 启动redis从服务器容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-slave -p 6380:6379 redis 9ee23465b5a829d440821014d30998b2b4d76cd10e10d0a01bcfd8081bd5d626 # 获取redis主服务器的IP地址 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; redis-master 172.17.0.4 # 配置redis从服务器为从节点 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-slave bash root@9ee23465b5a8:/data# redis-cli -h localhost -p 6379 # 这里为了方便，通过命令slaveof设置redis从服务器为从节点 localhost:6379\u0026gt; slaveof 172.17.0.4 6379 OK # 查看主从关系状态正常 localhost:6379\u0026gt; info replication # Replication role:slave master_host:172.17.0.4 master_port:6379 master_link_status:up java代码改进点： 读取数据时，优先从“从redis缓存”中读取； 从数据库查询到数据后，将数据写入“主Redis缓存”中，通过redis的主从复制自动同步到从Redis中； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 public class MySqlClusterDemoV2 { // 主mysql预编译sql语句对象 PreparedStatement masterPreparedStatement; // 从mysql预编译sql语句对象 PreparedStatement slavePreparedStatement; // 主Redis客户端对象 private Jedis masterJedis; // 从Redis客户端对象 private Jedis slaveJedis; // 主数据库连接对象 private Connection masterConnection; // 从数据库连接对象 private Connection slaveConnection; /** * 程序入口 * * @param args 命令行参数 */ public static void main(String[] args) { // 创建示例对象 MySqlClusterDemoV2 demo = new MySqlClusterDemoV2(); // 初始化数据库连接 demo.init(); // 插入示例数据 demo.insert(); // 场景1：从数据库查询ID为1的名称并打印 System.out.println(demo.getNameById(1)); // 场景2：从redis缓存再次查询并打印，用于验证数据一致性 System.out.println(demo.getNameById(1)); } /** * 初始化数据库和Redis连接 * 该方法在类初始化时调用，负责建立到MySQL主从数据库的连接以及到Redis服务器的连接 */ private void init() { // MySQL主库连接URL String mysqlMasterUrl = \u0026#34;jdbc:mysql://127.0.0.1:3306/redisDemo\u0026#34;; // MySQL从库连接URL String mysqlSlaveUrl = \u0026#34;jdbc:mysql://127.0.0.1:3316/redisDemo\u0026#34;; // 数据库用户名 String user = \u0026#34;root\u0026#34;; // 数据库密码 String password = \u0026#34;123456\u0026#34;; try { // 建立到MySQL主库的连接 masterConnection = DriverManager.getConnection(mysqlMasterUrl, user, password); // 建立到MySQL从库的连接 slaveConnection = DriverManager.getConnection(mysqlSlaveUrl, user, password); } catch (SQLException e) { // 如果发生SQL异常，则抛出运行时异常 throw new RuntimeException(e); } // 建立到主Redis服务器的连接 masterJedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); // 建立到从Redis服务器的连接 slaveJedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6380); } /** * 插入学生数据的方法 * 该方法用于向学生表中插入一条新的学生记录，包括姓名、年龄和分数 * 由于数据库操作可能存在异常，故在此方法中进行了异常捕获和处理 */ private void insert() { try { // 准备插入语句，将预设的学生数据插入到主数据库中 masterPreparedStatement = masterConnection.prepareStatement(\u0026#34;insert into student(name,age,score) values (\u0026#39;Frank\u0026#39;,18,95)\u0026#34;); // 执行插入操作 masterPreparedStatement.executeUpdate(); } catch (SQLException e) { // 捕获SQL异常，避免程序因未处理的异常而中断 throw new RuntimeException(e); } } /** * 根据学生ID获取学生姓名 * 首先检查Redis中是否存在该数据，如果存在，则直接返回，以提高查询效率 * 如果Redis中不存在，则从数据库中查询，并将结果存储到Redis中，以便后续查询 * * @param id 学生ID * @return 学生姓名，如果找不到则返回空字符串 */ private String getNameById(int id) { // 构造Redis的键 String key = \u0026#34;student:\u0026#34; + id; // 初始化姓名为空字符串 String name = \u0026#34;\u0026#34;; // 检查Redis中是否存在该键 if (slaveJedis.exists(key)) { // 如果存在，则打印消息并从Redis中获取姓名 System.out.println(\u0026#34;从redis中获取数据:id=\u0026#34; + id + \u0026#34;存在于数据库\u0026#34;); name = slaveJedis.get(key); // 打印获取到的姓名 System.out.println(\u0026#34;Name is \u0026#34; + name); // 返回获取到的姓名 return name; } // 尝试从数据库中获取姓名 try { // 准备数据库查询语句 slavePreparedStatement = slaveConnection.prepareStatement(\u0026#34;select name from student where id = ?\u0026#34;); // 设置查询参数为学生ID slavePreparedStatement.setInt(1, id); // 执行查询并获取结果集 ResultSet resultSet = slavePreparedStatement.executeQuery(); // 如果结果集中有数据 if (resultSet.next()) { // 获取姓名 name = resultSet.getString(\u0026#34;name\u0026#34;); // 打印从数据库中获取数据的消息 System.out.println(\u0026#34;从数据库中获取数据:id=\u0026#34; + id + \u0026#34;存在于数据库\u0026#34;); } // 将姓名存储到Redis中,并设置300s过期时间，如果没有找到数据，缓存为空值，防止缓存穿透 SetParams params = SetParams.setParams().ex(300); masterJedis.set(key, name, params); // 返回获取到的姓名 return name; } catch (SQLException e) { // 如果发生SQL异常，则抛出运行时异常 throw new RuntimeException(e); } } } MyCAT不维护了，建议不要使用了，不过可以看下它的原理。建议直接使用分布式数据库TiDB Redis整合MySql和MyCat分库组件 MyCAT是一个开源的分布式数据库组件，一般用它实现对数据库的分库分表功能，从而提升对数据库（尤其是大数据库表）的访问性能。 MyCAT官方文档\n分库分表概述 假设一电商系统业务量非常大，流水表（假设主键id）可能达到“亿”级规模，甚至更大。如果需要查询数据，即使使用索引等数据库优化的手段，也会成为性能上的瓶颈。此时可以考虑如下思路。\n在不同的10个数据库中，同时创建10张流水表，这些表的结构完全一致。 在1号数据库中只存放id%10=1的数据，比如存放id=1、11、21等的数据，2号数据库存放id%10=2的数据，以此类推。 这样就将一个大的流水表分成10张子表，而MyCAT组件能把应用程序对流水表的请求分散到这10张子表上，实际业务中子表的个数可以根据业务需求来定。由于把大表的数据分散到若干子表中，因此每次请求所面对的数据总量有效降低，从而能感受到“分表”对提升数据库访问性能的帮助。实际项目中，尽量将子表分散创建到不同的机器上，这样子表之间就具有更高的并发能力，不推荐在同一台机器上的同一个数据库进行分表操作。\n基于成本的考虑，或许无法为每个子表分配一台机器，但可以将不同的子表分散地创建在同一主机不同的数据库上，因而得出下面结论。\n子表创建在不同的机器上的性能 \u0026gt; 子表创建在同一台机器上的不同数据库的性能 \u0026gt; 子表创建在同一台机器上的同一个数据库的性能\n用MyCAT组件实现分库分表 MyCAT组件默认工作在8066端口，Java程序不是直接和MySQL等数据库直连，而是和MyCAT组件交互，再由MyCAT组件和数据库交互，MyCAT根据配置好的分库分表规则把请求发送到对应的数据库上，得到请求再返回给应用程序。\n为了实现分库分表效果，一般需要配置MyCAT组件的三个文件。\n文件名 说明 server.xml MyCAT组件的配置文件，一般用于配置MyCAT组件的端口号、用户名和密码、编码、字符集等 schema.xml MyCAT组件的分库分表配置文件，一般用于配置各分库的连接信息 rule.xml MyCAT规则配置文件，一般用于配置分库分表规则 server.xml配置如下： 配置了MyCAT组件的工作端口8066和管理端口9066，配置连接到MyCAT组件的用户名和密码，这里是MyCAT的用户名密码和数据库，而不是MySQL的，实践过程中一般和MySQL保持一致。 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:server SYSTEM \u0026#34;server.dtd\u0026#34;\u0026gt; \u0026lt;mycat:server xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;system\u0026gt; \u0026lt;property name=\u0026#34;serverPort\u0026#34;\u0026gt;8066\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;managePort\u0026#34;\u0026gt;9066\u0026lt;/property\u0026gt; \u0026lt;/system\u0026gt; \u0026lt;user name=\u0026#34;root\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;redisDemo\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;/mycat:server\u0026gt; schema.xml配置如下： 定义了redisDemo数据库的student表，按照mod-long规则分布到dn1,dn2,dn3这3个数据节点上,然后给出了dn1,dn2,dn3这3个数据节点的定义，分别指向host1,host2,host3这3个MySQL数据库。随后又定义了host1,host2,host3。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;redisDemo\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;student\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;host1\u0026#34; database=\u0026#34;redisDemo\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;host2\u0026#34; database=\u0026#34;redisDemo\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;host3\u0026#34; database=\u0026#34;redisDemo\u0026#34; /\u0026gt; \u0026lt;dataHost name=\u0026#34;host1\u0026#34; maxCon=\u0026#34;100\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;hostM1\u0026#34; url=\u0026#34;172.17.0.2:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;host2\u0026#34; maxCon=\u0026#34;100\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;hostM2\u0026#34; url=\u0026#34;172.17.0.3:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;host3\u0026#34; maxCon=\u0026#34;100\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;hostM3\u0026#34; url=\u0026#34;172.17.0.4:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; rule.xml配置如下： 定义mod-long规则，用于将id字段按照模3规则分配到dn1,dn2,dn3这3个数据节点上。 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;tableRule name=\u0026#34;mod-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;mod-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMod\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34; value=\u0026#34;3\u0026#34; /\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 综上，给出如下针对分库分表相关动作的定义：\n应用程序如果要使用MyCAT,就需要用户名root和密码123456连接到MyCAT组件。 假设要插入id为1的student的数据，根据schema.xml配置，会先根据mod-long规则对id进行模3处理，结果是1，所以会插入到host2所定义的172.17.0.3:3306的数据库的student表，如果要进行读取、删除和修改，就会先对id模3，再把请求发送到对应的数据库上。 Java、MySQL和MyCAT组件的整合 使用上面的配置文件，继续实践\n通过三个命令，准备三个包含mysql的docke容器： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd -p 3306:3306 --name mysqlHost1 -e MYSQL_ROOT_PASSWORD=123456 mysql 8f4d6474e3e45aca4d037b696a8a0d3bf98c620e3222681c06c4f0e5951c8a4a PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd -p 3316:3306 --name mysqlHost2 -e MYSQL_ROOT_PASSWORD=123456 mysql e0b0a0691740cc8f6959ff16f0cc54306519fe63c32b6393d33a0d999b19cb41 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd -p 3326:3306 --name mysqlHost3 -e MYSQL_ROOT_PASSWORD=123456 mysql f18e144b62b4897d7fd61ec6aa3d3d532535ea61917c2d1a7bdaea034f48d275 # 创建完成后，查看每个容器对应的IP PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; mysqlHost1 172.17.0.2 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; mysqlHost2 172.17.0.3 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; mysqlHost3 172.17.0.4 整理成表格，方便查阅\n容器名 IP mysqlHost1 172.17.0.2 mysqlHost2 172.17.0.3 mysqlHost3 172.17.0.4 分别进入三个容器，建库建表： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it mysqlHost1 bash bash-5.1# mysql -u root -p Enter password: mysql\u0026gt; create database redisDemo; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; use redisDemo; Database changed mysql\u0026gt; create table student ( -\u0026gt; id int not null primary key, -\u0026gt; name varchar(20), -\u0026gt; age int, -\u0026gt; score float -\u0026gt; ); Query OK, 0 rows affected (0.01 sec) # mysqlHost2和mysqlHost3执行相同的操作，此处略 # docker exec -it mysqlHost2 bash # docker exec -it mysqlHost3 bash 通过docker run命令启动一个MyCAT组件的容器（我发现docker仓库上没有可用的mycat镜像，于是自己根据源码生成的镜像，可以参考这篇文章MyCAT源码构建镜像） 1 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name mycat -p 8066:8066 -p 9066:9066 -v D:\\ArchitectPracticer\\Redis\\MyCAT\\server.xml:/usr/local/mycat/conf/server.xml:ro -v D:\\ArchitectPracticer\\Redis\\MyCAT\\schema.xml:/usr/local/mycat/conf/schema.xml:ro -v D:\\ArchitectPracticer\\Redis\\MyCAT\\rule.xml:/usr/local/mycat/conf/rule.xml:ro mycat:1.6.7.6 ","date":"2024-08-21T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_10_mysql_mycat/","title":"基于Docker的Redis实战-Redis整合Mysql集群和MyCat分库分表组件"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code\n一、Redis消息队列实战 实际项目中，模块间可以通过消息队列（Message queue,MQ）进行通信，MQ有各种实现，如RabbitMQ、Kafka等。使用场景比如：订单模块在处理好一个订单后可以把该订单对象放入消息队列，而记账模块则可以从消息队列中获取订单对象，进行记账。\n1.消息队列与Redis消息订阅发布模式 用消息队列来交互数据的好处是“解耦合”，比如订单模块和记账模块在交互数据时无需考虑对方的业务细节，一般会用现成的消息队列，如RabbitMQ、Kafka等。而Redis消息订阅发布模式也能实现消息队列的效果。\nRedis的消息订阅和发布模式是一种消息的通信模式，其中发布者（Publisher）可以向指定的频道（channel）发布消息，而订阅者（Subscriber）则可以订阅指定的频道，当有消息发布到该频道时，订阅者就会收到该消息。每个频道包含一个消息队列，当发布者发布消息时，消息会被推送到该频道的消息队列中，订阅者会从该队列中获取消息。\n2.消息订阅发布的命令和流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # 启动一个redis服务端容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redisPublisher -p 6379:6379 redis 563f5a099d06e078e77d4ae1ebefef01def94316203ed1db750a73c4afb5e4de # 获取redis服务端容器的IP PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; redisPublisher 172.17.0.2 # 进入redis服务端容器，执行redis-cli命令 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redisPublisher bash root@563f5a099d06:/data# redis-cli # 发布消息，channel是频道名称，message是消息内容。当前返回0，因为没有订阅者 127.0.0.1:6379\u0026gt; publish channel message (integer) 0 # 在另一个命令行窗口运行另一个容器redisSub1，使用redis-cli连接到redisPublisher容器所在的服务器，订阅MQChannel频道，当前返回1，表示订阅成功 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redisSub1 -p 6380:6380 redis bc7c2748c6a82e1b1c8c06cde89865ea6963c8dba8c16016e65c35be3d8c16bd PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redisSub1 bash root@bc7c2748c6a8:/data# redis-cli -h 172.17.0.2 -p 6379 172.17.0.2:6379\u0026gt; subscribe MQChannel 1) \u0026#34;subscribe\u0026#34; 2) \u0026#34;MQChannel\u0026#34; 3) (integer) 1 Reading messages... (press Ctrl-C to quit or any key to type command) # 回到redisPublisher容器，发布消息（注意，多个单词应该用引号），当前返回1，表示消息发送给1个订阅者 127.0.0.1:6379\u0026gt; publish MQChannel \u0026#34;Hello,MQ subscribers!\u0026#34; (integer) 1 # 在redisSub1容器中，可以看到接收到以下消息，1)message为消息类型，2)MQChannel为频道名称，3)Hello,MQ subscribers!为消息内容 1) \u0026#34;message\u0026#34; 2) \u0026#34;MQChannel\u0026#34; 3) \u0026#34;Hello,MQ subscribers!\u0026#34; # 在另一个命令行窗口再启动另一个redisSub2容器，订阅MQChannel频道，当前返回1，表示订阅成功 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redisSub2 redis 8a70f31c6f2d461e95fafbe2f79c499d13ff3fe4a12415fdb67a78e8efd7b899 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redisSub2 bash root@8a70f31c6f2d:/data# redis-cli -h 172.17.0.2 -p 6379 172.17.0.2:6379\u0026gt; subscribe MQChannel 1) \u0026#34;subscribe\u0026#34; 2) \u0026#34;MQChannel\u0026#34; 3) (integer) 1 Reading messages... (press Ctrl-C to quit or any key to type command) # 再次回到redisPublisher容器，发布消息，当前返回2，表示消息发送给2个订阅者 127.0.0.1:6379\u0026gt; publish MQChannel \u0026#34;This is the 2nd message.\u0026#34; (integer) 2 # 回到reidsSub1和redisSub2容器中，可以看到接收到以下消息，1)message为消息类型，2)MQChannel为频道名称，3)This is the 2nd message.为消息内容 1) \u0026#34;message\u0026#34; 2) \u0026#34;MQChannel\u0026#34; 3) \u0026#34;This is the 2nd message.\u0026#34; Reading messages... (press Ctrl-C to quit or any key to type command) 3.消息订阅发布的相关命令汇总 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 发布消息，channel是频道名称，message是消息内容，多个单词应该用引号 publish channel message # 订阅频道，channel是频道名称，可以同时指定多个频道 subscribe channel [channel ...] # 取消订阅频道，channel是频道名称，可以同时指定多个频道 unsubscribe [channel [channel ...]] # 使用模式的方式订阅频道，pattern是模式名称，可以同时指定多个模式。?表示匹配一个字符，*表示匹配任意多个字符 psubscribe pattern [pattern ...] # 取消订阅模式，pattern是模式名称，可以同时指定多个模式 punsubscribe [pattern [pattern ...]] 4.Java与消息队列的实战范例 确保pom.xml中包含以下依赖。\n1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.83\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建一个Publisher类，用于发布消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class Publisher { /** * 主函数入口 * @param args 命令行参数，本程序未使用 */ public static void main(String[] args) { // 创建一个HashMap对象用于存储订单信息 HashMap\u0026lt;String,String\u0026gt; order = new HashMap\u0026lt;\u0026gt;(); // 添加订单ID order.put(\u0026#34;id\u0026#34;,\u0026#34;1\u0026#34;); // 添加订单所有者 order.put(\u0026#34;owner\u0026#34;,\u0026#34;Farb\u0026#34;); // 添加订单金额 order.put(\u0026#34;amount\u0026#34;,\u0026#34;10000\u0026#34;); // 将订单信息转换为JSON字符串格式 String jsonString = JSON.toJSONString(order); // 创建Jedis对象，连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); // 发布JSON字符串到指定的Redis频道上 jedis.publish(\u0026#34;MQChannel\u0026#34;, jsonString); } } 创建一个Subscriber类，该类继承JedisPubSub抽象类，用于订阅消息、接收消息、取消订阅。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public class Subscriber extends JedisPubSub { /** * 主函数入口 * * @param args 命令行参数 */ public static void main(String[] args) { // 创建一个订阅者实例 Subscriber subscriber = new Subscriber(); // 连接到本地的Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 订阅名为\u0026#34;MQChannel\u0026#34;的频道 jedis.subscribe(subscriber, \u0026#34;MQChannel\u0026#34;); } @Override public void onSubscribe(String channel, int subscribedChannels) { System.out.println(\u0026#34;subscribe the channel\u0026#34; + channel); } @Override public void onUnsubscribe(String channel, int subscribedChannels) { System.out.println(\u0026#34;unsubscribe the channel\u0026#34; + channel); } /** * 接收并处理来自指定频道的消息 * 该方法通过解析接收到的消息内容，将其转换为HashMap对象，以便后续处理 * 主要用于演示如何从消息中提取订单信息并进行相关操作 * * @param channel 消息所属的频道，用于标识消息的来源 * @param message 原始的字符串消息内容，通常为JSON格式字符串，包含订单信息 */ @Override public void onMessage(String channel, String message) { // 将消息内容解析为HashMap对象，以便于访问其中的特定字段 HashMap\u0026lt;String, String\u0026gt; orderMap = JSON.parseObject(message, HashMap.class); // 从订单Map中获取并打印订单的ID、所有者和账户信息 System.out.println(\u0026#34;id=\u0026#34; + orderMap.get(\u0026#34;id\u0026#34;)); System.out.println(\u0026#34;owner=\u0026#34; + orderMap.get(\u0026#34;owner\u0026#34;)); System.out.println(\u0026#34;amount=\u0026#34; + orderMap.get(\u0026#34;amount\u0026#34;)); } } 二、Java实战Redis分布式锁 在一台主机的多线程场景里，为了保护某个对象在同一时刻只能被一个线程访问，可以使用锁机制，即线程只有在获取该对象锁资源的前提下才能访问，在访问完以后需要立刻释放锁，以便其他线程继续使用该对象。 扩展到多台主机，如果访问同一对象的线程来自分布式系统的多台主机，那么用来确保访问唯一性的锁就叫分布式锁。\n1.观察分布式锁的特性 分布式锁工作在分布式系统里的高并发场景里，除了具有“加锁”和“解锁”的功能外，还需具备如下两个特性：\n限时等待。哪怕加锁的主机系统崩溃导致无法再发出\u0026quot;解锁\u0026quot;指令，加载在对象上的分布式锁也能在一定时间后自动解锁； 需要确保加锁和解锁的主机必须唯一。比如主机1在发出“锁余额数据”指令的同时，发出“10秒后解锁”的指令，但是10秒后主机1并没有执行完操作余额数据的指令，此时主机1自动解锁，并且主机2得到了锁。当主机1执行完毕时，释放锁时，释放的是主机2的锁，而不是主机1的锁。 2.加锁与解锁的Redis命令分析 1 2 3 4 5 6 7 8 9 # 可以使用set和del实现加锁和解锁 set key value [NX|XX] [GET] [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL] # NX：如果键不存在，则设置键值对；XX：如果键存在，则设置键值对；GET：返回上次的值；EX：设置键值对过期时间，单位为秒；PX：设置键值对过期时间，单位为毫秒；EXAT：设置键值对过期时间，指定时间戳；PXAT：设置键值对过期时间 # 如果flag不存在则设置为1，过期时间为60s setnx flag 1 ex 60 # 如果多个线程用分布式竞争同一个资源，由于加入了nx参数，只有一个线程能成功设置，表示这个线程抢占到分布式锁，其他线程会返回0，表示设置失败。 # set命令后用了ex参数指定了flag的生成时间，即使抢占到分布式锁的机器因为故障而无法发起del命令而实现解锁动作，该flag键也能在生存时间过期后自动删除，这样该线程对资源的占有就会自动释放，其他线程继续抢占。 # 占有资源的线程使用完毕后可以通过del flag 命令释放锁，但需要注意的是，加锁和解锁的是同一台机器或同一个线程，避免解错锁。 3.Java实现Redis分布式锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 public class RedisLockUtil { /** * 尝试获取分布式锁 * * @param jedis Jedis实例，用于操作Redis * @param key 锁的键名，通常为加锁的资源标识 * @param sourceId 请求加锁的唯一标识，如当前线程ID * @param expireSeconds 锁的超时时间，单位为秒 * @return 返回true表示成功获取锁，返回false表示获取锁失败 */ public static boolean tryGetDistributedLock(Jedis jedis, String key, String sourceId, int expireSeconds) { // 使用set命令的nx（仅当key不存在时设置）和ex（设置过期时间）选项来尝试获取分布式锁 // 如果锁获取成功，返回\u0026#34;OK\u0026#34;，否则返回null // 注意：set nx和设置过期时间expire必须写到一行命令，否则无法保证两个操作的原子性，导致始终无法释放锁 if (Objects.equals(jedis.set(key, sourceId, SetParams.setParams().nx().ex(expireSeconds)), \u0026#34;OK\u0026#34;)) { System.out.println(sourceId + \u0026#34; get distributed lock\u0026#34;); return true; } return false; } /** * 释放分布式锁 * * @param jedis Jedis实例，用于执行Redis操作 * @param key 锁的键名，用于标识一个分布式锁 * @param sourceId 锁的拥有者标识，用于确保只有锁的拥有者才能释放锁 * @return boolean 表示锁释放的结果，true表示成功释放，false表示释放失败 * * 通过使用Lua脚本在Redis服务器端校验并释放锁，以保证操作的原子性 * 脚本逻辑：检查锁的拥有者是否与传入的sourceId一致，如果一致则删除锁，返回1；否则返回0 * 这样可以防止其他客户端误释放了不属于自己的锁 */ public static boolean releaseDistributedLock(Jedis jedis, String key, String sourceId) { // 定义Lua脚本，用于在Redis服务器端检查并释放分布式锁 String script = \u0026#34;if redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#39;del\u0026#39;, KEYS[1]) else return 0 end\u0026#34;; // 执行Lua脚本，传入锁的键名和拥有者标识 Object result = jedis.eval(script, 1, key, sourceId); // 检查脚本执行结果，如果删除成功，则打印信息并返回true if (\u0026#34;1\u0026#34;.equals(result.toString())) { System.out.println(sourceId + \u0026#34; release distributed lock\u0026#34;); return true; } // 删除失败，返回false return false; } } public class DistributedRedisLockDemo extends Thread { private static final String ACCOUNT_ID = \u0026#34;1234\u0026#34;; /** * 程序入口主函数 * 该函数的目的是模拟并发环境下对分布式Redis锁的需求 * 通过创建并启动5个DistributedRedisLockDemo实例来模拟并发场景 * 每个实例启动一个线程尝试获取分布式锁，从而验证分布式锁在并发环境下的有效性和稳定性 */ public static void main(String[] args) { for (int i = 0; i \u0026lt; 5; i++) { new DistributedRedisLockDemo().start(); } } /** * 设置账户信息的方法 * 此方法使用分布式锁来确保并发环境下账户信息的设置操作能够安全执行 */ public void setAccount() { // 获取当前线程的名称，用作锁的标识 String sourceId = Thread.currentThread().getName(); // 初始化锁获取标志为false boolean lockFlag = false; // 创建Jedis实例，连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); try { // 尝试获取分布式锁，如果成功则执行业务逻辑，否则执行其他操作 lockFlag = RedisLockUtil.tryGetDistributedLock(jedis, ACCOUNT_ID, sourceId, 10); if (lockFlag) { // 获取锁成功，执行业务逻辑 System.out.println(sourceId + \u0026#34;获取锁成功，执行业务逻辑\u0026#34;); } else { // 获取锁失败，执行其他操作 System.out.println(sourceId + \u0026#34;获取锁失败\u0026#34;); } } catch (Exception ex) { System.out.println(ex); } finally { // 如果成功获取了锁，则在业务逻辑执行完毕后释放锁 if (lockFlag) { RedisLockUtil.releaseDistributedLock(jedis, ACCOUNT_ID, sourceId); System.out.println(sourceId + \u0026#34;释放锁成功\u0026#34;); } } } @Override public void run() { try { setAccount(); } catch (Exception e) { System.out.println(e); } } } // 运行结果： Thread-0获取锁失败 Thread-3获取锁失败 Thread-1 get distributed lock Thread-2获取锁失败 Thread-4获取锁失败 Thread-1获取锁成功，执行业务逻辑 Thread-1 release distributed lock Thread-1释放锁成功 三、 java实现Redis限流 限流的含义是指在给定的时间内，对某一个资源进行访问的次数不能超过一定的阈值，否则就拒绝访问。比如秒杀模块中，需要确保10s内发往支付模块的请求数量小于500个。限流的作用就是防止某个时间段内的请求数过多，造成模块因高并发而不可用。\n1.zset有序集合相关命令与限流 有序集合（zset）是一种特殊类型的集合，它包含一个或多个成员，每个成员都关联有一个分数（score）。有序集合的成员按分数值从小到大排列。有序集合的成员是唯一的，分数可以是整数也可以是浮点数。\n1 2 3 4 5 6 7 8 9 10 11 # 向有序集合添加元素 # 在限流场景中，可以将score存储为时间戳，这样zset就可以根据时间戳的score排序 zadd key score member # 删除键为key，score在min和max之间的所有元素 # 通过这个操作，可以排除限流时间范围外的数据，在此基础上，通过zcard统计有序集合中元素的数量 zremrangeByScore key min max # 获取键为key的zset中元素的数量 zcard key 2.java实现zset限流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 public class LimitRequestDemo { /** * 主函数，用于演示如何使用Jedis操作Redis进行限流控制 * 该函数首先连接到本地的Redis服务器，然后删除已有的请求类型键， * 接着循环5次，每次调用canVisit方法来模拟一次访问请求，并进行限流判断 * * @param args 命令行参数，本例中未使用 */ public static void main(String[] args) { // 创建Jedis实例，连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 定义请求类型为支付请求 String requestType = \u0026#34;PayRequest\u0026#34;; // 删除现有的请求类型键，以确保开始时环境干净 jedis.del(requestType); // 循环5次，模拟5次访问请求 for (int i = 0; i \u0026lt; 5; i++) { // 调用canVisit方法，传入Jedis实例，请求类型，资源限制（100），以及时间窗口（3秒） canVisit(jedis, requestType, 100, 3); } } /** * 判断是否可以访问 * 使用Redis的有序集合zset来记录请求的时间戳，通过清除超过时间窗口的请求记录来限制请求频率。 * 如果在指定时间窗口内的请求数量超过限制，则提示请求过于频繁。 * * @param jedis Jedis实例，用于操作Redis数据库 * @param requestType 请求类型，用于区分不同类型的请求并分别限流 * @param limitTime 单位为秒的时间窗口长度，用于定义多久算作一次请求 * @param limitCount 在指定时间窗口内允许的最大请求数量 */ public static void canVisit(Jedis jedis, String requestType, int limitTime, int limitCount) { // 获取当前时间戳 long currentTimeMillis = System.currentTimeMillis(); // 将当前时间戳添加到指定请求类型的有序集合中 jedis.zadd(requestType, currentTimeMillis, Long.toString(currentTimeMillis)); // 移除超过时间窗口的请求时间戳 jedis.zremrangeByScore(requestType, 0, currentTimeMillis - limitTime * 1000); // 获取当前时间窗口内的请求数量 Long totalCount = jedis.zcard(requestType); // 为请求类型的集合设置过期时间，防止数据溢出 jedis.expire(requestType, limitTime + 1); // 判断请求数是否超过限制 if (totalCount \u0026gt; limitCount) { System.out.println(\u0026#34;请求过于频繁，请稍后再试\u0026#34;); } else { System.out.println(\u0026#34;请求成功\u0026#34;); } } } // 运行结果： 请求成功 请求成功 请求成功 请求过于频繁，请稍后再试 请求过于频繁，请稍后再试 四.Redis压力测试实战 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 redis-benchmark [option] [optiion value] # option是参数项，option value是参数值 # -h 指定redis服务器地址 # -p 指定redis服务器端口 # -c 指定并发连接数 # -n 指定请求次数 # -q 强制退出Redis,显示时只给出“每秒能处理的请求数”这个值 # -t 指定测试的命令，默认执行所有命令 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redisDemo bash # 对本机6379端口的redis服务器进行压测，执行set和get命令各2000次 root@563f5a099d06:/data# redis-benchmark -h 127.0.0.1 -p 6379 -t set,get -n 2000 # 2000次请求set的压测结果，0.01s处理完成 ====== SET ====== 2000 requests completed in 0.01 seconds 50 parallel clients 3 bytes payload keep alive: 1 host configuration \u0026#34;save\u0026#34;: 3600 1 300 100 60 10000 host configuration \u0026#34;appendonly\u0026#34;: no multi-thread: no # 显示了n%的请求处理时间 Latency by percentile distribution: 0.000% \u0026lt;= 0.039 milliseconds (cumulative count 1) 50.000% \u0026lt;= 0.095 milliseconds (cumulative count 1043) 75.000% \u0026lt;= 0.111 milliseconds (cumulative count 1677) 87.500% \u0026lt;= 0.119 milliseconds (cumulative count 1775) 93.750% \u0026lt;= 0.167 milliseconds (cumulative count 1887) 96.875% \u0026lt;= 0.207 milliseconds (cumulative count 1942) 98.438% \u0026lt;= 0.247 milliseconds (cumulative count 1976) 99.219% \u0026lt;= 0.271 milliseconds (cumulative count 1986) 99.609% \u0026lt;= 0.295 milliseconds (cumulative count 1994) 99.805% \u0026lt;= 0.303 milliseconds (cumulative count 1997) 99.902% \u0026lt;= 0.319 milliseconds (cumulative count 1999) 99.951% \u0026lt;= 0.327 milliseconds (cumulative count 2000) 100.000% \u0026lt;= 0.327 milliseconds (cumulative count 2000) Cumulative distribution of latencies: 73.050% \u0026lt;= 0.103 milliseconds (cumulative count 1461) 97.100% \u0026lt;= 0.207 milliseconds (cumulative count 1942) 99.850% \u0026lt;= 0.303 milliseconds (cumulative count 1997) 100.000% \u0026lt;= 0.407 milliseconds (cumulative count 2000) # 汇总信息，吞吐量：每秒28.6万次请求 Summary: throughput summary: 285714.28 requests per second latency summary (msec): avg min p50 p95 p99 max 0.103 0.032 0.095 0.175 0.255 0.327 #以下时get的压测结果，与上面类似 ====== GET ====== 2000 requests completed in 0.01 seconds 50 parallel clients 3 bytes payload keep alive: 1 host configuration \u0026#34;save\u0026#34;: 3600 1 300 100 60 10000 host configuration \u0026#34;appendonly\u0026#34;: no multi-thread: no Latency by percentile distribution: 0.000% \u0026lt;= 0.039 milliseconds (cumulative count 2) 50.000% \u0026lt;= 0.103 milliseconds (cumulative count 1211) 75.000% \u0026lt;= 0.119 milliseconds (cumulative count 1512) 87.500% \u0026lt;= 0.159 milliseconds (cumulative count 1751) 93.750% \u0026lt;= 0.223 milliseconds (cumulative count 1878) 96.875% \u0026lt;= 0.407 milliseconds (cumulative count 1938) 98.438% \u0026lt;= 0.759 milliseconds (cumulative count 1969) 99.219% \u0026lt;= 0.935 milliseconds (cumulative count 1985) 99.609% \u0026lt;= 0.967 milliseconds (cumulative count 1993) 99.805% \u0026lt;= 0.999 milliseconds (cumulative count 1997) 99.902% \u0026lt;= 1.071 milliseconds (cumulative count 1999) 99.951% \u0026lt;= 1.079 milliseconds (cumulative count 2000) 100.000% \u0026lt;= 1.079 milliseconds (cumulative count 2000) Cumulative distribution of latencies: 60.550% \u0026lt;= 0.103 milliseconds (cumulative count 1211) 92.650% \u0026lt;= 0.207 milliseconds (cumulative count 1853) 96.450% \u0026lt;= 0.303 milliseconds (cumulative count 1929) 96.900% \u0026lt;= 0.407 milliseconds (cumulative count 1938) 97.250% \u0026lt;= 0.503 milliseconds (cumulative count 1945) 97.650% \u0026lt;= 0.607 milliseconds (cumulative count 1953) 98.000% \u0026lt;= 0.703 milliseconds (cumulative count 1960) 98.600% \u0026lt;= 0.807 milliseconds (cumulative count 1972) 98.950% \u0026lt;= 0.903 milliseconds (cumulative count 1979) 99.900% \u0026lt;= 1.007 milliseconds (cumulative count 1998) 100.000% \u0026lt;= 1.103 milliseconds (cumulative count 2000) Summary: throughput summary: 249999.98 requests per second latency summary (msec): avg min p50 p95 p99 max 0.131 0.032 0.103 0.247 0.919 1.079 再执行一个压测命令查看一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 20个并发连接，2000次请求，没有指定-t参数，默认执行所有命令，使用-q参数，只显示每秒处理的请求数，如果去掉-q，则会显示每条命令的详细信息。 root@563f5a099d06:/data# redis-benchmark -h localhost -p 6379 -c 20 -n 2000 -q # 显示每秒处理的请求数，以及50%的请求处理耗时 PING_INLINE: 285714.28 requests per second, p50=0.047 msec PING_MBULK: 285714.28 requests per second, p50=0.047 msec SET: 249999.98 requests per second, p50=0.047 msec GET: 249999.98 requests per second, p50=0.047 msec INCR: 249999.98 requests per second, p50=0.047 msec LPUSH: 285714.28 requests per second, p50=0.039 msec RPUSH: 249999.98 requests per second, p50=0.047 msec LPOP: 222222.23 requests per second, p50=0.039 msec RPOP: 285714.28 requests per second, p50=0.047 msec SADD: 249999.98 requests per second, p50=0.047 msec HSET: 249999.98 requests per second, p50=0.047 msec SPOP: 222222.23 requests per second, p50=0.047 msec ZADD: 222222.23 requests per second, p50=0.047 msec ZPOPMIN: 222222.23 requests per second, p50=0.047 msec LPUSH (needed to benchmark LRANGE): 249999.98 requests per second, p50=0.047 msec LRANGE_100 (first 100 elements): 90909.09 requests per second, p50=0.119 msec LRANGE_300 (first 300 elements): 35714.29 requests per second, p50=0.279 msec LRANGE_500 (first 500 elements): 25000.00 requests per second, p50=0.391 msec LRANGE_600 (first 600 elements): 21505.38 requests per second, p50=0.455 msec MSET (10 keys): 333333.34 requests per second, p50=0.039 msec XADD: 285714.28 requests per second, p50=0.039 msec ","date":"2024-08-18T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_09_redis_practical_cases/","title":"基于Docker的Redis实战-Redis消息队列、分布式锁、限流、压力测试综合实践案例"},{"content":"1. getInputStream() must not be called against a directory: file://D:/DevTools/java/apache-maven-3.9.5/conf 这个错误是在IDEA中配置Maven的时候出现的，在配置Maven的setting文件路径的时候，如果配置的是一个conf目录或其他目录，就会报错，正确做法是指定setting.xml的全路径。\n2. SLF4J: Failed to load class \u0026ldquo;org.slf4j.impl.StaticLoggerBinder 通常意味着 Simple Logging Facade for Java (SLF4J) 在启动时未能找到一个合适的日志实现。这可能是由于以下几个原因造成的：\n缺少日志实现库：项目中没有包含任何 SLF4J 的绑定实现，如 Logback 或 Log4j。 多个日志实现库冲突：项目中包含了多个 SLF4J 绑定实现，导致 SLF4J 不确定使用哪一个。 错误的日志实现库版本：项目中包含的日志实现库与 SLF4J 版本不兼容。** 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;dependencies\u0026gt; \u0026lt;!-- SLF4J API --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.36\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Logback as the logging implementation --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 3. Loading class com.mysql.jdbc.Driver'. This is deprecated. The new driver class is com.mysql.cj.jdbc.Driver\u0026rsquo;. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 当你看到这条警告信息时，说明你在使用 MySQL 的 JDBC 驱动时正在加载旧版的驱动类 com.mysql.jdbc.Driver，而新版的驱动类应该是 com.mysql.cj.jdbc.Driver。这通常发生在使用 MySQL 8.0 及更高版本时。\n1 2 3 4 5 6 // 不要这样写 Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); // 按照提示，驱动会自动注册，所以不写也没问题 // 如果你需要显式指定驱动类，使用新版的驱动类 Class.forName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); 4.Caused by: jakarta.persistence.PersistenceException: [PersistenceUnit: default] Unable to build Hibernate SessionFactory; nested exception is org.hibernate.exception.JDBCConnectionException: Unable to open JDBC Connection for DDL execution [Public Key Retrieval is not allowed] [n/a] 数据库连接字符串中加上：allowPublicKeyRetrieval=true\n1 2 3 4 5 6 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/stockDB?allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Shanghai\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false username: root password: 123456 5. Caused by: org.hibernate.service.spi.ServiceException: Unable to create requested service [org.hibernate.engine.jdbc.env.spi.JdbcEnvironment] due to: Unable to determine Dialect without JDBC metadata (please set \u0026lsquo;jakarta.persistence.jdbc.url\u0026rsquo; for common cases or \u0026lsquo;hibernate.dialect\u0026rsquo; when a custom Dialect implementation must be provided) jpa是在spring节点下配置，而不是在spring.datasource下配置。\n1 2 3 4 5 6 7 spring: jpa: database: MySQL database-platform: org.hibernate.dialect.MySQLDialect show-sql: true hibernate: ddl-auto: update 6. java.lang.UnsupportedOperationException: io.lettuce.core.output.ValueOutput does not support set(long) 1 2 // 注意，这里必须使用Long返回类型，因为redis中的Integer对应java中的Long RedisScript\u0026lt;Long\u0026gt; defaultRedisScript = new DefaultRedisScript\u0026lt;\u0026gt;(luaScript, Long.class); 7. Spring Boot [3.4.0] is not compatible with this Spring Cloud release train SpringCloud应用启动失败：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 *************************** APPLICATION FAILED TO START *************************** Description: Your project setup is incompatible with our requirements due to following reasons: - Spring Boot [3.4.0] is not compatible with this Spring Cloud release train Action: Consider applying the following actions: - Change Spring Boot version to one of the following versions [3.2.x, 3.3.x] . You can find the latest Spring Boot versions here [https://spring.io/projects/spring-boot#learn]. If you want to learn more about the Spring Cloud Release train compatibility, you can visit this page [https://spring.io/projects/spring-cloud#overview] and check the [Release Trains] section. If you want to disable this check, just set the property [spring.cloud.compatibility-verifier.enabled=false] 根因就是SpringBoot和SpringCloud版本不匹配，可以点击错误中的连接查看配套版本。下面这两个版本是配套的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;farb.top\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;EurekaServer\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;EurekaServer\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;EurekaServer\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;2023.0.2\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;/properties\u0026gt; 8. 微服务模块中通过RestTemplate调用其他服务时报错，java.net.UnknownHostException: xxxservice 原因是因为RestTemplate是直接在类中new的，不是专门定义的Bean。\n通过Bean 定义的 RestTemplate，可以很好地与其他 Spring 组件集成。例如，在使用服务发现（如 Eureka）和负载均衡（如 Ribbon）的微服务架构中，通过@LoadBalanced注解标记的RestTemplate（定义为 Bean）可以自动与 Ribbon 集成，实现基于服务名称的负载均衡调用。 而通过new 的 RestTemplate 没有集成Ribbon，因而找不到微服务。\n1 2 3 4 5 6 7 8 @Configuration public class AppConfig { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } ","date":"2024-08-14T00:00:00Z","permalink":"https://farb.github.io/p/java_error_notes/","title":"Java代码报错记录集"},{"content":"1. ModuleNotFoundError: No module named \u0026lsquo;xxx\u0026rsquo; 1 2 3 4 5 from PIL import Image, ImageFilter ModuleNotFoundError: No module named \u0026#39;PIL\u0026#39; # 缺少依赖PIL，PIL已被Pillow替代,安装 pip install Pillow 1 2 3 4 5 import pytesseract ModuleNotFoundError: No module named \u0026#39;pytesseract\u0026#39; # 缺少依赖pytesseract,安装 pip install pytesseract 2. pytesseract.pytesseract.TesseractNotFoundError: tesseract is not installed or it\u0026rsquo;s not in your PATH 没有安装tesseract-ocr,可以到这里 https://github.com/UB-Mannheim/tesseract/wiki 下载安装，并自行配置环境变量指向安装目录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Traceback (most recent call last): File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 275, in run_tesseract proc = subprocess.Popen(cmd_args, **subprocess_args()) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \u0026#34;D:\\Python\\Python312\\Lib\\subprocess.py\u0026#34;, line 1026, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \u0026#34;D:\\Python\\Python312\\Lib\\subprocess.py\u0026#34;, line 1538, in _execute_child hp, ht, pid, tid = _winapi.CreateProcess(executable, args, ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ FileNotFoundError: [WinError 2] 系统找不到指定的文件。 During handling of the above exception, another exception occurred: ... File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 486, in image_to_string return { ^ File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 489, in \u0026lt;lambda\u0026gt; Output.STRING: lambda: run_and_get_output(*args), ^^^^^^^^^^^^^^^^^^^^^^^^^ File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 352, in run_and_get_output run_tesseract(**kwargs) File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 280, in run_tesseract raise TesseractNotFoundError() pytesseract.pytesseract.TesseractNotFoundError: tesseract is not installed or it\u0026#39;s not in your PATH. See README file for more information. 3. Please make sure the TESSDATA_PREFIX environment variable is set to your \u0026ldquo;tessdata\u0026rdquo; directory. Failed loading language 'chi_sim' Tesseract couldn't load any languages! Could not initialize tesseract. 到这里下载各种语言的训练数据。 https://github.com/tesseract-ocr/tessdata\n1 2 3 4 5 6 7 8 9 10 11 File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 486, in image_to_string return { ^ File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 489, in \u0026lt;lambda\u0026gt; Output.STRING: lambda: run_and_get_output(*args), ^^^^^^^^^^^^^^^^^^^^^^^^^ File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 352, in run_and_get_output run_tesseract(**kwargs) File \u0026#34;D:\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py\u0026#34;, line 284, in run_tesseract raise TesseractError(proc.returncode, get_errors(error_string)) pytesseract.pytesseract.TesseractError: (1, \u0026#39;Error opening data file D:\\\\Program Files\\\\Tesseract-OCR/tessdata/chi_sim.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \u0026#34;tessdata\u0026#34; directory. Failed loading language \\\u0026#39;chi_sim\\\u0026#39; Tesseract couldn\\\u0026#39;t load any languages! Could not initialize tesseract.\u0026#39;) 4. Exception redis.clients.jedis.exceptions.JedisDataException: value sent to redis cannot be null 1 2 // 原始代码这样写的 jedis.rpush(key, null, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;); 原因是尝试向 Redis 中写入了空值（null）。根据 Redis 的设计，它不允许存储 null 值。 在代码中，当没有查询到数据时，会尝试向 Redis 写入 null, \u0026ldquo;0\u0026rdquo;, \u0026ldquo;0\u0026rdquo; 这三个值。其中 null 是不允许的，因此触发了异常。 要解决这个问题，可以考虑以下几种方法： 不写入任何值：如果查询不到数据，则不向 Redis 写入任何内容。 写入特殊值：用一个特殊值代替 null，比如空字符串 \u0026quot;\u0026quot; 或者 -1 表示无效或未找到的数据。 这里提供一种修改方案，即使用空字符串替换 null:\n","date":"2024-08-14T00:00:00Z","permalink":"https://farb.github.io/p/python_error_notes/","title":"Python代码报错记录集"},{"content":"1. ModuleNotFoundError: No module named \u0026lsquo;xxx\u0026rsquo; docker run -itd \u0026ndash;name mycat -p 8066:8066 -p 9066:9066 mycat:1.6.7.6\n","date":"2024-08-14T00:00:00Z","permalink":"https://farb.github.io/p/python_error_notes/","title":"Python代码报错记录集"},{"content":"源码链接： https://gitee.com/farb/architect-practicer-code\n1. Java通过Jedis读写Redis 1.Maven引入Jedis依赖 IDEA新建项目RedisBasedDocker，pom.xml文件内容如下，引入Redis的客户端Jedis依赖，使用java11版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;top.farb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;RedisBasedDocker\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/project\u0026gt; 2.通过Jedis读写Redis字符串 1 2 # 首先通过docker的方式启动redis服务器 PS D:\\code\\architect-practicer-code\\java\\RedisBasedDocker\u0026gt; docker run -itd --name javaRedis -p 6379:6379 redis:latest 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public static void main(String[] args) { // 创建一个Jedis对象，连接到本地的Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 验证与Redis服务器的连接是否成功 System.out.println(\u0026#34;jedis.ping() = \u0026#34; + jedis.ping()); // 设置键值对，将\u0026#34;name\u0026#34;键的值设置为\u0026#34;farb\u0026#34; System.out.println(jedis.set(\u0026#34;name\u0026#34;, \u0026#34;farb\u0026#34;)); // 获取\u0026#34;name\u0026#34;键的值，并打印 System.out.println(jedis.get(\u0026#34;name\u0026#34;)); // 尝试获取一个不存在的键，将返回null System.out.println(jedis.get(\u0026#34;notExistKey\u0026#34;)); } // 运行程序，输出结果如下： jedis.ping() = PONG OK farb null 3.操作各种Redis命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 /** * 演示Redis中一些其他命令的使用 * 本函数主要展示如何在Redis中执行如设置键值对、检查键是否存在、匹配键名和删除键等操作 */ static void otherCommands() { // 创建Jedis实例，连接到本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 设置键值对，为键\u0026#34;name\u0026#34;、\u0026#34;age\u0026#34;和\u0026#34;salary\u0026#34;分别设置值\u0026#34;farb\u0026#34;、\u0026#34;18\u0026#34;和\u0026#34;30000\u0026#34; jedis.set(\u0026#34;name\u0026#34;, \u0026#34;farb\u0026#34;); jedis.set(\u0026#34;age\u0026#34;, \u0026#34;18\u0026#34;); jedis.set(\u0026#34;salary\u0026#34;, \u0026#34;30000\u0026#34;); // 检查键\u0026#34;name\u0026#34;是否存在于Redis中，并打印结果 System.out.println(jedis.exists(\u0026#34;name\u0026#34;)); // 检查键\u0026#34;notExistKey\u0026#34;是否存在于Redis中，并打印结果 System.out.println(jedis.exists(\u0026#34;notExistKey\u0026#34;)); // 匹配所有包含\u0026#34;a\u0026#34;的键，并打印结果 System.out.println(jedis.keys(\u0026#34;*a*\u0026#34;)); // 删除键\u0026#34;name\u0026#34;，并打印删除的键的数量 System.out.println(jedis.del(\u0026#34;name\u0026#34;)); // 再次匹配所有包含\u0026#34;a\u0026#34;的键，并打印结果，以验证删除操作的效果 System.out.println(jedis.keys(\u0026#34;*a*\u0026#34;)); } // 运行程序，输出结果如下： true false [name, salary, age] 1 [age, salary] 4.以事务的方式操作redis jedis.multi()方法用于创建一个事务，然后通过调用jedis.exec()方法来执行这个事务，jedis.discard()方法用于取消这个事务，jedis.watch()方法用于对一个键进行监视，jedis.unwatch()方法用于取消对一个键的监视。watch的作用相当于多线程中的加锁操作，需要unwatch释放锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 /** * 本方法用于演示Jedis事务的基本使用和特性 * 事务可以看作是一个命令的集合，这些命令在发送到服务器时会被当作一个整体来处理 * 这个方法展示了事务的创建、命令添加、取消和执行过程 */ static void transactionDemo() { // 创建一个Jedis实例，连接到本地的Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 开始一个事务 Transaction transaction = jedis.multi(); // 在事务中设置两个键值对 transaction.set(\u0026#34;trans1\u0026#34;, \u0026#34;1\u0026#34;); transaction.set(\u0026#34;trans2\u0026#34;, \u0026#34;2\u0026#34;); // 取消这个事务，事务中的所有命令都不会被执行 transaction.discard(); // 打印出所有以\u0026#34;trans\u0026#34;开头的键，验证事务是否成功取消 System.out.println(jedis.keys(\u0026#34;trans*\u0026#34;)); // 设置一个标记键，用于演示watch命令 jedis.set(\u0026#34;flag\u0026#34;, \u0026#34;true\u0026#34;); // 对\u0026#34;flag\u0026#34;键进行监视，以便在事务中使用 jedis.watch(\u0026#34;flag\u0026#34;); // 再次开始一个事务 Transaction transaction1 = jedis.multi(); // 在事务中设置两个键值对 transaction1.set(\u0026#34;key1\u0026#34;, \u0026#34;1\u0026#34;); transaction1.set(\u0026#34;key2\u0026#34;, \u0026#34;2\u0026#34;); // 执行这个事务，事务中的所有命令都会被执行 transaction1.exec(); // 打印出所有以\u0026#34;key\u0026#34;开头的键，验证事务是否成功执行 System.out.println(jedis.keys(\u0026#34;key*\u0026#34;)); // 取消对\u0026#34;flag\u0026#34;键的监视 jedis.unwatch(); } // 运行程序，输出结果如下： [] [key1, key2] 5.Jedis连接池 如果多个客户端在使用Redis时，需要频繁的创建和销毁Jedis实例，这会消耗大量的资源，导致性能下降。为了解决这个问题，Redis提供了连接池的功能，通过连接池可以复用已经创建的连接，从而提高Redis的性能。 引入了Jedis连接池，大量客户端不是直接向Redis服务器申请连接，而是从连接池中获取连接，并在使用完毕后将其归还给连接池，这样可以避免连接的频繁创建和销毁，高并发场景里建议使用连接池，从而提高Redis的性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * 配置并使用Jedis连接池来管理Redis连接 * 该方法演示了如何创建Jedis连接池并配置其参数，然后使用该连接池获取Jedis实例进行Redis操作， * 最后关闭连接池 */ static void jedisPool() { // 创建Jedis连接池配置对象 JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); // 设置连接池最大连接数 jedisPoolConfig.setMaxTotal(10); // 设置连接池最大空闲连接数 jedisPoolConfig.setMaxIdle(5); // 设置连接池最小空闲连接数 jedisPoolConfig.setMinIdle(3); // 设置获取连接的最大等待时间 jedisPoolConfig.setMaxWaitMillis(1000); // 设置当连接池资源耗尽时是否阻塞等待 jedisPoolConfig.setBlockWhenExhausted(false); // 根据配置创建Jedis连接池 JedisPool jedisPool = new JedisPool(jedisPoolConfig, \u0026#34;localhost\u0026#34;, 6379); // 从连接池中获取Jedis实例 Jedis jedis = jedisPool.getResource(); // 使用Jedis实例执行set操作 jedis.set(\u0026#34;name\u0026#34;, \u0026#34;farb\u0026#34;); // 使用Jedis实例执行get操作并打印结果 System.out.println(jedis.get(\u0026#34;name\u0026#34;)); // 关闭连接池，释放资源 jedisPool.close(); } 6.用管道的方式提升操作性能 在Redis中，管道是一种优化Redis操作性能的技术，它允许客户端一次性发送多个命令，然后一次性从Redis服务器接收多个响应。通过使用管道，客户端可以减少网络延迟，从而提高操作性能。在大数据的操作场景里，通过管道的方式能大量节省“命令和结果的传输时间”，从而提升性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 /** * 演示使用Redis的Jedis客户端进行数据操作时，使用pipeline技术的性能提升 * 通过对比使用和不使用pipeline的方式进行数据设置和获取操作的耗时，来展示pipeline的优势 */ static void pipelineDemo() { // 创建Jedis实例，连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 记录开始时间 long start = System.currentTimeMillis(); // 不使用pipeline进行10000次set和get操作 for (int i = 0; i \u0026lt; 10000; i++) { jedis.set(\u0026#34;key\u0026#34; + i, \u0026#34;value\u0026#34; + i); jedis.get(\u0026#34;key\u0026#34; + i); } // 记录结束时间，计算不使用pipeline时的操作耗时 long end = System.currentTimeMillis(); System.out.println(\u0026#34;不使用管道耗时：\u0026#34; + (end - start) + \u0026#34;ms\u0026#34;); // 重新记录开始时间，准备使用pipeline start = System.currentTimeMillis(); // 创建Pipeline对象，用于批量执行Jedis命令 Pipeline pipeline = jedis.pipelined(); // 使用pipeline进行10000次set和get操作 for (int i = 0; i \u0026lt; 10000; i++) { pipeline.set(\u0026#34;key\u0026#34; + i, \u0026#34;value\u0026#34; + i); pipeline.get(\u0026#34;key\u0026#34; + i); } // 同步执行pipeline中积累的所有命令 pipeline.sync(); // 记录结束时间，计算使用pipeline时的操作耗时 end = System.currentTimeMillis(); System.out.println(\u0026#34;使用管道耗时：\u0026#34; + (end - start) + \u0026#34;ms\u0026#34;); } // 运行程序，输出结果如下： 不使用管道耗时：6141ms 使用管道耗时：28ms 通过以上例子，可以看到，如果需要大批量的向Redis服务器读写数据，那么建议采用管道的方式提升性能。\n2. Java操作各种Redis数据类型 读写列表类对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public static void main(String[] args) { listDemo(); } /** * List数据结构演示 * 该方法用于演示如何使用Jedis操作List数据结构，包括插入和查询操作 */ private static void listDemo() { // 创建Jedis对象，连接本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 向List的尾部添加元素 jedis.rpush(\u0026#34;001\u0026#34;, \u0026#34;Peter\u0026#34;); jedis.rpush(\u0026#34;001\u0026#34;, \u0026#34;15\u0026#34;); jedis.rpush(\u0026#34;001\u0026#34;, \u0026#34;Male\u0026#34;); // 检查Key是否存在 if (jedis.exists(\u0026#34;001\u0026#34;)) { // 如果Key存在，打印List中的每个元素 System.out.println(jedis.lindex(\u0026#34;001\u0026#34;, 0)); System.out.println(jedis.lindex(\u0026#34;001\u0026#34;, 1)); System.out.println(jedis.lindex(\u0026#34;001\u0026#34;, 2)); } else { // 如果Key不存在，打印提示信息 System.out.println(\u0026#34;Key does not exist,get from db\u0026#34;); } } // 运行程序，输出结果如下： Peter 15 Male 2.读写哈希表对象 如果待缓存对象的属性个数很多，就建议用哈希表对象来缓存：一方面，在哈希表中是用属性名称来定位数据的，而不是属性的顺序；另一方面，哪怕没存若干属性，也不会影响对该对象的读取，顶多就是读取的属性值为空。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 示例如何使用Jedis操作Hash数据类型 * 该方法连接到本地的Redis服务器，使用HSET命令向两个员工ID（Emp002和Emp003）添加信息， * 并使用HGET命令获取这些信息 */ static void hashDemo() { // 创建Jedis实例，连接到本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 向Emp002这个Hash中设置name、age和gender字段 jedis.hset(\u0026#34;Emp002\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;Peter\u0026#34;); jedis.hset(\u0026#34;Emp002\u0026#34;, \u0026#34;age\u0026#34;, \u0026#34;15\u0026#34;); jedis.hset(\u0026#34;Emp002\u0026#34;, \u0026#34;gender\u0026#34;, \u0026#34;Male\u0026#34;); // 获取并打印Emp002的name和age字段 System.out.println(jedis.hget(\u0026#34;Emp002\u0026#34;, \u0026#34;name\u0026#34;)); System.out.println(jedis.hget(\u0026#34;Emp002\u0026#34;, \u0026#34;age\u0026#34;)); // 使用Map封装Emp003的信息，然后一次性设置到Redis中 Map\u0026lt;String, String\u0026gt; emp03 = new HashMap\u0026lt;\u0026gt;(); emp03.put(\u0026#34;name\u0026#34;, \u0026#34;farb\u0026#34;); emp03.put(\u0026#34;age\u0026#34;, \u0026#34;18\u0026#34;); emp03.put(\u0026#34;gender\u0026#34;, \u0026#34;Male\u0026#34;); jedis.hset(\u0026#34;Emp003\u0026#34;, emp03); // 再次获取并打印Emp002和Emp003的name字段，展示数据一致性 System.out.println(jedis.hget(\u0026#34;Emp002\u0026#34;, \u0026#34;name\u0026#34;)); System.out.println(jedis.hget(\u0026#34;Emp002\u0026#34;, \u0026#34;age\u0026#34;)); } // 运行程序，输出结果如下： Peter 15 farb 18 3.读写集合对象 一般项目中，大多使用Redis的字符串，列表和哈希表来缓存数据，而集合对象一般用于去重的场景。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * 使用Jedis操作Redis的Set数据结构的演示方法 * 该方法展示了如何向Set中添加元素，并打印出Set中的所有元素 */ static void setDemo() { // 创建Jedis对象，连接本地的Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 向Set“bonusId”中添加元素“1”、“2”、“3”、“4”、“1”，注意重复元素会被忽略 jedis.sadd(\u0026#34;bonusId\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;1\u0026#34;); // 打印Set“bonusId”中的所有元素 System.out.println(jedis.smembers(\u0026#34;bonusId\u0026#34;)); } // 运行程序，输出结果如下： [1, 2, 3, 4] 4.读写有序集合对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 示范使用Sorted Set数据结构的操作 * 该方法主要展示了如何在Redis中使用Jedis操作Sorted Set，包括添加成员和获取排序范围 */ static void sortedSetDemo() { // 创建Jedis对象，连接本地的Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 向Sorted Set \u0026#34;emps\u0026#34;中添加成员\u0026#34;Peter\u0026#34;，分数为1.0 jedis.zadd(\u0026#34;emps\u0026#34;, 1.0, \u0026#34;Peter\u0026#34;); // 向Sorted Set \u0026#34;emps\u0026#34;中添加成员\u0026#34;Jane\u0026#34;，分数为3.0 jedis.zadd(\u0026#34;emps\u0026#34;, 3.0, \u0026#34;Jane\u0026#34;); // 向Sorted Set \u0026#34;emps\u0026#34;中添加成员\u0026#34;Mike\u0026#34;，分数为2.0 jedis.zadd(\u0026#34;emps\u0026#34;, 2.0, \u0026#34;Mike\u0026#34;); // 打印Sorted Set \u0026#34;emps\u0026#34;中所有成员，验证添加操作的结果 System.out.println(jedis.zrange(\u0026#34;emps\u0026#34;, 0, -1)); // 根据分数范围查询并打印Sorted Set \u0026#34;emps\u0026#34;中的成员及其分数，分数范围为2.0到3.0 System.out.println(jedis.zrangeByScoreWithScores(\u0026#34;emps\u0026#34;, 2.0, 3.0)); } // 运行程序，输出结果如下： [Peter, Mike, Jane] [[Mike,2.0], [Jane,3.0]] 5.操作地理位置数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 地理位置演示函数 * 该函数演示了如何使用Jedis操作Redis中的地理位置数据 * 主要包括添加地理位置数据、获取位置信息、查询一定半径内的地理位置以及计算两点间的距离 */ static void geoDemo() { // 创建Jedis对象，连接本地的Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 向Redis中添加地理位置数据，包括经度、纬度和位置标识 jedis.geoadd(\u0026#34;geo\u0026#34;, 120.52, 30.40, \u0026#34;pos1\u0026#34;); jedis.geoadd(\u0026#34;geo\u0026#34;, 120.52, 31.53, \u0026#34;pos2\u0026#34;); jedis.geoadd(\u0026#34;geo\u0026#34;, 122.12, 30.40, \u0026#34;pos3\u0026#34;); jedis.geoadd(\u0026#34;geo\u0026#34;, 122.12, 31.53, \u0026#34;pos4\u0026#34;); // 打印所有位置的地理坐标 System.out.println(jedis.geopos(\u0026#34;geo\u0026#34;, \u0026#34;pos1\u0026#34;, \u0026#34;pos2\u0026#34;, \u0026#34;pos3\u0026#34;, \u0026#34;pos4\u0026#34;)); // 查询以给定经纬度为中心，指定半径内的地理位置 List\u0026lt;GeoRadiusResponse\u0026gt; geoList = jedis.georadius(\u0026#34;geo\u0026#34;, 120.52, 30.40, 200, GeoUnit.KM); for (GeoRadiusResponse res : geoList) { // 打印查询到的地理位置 System.out.println(res.getMemberByString()); } // 计算两个地理位置之间的距离 Double distance = jedis.geodist(\u0026#34;geo\u0026#34;, \u0026#34;pos1\u0026#34;, \u0026#34;pos2\u0026#34;, GeoUnit.KM); // 打印计算得到的距离 System.out.println(distance); } // 运行程序，输出结果如下： [(120.5200007557869,30.399999526689975), (120.5200007557869,31.530001032013715), (122.11999744176865,30.399999526689975), (122.11999744176865,31.530001032013715)] pos1 pos2 pos3 pos4 125.6859 6.Redis与Mysql的整合 通过Docker安装Mysql开发环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # 通过docker pull mysql 拉取镜像并下载到本地后，查看镜像并运行镜像 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE mysql latest 05247af91864 8 weeks ago 578MB # 通过-e 设置环境变量，指定该容器包含的Mysql服务器登录密码是123456 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 mysql 0fab30cacbb5374936d664a694056f2972f0cdeedabe21b969c1be6c62346ca8 # 进入容器，登录后建库建表，插入数据 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it mysql bash bash-5.1# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 8.4.0 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; create database redisDemo; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; use redisDemo; Database changed mysql\u0026gt; create table student ( -\u0026gt; id int not null primary key, -\u0026gt; name varchar(20), -\u0026gt; age int, -\u0026gt; score float -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into student (id,name,age,score) values(1,\u0026#39;Peter\u0026#39;,18,100); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert into student (id,name,age,score) values(2,\u0026#39;Tom\u0026#39;,17,90); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert into student (id,name,age,score) values(3,\u0026#39;John\u0026#39;,16,88); Query OK, 1 row affected (0.01 sec) # 查看数据,至此，mysql环境搭建完毕 mysql\u0026gt; select * from student; +----+-------+------+-------+ | id | name | age | score | +----+-------+------+-------+ | 1 | Peter | 18 | 100 | | 2 | Tom | 17 | 90 | | 3 | John | 16 | 88 | +----+-------+------+-------+ 3 rows in set (0.00 sec) 通过JDBC连接并操作Mysql数据库 沿用上面的pom.xml文件，确保有以下依赖，如果没有添加依赖\n1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public static void main(String[] args) { mysqlDemo(); } /** * MySQL演示函数 * 该函数演示了如何使用Java连接到MySQL数据库，并从数据库中检索数据 * 它首先加载数据库驱动，然后创建与数据库的连接，执行查询并打印结果 * 最后，它关闭数据库连接和相关资源 */ static void mysqlDemo() { // 显示定义MySQL数据库的JDBC驱动，不指定驱动也会自动注册 String driver = \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;; // 定义数据库连接URL String url = \u0026#34;jdbc:mysql://localhost:3306/redisDemo\u0026#34;; // 定义数据库用户名 String user = \u0026#34;root\u0026#34;; // 定义数据库密码 String password = \u0026#34;123456\u0026#34;; try { // 加载并注册JDBC驱动 Class.forName(driver); // 建立与数据库的连接 Connection conn = java.sql.DriverManager.getConnection(url, user, password); // 准备SQL语句，用于查询学生信息 PreparedStatement stmt = conn.prepareStatement(\u0026#34;select * from student\u0026#34;); // 执行查询并获取结果集 ResultSet rs = stmt.executeQuery(); // 遍历结果集，打印每个学生的详细信息 while (rs.next()) { System.out.print(\u0026#34;id:\u0026#34; + rs.getString(\u0026#34;id\u0026#34;) + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;name:\u0026#34; + rs.getString(\u0026#34;name\u0026#34;) + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;age:\u0026#34; + rs.getInt(\u0026#34;age\u0026#34;) + \u0026#34;,\u0026#34;); System.out.println(\u0026#34;score:\u0026#34; + rs.getString(\u0026#34;score\u0026#34;)); } // 关闭结果集、PreparedStatement和数据库连接，释放资源 rs.close(); stmt.close(); conn.close(); } catch (Exception e) { // 打印异常信息，用于调试和错误追踪 System.out.println(e); } } 引入Redis做缓存 定义一个和数据库中Student表对应的Student类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 import lombok.Data; @Data public class Student { private int id; private String name; private int age; private Float score; } /** * 数据库与Redis示例函数 * 此函数展示了如何从数据库中获取学生信息，并打印出来 * 它首先进行初始化，然后尝试从数据库中获取学生信息，并打印学生的ID、姓名、年龄和分数 * 注意：这个函数假设存在一个初始化函数init()和一个用于从数据库获取学生信息的函数getStudent(int id) */ static void mysqlRedisDemo() { init(); // 初始化环境或资源，为数据库操作做准备 for (int i = 1; i \u0026lt;= 2; i++) { // 循环两次，尝试获取学生信息，这里循环的次数可能基于特定需求或示例目的设定 Student student = getStudent(1); // 从数据库中获取指定ID为1的学生信息 if (student != null) { // 检查获取到的学生信息是否为空，不为空则打印信息 System.out.print(\u0026#34;id=\u0026#34; + student.getId() + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;name=\u0026#34; + student.getName() + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;age=\u0026#34; + student.getAge() + \u0026#34;,\u0026#34;); System.out.println(\u0026#34;score=\u0026#34; + student.getScore()); // 打印学生的各项信息 } } } static void init() { // 定义MySQL数据库的JDBC驱动 String driver = \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;; // 定义数据库连接URL String url = \u0026#34;jdbc:mysql://localhost:3306/redisDemo\u0026#34;; // 定义数据库用户名 String user = \u0026#34;root\u0026#34;; // 定义数据库密码 String password = \u0026#34;123456\u0026#34;; try { // 加载并注册JDBC驱动 Class.forName(driver); // 建立与数据库的连接 conn = java.sql.DriverManager.getConnection(url, user, password); jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); } catch (Exception e) { System.out.println(e); } } /** * 根据学生ID获取学生信息 * 首先尝试从Redis缓存中获取学生信息，如果缓存存在，则从Redis中读取并返回学生信息 * 如果Redis中不存在该学生信息，则从MySQL数据库中查询，并将结果缓存到Redis中 * * @param id 学生ID * @return 返回学生信息，如果找不到对应ID的学生，则返回null */ static Student getStudent(int id) { // 构建Redis中的学生信息键名 String key = \u0026#34;student:\u0026#34; + id; // 检查Redis中是否存在该学生信息 if (jedis.exists(key)) { System.out.println(\u0026#34;从redis中获取数据\u0026#34;); // 从Redis中获取学生信息，并映射到Student对象中 List\u0026lt;String\u0026gt; list = jedis.lrange(key, 0, 2); Student student = new Student(); student.setId(id); student.setName(list.get(0)); student.setAge(Integer.parseInt(list.get(1))); student.setScore(Float.parseFloat(list.get(2))); return student; } System.out.println(\u0026#34;从mysql中获取数据\u0026#34;); try { // 准备SQL语句，用于查询学生信息 PreparedStatement stmt = conn.prepareStatement(\u0026#34;select * from student where id=?\u0026#34;); stmt.setInt(1, id); // 执行查询并获取结果集 ResultSet rs = stmt.executeQuery(); // 遍历结果集，打印每个学生的详细信息 if (rs.next()) { // 创建Student对象，并填充从数据库查询到的信息 Student student = new Student(); student.setId(id); student.setName(rs.getString(\u0026#34;name\u0026#34;)); student.setAge(rs.getInt(\u0026#34;age\u0026#34;)); student.setScore(rs.getFloat(\u0026#34;score\u0026#34;)); // 将查询到的学生信息存入Redis缓存 jedis.rpush(key, student.getName(), String.valueOf(student.getAge()), String.valueOf(student.getScore())); return student; } else { System.out.println(\u0026#34;mysql数据库中没有找到该学生\u0026#34;); } } catch (SQLException e) { System.out.println(e); } return null; } // 运行程序，输出结果如下： 从mysql中获取数据 id=1,name=Peter,age=18,score=100.0 从redis中获取数据 id=1,name=Peter,age=18,score=100.0 // 可以看出第一次缓存中没有数据，先从mysql中获取数据，然后将结果存入redis,下次直接从redis中取结果 模拟缓存穿透现象 如果项目中引入了redis，那么多次请求相同数据且该数据存在于数据库的场景里能直接从Redis中读取数据，有效地降低对数据库的访问压力。在高并发的场景里，如果频繁地请求不存在于数据库的数据，就会引发缓存穿透的现象。 在上面的例子中，只存在id为1，2，3中的数据，如果请求id为4，5等不存在的数据，每次查询Redis缓存都不可能找到数据，所以都会继续向数据库发查询请求，高并发的查询请求会“穿透redis缓存”，集中到数据库上，这样就会给数据库造成很大的压力，严重时数据库甚至会崩溃，从而无法继续接受请求，造成严重的产线问题，这就是缓存穿透现象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 缓存穿透现象模拟，相当于高并发场景直接查询数据库 for (int i = 1; i \u0026lt;= 10000; i++) { int idNotExists=10; Student student = getStudent(idNotExists); // 从数据库中获取指定ID为10(不存在)的学生信息 if (student != null) { System.out.print(\u0026#34;id=\u0026#34; + student.getId() + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;name=\u0026#34; + student.getName() + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;age=\u0026#34; + student.getAge() + \u0026#34;,\u0026#34;); System.out.println(\u0026#34;score=\u0026#34; + student.getScore()); // 打印学生的各项信息 } } // 运行程序，输出结果如下： // 打印10000次，每次从数据库中获取指定ID为10(不存在)的学生信息，给数据库造成巨大压力 从mysql中获取数据 mysql数据库中没有找到该学生 ... 从mysql中获取数据 mysql数据库中没有找到该学生 模拟内存使用不当的场景 因为Redis是把数据存储到内存中的，所以从Redis缓存中读取数据的效率要高于Mysql数据库，如果每次在设置缓存时不设置超时时间，那么每次设置的缓存都会一直保存在内存中，久而久之，就会导致内存溢出问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /** * 演示Redis操作中的不当用法 * 此方法展示在使用Redis进行大量数据操作时，不当的内存管理可能导致的潜在问题 * 通过在循环中不断向Redis列表添加数据，可能导致JVM内存溢出 */ static void improperUse() { // 创建Redis客户端 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 打印当前JVM空闲内存量，单位为M System.out.println((Runtime.getRuntime().freeMemory() \u0026gt;\u0026gt; 20) + \u0026#34;M\u0026#34;); // 循环100000次，每次向Redis中添加数据 for (int i = 0; i \u0026lt; 100000; i++) { // 创建一个包含随机字符串的键 String key = \u0026#34;Stu:\u0026#34; + i; // 将键添加到Redis列表中 jedis.rpush(key, String.valueOf(i)); } // 再次打印JVM空闲内存量，单位为M System.out.println((Runtime.getRuntime().freeMemory() \u0026gt;\u0026gt; 20) + \u0026#34;M\u0026#34;); } // 运行程序，输出结果如下： // 这里可以看到内存是不断减少的，如果数据量更大，或者时间更长，极有可能造成OOM，所以redis中的数据一定要设置过期时间 502M 499M 4.Redis缓存实战分析 缓存不存在的键，以防穿透 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 static void avoidPenetrateDemo() { init(); // 缓存穿透现象模拟 for (int i = 1; i \u0026lt;= 3; i++) { int idNotExists = 10; Student student = getStudentV2(idNotExists); // 从数据库中获取指定ID为10(不存在)的学生信息 if (student != null) { System.out.print(\u0026#34;id=\u0026#34; + student.getId() + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;name=\u0026#34; + student.getName() + \u0026#34;,\u0026#34;); System.out.print(\u0026#34;age=\u0026#34; + student.getAge() + \u0026#34;,\u0026#34;); System.out.println(\u0026#34;score=\u0026#34; + student.getScore()); // 打印学生的各项信息 } } } static Student getStudentV2(int id) { // 构建Redis中的学生信息键名 String key = \u0026#34;studentV2:\u0026#34; + id; // 检查Redis中是否存在该学生信息 if (jedis.exists(key)) { System.out.println(\u0026#34;从redis中获取数据\u0026#34;); // 从Redis中获取学生信息，并映射到Student对象中 List\u0026lt;String\u0026gt; list = jedis.lrange(key, 0, 2); Student student = new Student(); student.setId(id); student.setName(list.get(0)); student.setAge(Integer.parseInt(list.get(1))); student.setScore(Float.parseFloat(list.get(2))); return student; } System.out.println(\u0026#34;从mysql中获取数据\u0026#34;); try { // 准备SQL语句，用于查询学生信息 PreparedStatement stmt = conn.prepareStatement(\u0026#34;select * from student where id=?\u0026#34;); stmt.setInt(1, id); // 执行查询并获取结果集 ResultSet rs = stmt.executeQuery(); // 遍历结果集，打印每个学生的详细信息 if (rs.next()) { // 创建Student对象，并填充从数据库查询到的信息 Student student = new Student(); student.setId(id); student.setName(rs.getString(\u0026#34;name\u0026#34;)); student.setAge(rs.getInt(\u0026#34;age\u0026#34;)); student.setScore(rs.getFloat(\u0026#34;score\u0026#34;)); // 将查询到的学生信息存入Redis缓存 jedis.rpush(key, student.getName(), String.valueOf(student.getAge()), String.valueOf(student.getScore())); return student; } else { // v2与上面的版本只有这里不同 jedis.rpush(key, \u0026#34;\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;); System.out.println(\u0026#34;mysql数据库中没有找到该学生\u0026#34;); } } catch (SQLException e) { System.out.println(e); } return null; } // 运行程序，输出结果如下： 从mysql中获取数据 mysql数据库中没有找到该学生 从redis中获取数据 id=10,name=,age=0,score=0.0 从redis中获取数据 id=10,name=,age=0,score=0.0 // 可以看到，只有第一次去数据库查询，后面都从redis缓存中查询，减轻了数据库压力，大大提升了查询效率 合理设置缓存超时时间，以防内存溢出 其他代码都一样，只是在保存到redis中之后，给key设置了缓存时间，jedis.expire(key,60*5); // 缓存5分钟,这样可以避免因对象永不过期而导致的内存溢出问题，对于缓存的时间合理性，需要根据业务需求合理设置，如果太长，依然会导致OOM，如果太短，缓存中的对象会过早失效，从而加重数据库的负担。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 遍历结果集，打印每个学生的详细信息 if (rs.next()) { // 创建Student对象，并填充从数据库查询到的信息 Student student = new Student(); student.setId(id); student.setName(rs.getString(\u0026#34;name\u0026#34;)); student.setAge(rs.getInt(\u0026#34;age\u0026#34;)); student.setScore(rs.getFloat(\u0026#34;score\u0026#34;)); // 将查询到的学生信息存入Redis缓存 jedis.rpush(key, student.getName(), String.valueOf(student.getAge()), String.valueOf(student.getScore())); jedis.expire(key,60*5); // 缓存5分钟 return student; } else { jedis.rpush(key, \u0026#34;\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;); jedis.expire(key,60*30); // 缓存30分钟 System.out.println(\u0026#34;mysql数据库中没有找到该学生\u0026#34;); } 超时时间外加随机数，以防穿透，造成缓存雪崩 所有的key都设置为相同的过期时间，有个很大的问题就是，如果在某一时刻，批量加入的一千万个缓存数据同时过期，那么这批数据同时失效，从而对这批数据的请求都会发送到数据库，如果此时并发负载比较重，那么数据库同样会崩溃。解决方法是设置超时时间时加一个随机数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 /** * 演示Redis键的随机过期时间设置 * 本方法旨在展示如何在Redis中设置键，并为每个键分配一个随机的过期时间 * 它首先清除Redis的所有现有数据，然后设置5个键，每个键的过期时间都是一个随机数加上一个固定值 * 之后，它通过休眠6秒来模拟超时，然后检查每个键是否仍然存在 * * @throws InterruptedException 如果线程在休眠期间被中断 */ static void randomExpireTimeDemo() throws InterruptedException { // 创建Jedis实例，连接到本地Redis服务器 Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;, 6379); // 清除Redis中的所有数据，以便开始新的演示 jedis.flushAll(); // 定义一个固定的过期时间秒数 int fixedTime = 5; // 循环5次，每次设置一个键和随机过期时间 for (int i = 0; i \u0026lt; 5; i++) { // 生成一个0到2之间的随机数，作为随机过期时间部分 int randomTime = (int) (Math.random() * 3); // 构造键名 String key = \u0026#34;stu:\u0026#34; + i; // 设置键值对 jedis.set(key, \u0026#34;value\u0026#34; + i); // 为键设置过期时间，是随机时间和固定时间之和 jedis.expire(key, randomTime + fixedTime); } // 休眠6秒,模拟超时，以便观察键的过期效果 Thread.sleep(6000); // 再次循环，检查并打印每个键是否存在 for (int i = 0; i \u0026lt; 5; i++) { // 构造键名 String key = \u0026#34;stu:\u0026#34; + i; // 检查键是否存在，并打印结果 if (jedis.exists(key)) { System.out.println(key + \u0026#34; exists.\u0026#34;); } else { System.out.println(key + \u0026#34; not exists.\u0026#34;); } } } // 运行程序，输出结果如下： stu:0 exists. stu:1 exists. stu:2 not exists. stu:3 exists. stu:4 not exists. // 可以看到，在常规超时时间后，并不是所有键同时失效，说明设置了随机过期时间，可以防止缓存穿透造成的雪崩。 ","date":"2024-08-14T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_08_java_mysql_redis/","title":"基于Docker的Redis实战--Java整合Mysql和Redis"},{"content":"搭建基于主从复制模式的集群 主从复制模式概述 主服务器（Master Server）：负责处理客户端的写请求，写入数据后，会复制到一台或多台Redis服务器。\n从服务器（Slave Server）：负责处理客户端的读请求，从主服务器复制数据。\n主从复制模式的优点：\n写操作集中在主服务器，读操作集中到从服务器，从而实现了读写分离，提升了读写性能。 因为存在数据备份，因此能提升数据的安全性，当主服务器故障时，可以很快切换到从服务器读取数据。 如果项目中并发要求不高，或者哪怕从Redis中读不到数据对性能也不会有太大损害，就可以使用一主一从。\n注意要点：\n一个主服务器可以带一个或多个从服务器，从服务器可以再带从服务器，但在复制时只能把主服务器上的数据复制到从服务器。 一台从服务器只能跟随一台主服务器，不能出现一从多主的模式。 Redis2.8以后的版本，采用异步的复制模式，进行主从复制时不会影响主服务器上的读写操作。 用命令搭建基于主从复制模式的集群 这里搭建一个一主二从模式的集群。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 # 创建主服务器master容器，占用6379端口 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name master -p 6379:6379 redis ee645f3b1c2a0c56f5eafb5766701e04c638a4b5b26556cf27735ac4f3454618 # 创建从服务器slave1容器，占用6380端口，因为这是模拟一主多从模式，所以宿主机的端口号必须区分开 # 实际项目中，一般多台Redis服务器会部署在不同的服务器上，所以都可以使用6379端口 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name slave1 -p 6380:6380 redis 1d054285a7754e35c130b9951d8f3b2e473c8f989a422c993068cff47d1850f6 # 创建从服务器slave2容器，占用6381端口 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name slave2 -p 6381:6381 redis c1b27efb7e6c112a83fac13fa1df4f8376faa291885933487d46478f260c568c # 通过docker inspect master可以查看主服务器的详细信息，通过IPAddress可知主服务器容器的IP地址是172.17.0.2 # 真实项目中Redis服务器的IP一般是固定的，而通过Docker容器启动的Redis服务器的IP是动态的，可以通过docker inspect 查看 # 进入master容器，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it master bash root@ee645f3b1c2a:/data# redis-cli 127.0.0.1:6379\u0026gt; info replication # Replication # 可以看出角色是主服务器 role:master # 可看出没有从服务器连接 connected_slaves:0 master_failover_state:no-failover master_replid:821b97303c65400fb0d83fcc05b01545326b6083 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 # 打开一个新的命令行窗口，进入slave1容器，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it slave1 bash root@1d054285a775:/data# redis-cli 127.0.0.1:6379\u0026gt; info replication # Replication # 可以看出和主服务器的信息一样，因为还没有设置主从模式，故此时还没区分主从服务器 role:master connected_slaves:0 master_failover_state:no-failover master_replid:59c0aa90a59be9ee610e0ea16f337f69e5116f1a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 # 在slave1容器中，通过slaveof命令设置slave1容器为master容器的从服务器，通过info replication命令查看Redis服务器的主从模式状态信息 127.0.0.1:6379\u0026gt; slaveof 172.17.0.2 6379 OK 127.0.0.1:6379\u0026gt; info replication # Replication # 可以看出角色是slave服务器，并且可以知道master服务器的IP地址和端口号 role:slave master_host:172.17.0.2 master_port:6379 master_link_status:up master_last_io_seconds_ago:8 #... 其他显示省略 # 再次进入master容器中，可以看到master容器中已经有一个从服务器了，并且能看到从服务器的详细信息 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=172.17.0.3,port=6379,state=online,offset=238,lag=1 # 最后进入slave2容器中，通过slaveof命令设置slave2容器为master容器的从服务器，通过info replication命令查看Redis服务器的主从模式状态信息 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it slave2 bash root@c1b27efb7e6c:/data# redis-cli 127.0.0.1:6379\u0026gt; slaveof 172.17.0.2 6379 OK 127.0.0.1:6379\u0026gt; info replication # Replication # 可以看出角色是slave服务器，并且可以知道master服务器的IP地址和端口号 role:slave master_host:172.17.0.2 master_port:6379 # 再次进入master容器中，可以看到master容器中已经有两个从服务器了，并且能看到从服务器的详细信息 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=172.17.0.3,port=6379,state=online,offset=630,lag=0 slave1:ip=172.17.0.4,port=6379,state=online,offset=630,lag=0 # 此时，在两个从服务器中执行get name,都返回nil， # 当在主服务器中执行set name farb，两个从服务器中执行get name，都返回farb 通过配置文件搭建主从集群 除了可以使用slaveof命令搭建主从模式的集群，也可以使用redis.conf配置文件来搭建主从模式的集群。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 强制删除上面创建的一主而从的容器，防止影响后面的实验 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker rm -f master slave1 slave2 master slave1 slave2 # 创建主服务器master容器，占用6379端口,通过docker inpect命令查看主服务器的详细信息，通过IPAddress可知主服务器容器的IP地址是172.17.0.2 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-master -p 6379:6379 redis # 在redisSlave1.conf中配置如下： port 6380 # redis-slave1服务器的端口号 slaveof 172.17.0.2 6379 # redis-slave1服务器的master服务器的IP地址和端口号 # 创建从服务器redis-slave1容器,并使用-v绑定redisSlave1.conf文件到容器中 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-slave1 -v D:\\ArchitectPracticer\\Redis\\RedisConfMasterSlave:/redisConfig:rw redis redis-server /redisConfig/redisSlave1.conf 1daa79fc05a9087ad4167ec5c4a5899935fbbb27c354667c94b0c8bf1100d207 # 进入redis-slave1容器中，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-slave1 bash # redics-cli 默认使用的地址是127.0.0.1:6379，所以会连接失败 root@1daa79fc05a9:/data# redis-cli Could not connect to Redis at 127.0.0.1:6379: Connection refused not connected\u0026gt; # 当前redisSlave1.conf中配置的端口是6380，所以需要通过-h指定主机地址，通过-p指定端口号 root@1daa79fc05a9:/data# redis-cli -h localhost -p 6380 # 可以看出角色是slave服务器，并且可以知道master服务器的IP地址和端口号 localhost:6380\u0026gt; info replication # Replication role:slave master_host:172.17.0.2 # 同样的方式创建redis-slave2服务器，在redisSlave2.conf中配置如下： port 6381 slaveof 172.17.0.2 6379 # 创建从服务器redis-slave2容器,并使用-v绑定redisSlave2.conf文件到容器中 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-slave2 -v D:\\ArchitectPracticer\\Redis\\RedisConfMasterSlave:/redisConfig:rw redis redis-server /redisConfig/redisSlave2.conf 8636a97f6e2d7ba10231b330d248f4e37ff2f2477ae74c87d1aae18227f44c99 # 进入redis-slave2容器中，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-slave2 bash root@8636a97f6e2d:/data# redis-cli -h localhost -p 6381 localhost:6381\u0026gt; info replication # Replication role:slave master_host:172.17.0.2 master_port:6379 # 再次回到redis-master容器中，通过info replication命令查看Redis服务器的主从模式状态信息 # 可以看到已经和redis-slave1和redis-slave2建立了主从模式的关系 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=172.17.0.3,port=6380,state=online,offset=14,lag=0 slave1:ip=172.17.0.4,port=6381,state=online,offset=14,lag=0 # 此时，在redis-master执行set age 18，redis-slave1和redis-slave2执行get age，都返回18 配置读写分离效果 默认搭建好主从复制模式的集群后， 主服务器是可读可写的，而从服务器是只读的。如果对从服务器执行set等写命令，会报错。当然，如果确实需要，也可以将从服务器的只读属性设置为可读可写。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 进入redis-slave1容器中，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 localhost:6380\u0026gt; info replication # Replication role:slave master_host:172.17.0.2 master_port:6379 master_link_status:down master_last_io_seconds_ago:-1 master_sync_in_progress:0 slave_read_repl_offset:14 slave_repl_offset:14 master_link_down_since_seconds:-1 slave_priority:100 # 可以看到slave_read_only属性为1，表示从服务器是只读的 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:0d4ffddabfc229c371de8e1ee4d411424ad14261 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:14 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 # 默认为只读模式，所以无法执行写操作 localhost:6380\u0026gt; set sex male (error) READONLY You can\u0026#39;t write against a read only replica. # 通过redis.conf配置文件，将slave-read-only属性设置为no，表示从服务器是可读可写的 slave-read-only no #重启redis-slave1容器，通过redis-cli命令进入Redis客户端，并再次执行set sex male localhost:6380\u0026gt; get sex (nil) localhost:6380\u0026gt; set sex male OK localhost:6380\u0026gt; get sex \u0026#34;male\u0026#34; # 分别进入redis-master和redis-slave2容器中，执行get sex均返回nil,说明写入从服务器的数据不会进行任何同步操作。 用心跳机制提高主从复制的可靠性 主从复制的模式里，从服务器会默认以一秒一次的频率向主服务器发送REPLCONF ACK命令，来确保主服务器和从服务器之间的连接。这种定时交互命令确保连接的机制叫做“心跳”机制。在主服务器中执行info replication命令，可以看到从属于它的从服务器的“心跳”状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=172.17.0.3,port=6380,state=online,offset=14,lag=0 slave1:ip=172.17.0.4,port=6381,state=online,offset=14,lag=0 # 通过上面的lag=0，可知主从服务器之间连接畅通，延迟都是0秒 # 创建主服务器的配置文件redisMaster.conf，配置如下： min-slaves-to-write 2 # 连接到主服务器的从服务器最少需要2个，否则主服务器将拒绝同步操作 min-slaves-max-lag 15 # 从服务器与主服务器之间的最大延迟不能超过15秒 # 以上两个条件是“或”的关系，只要一个条件不满足就停止主从复制的操作。 # 重新创建并启动redis-master容器，并使用-v绑定redisMaster.conf文件到容器中 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-master -v D:\\ArchitectPracticer\\Redis\\RedisConfMasterSlave:/redisConfig:rw -p 6379:6379 redis redis-server /redisConfig/redisMaster.conf 24ea09c6e60202c13e04ff52339e397dcc539da6376444e03d9fe66e58be59d3 # 主服务器写入set k1 v1 成功后，redis-slave1和redis-slave2均可读取数据 127.0.0.1:6379\u0026gt; set k1 v1 OK # shutdown redis-slave2服务器后，再次在主服务器执行set命令，发现报错。因为违反了配置中的min-slaves-to-write 2 127.0.0.1:6379\u0026gt; set k2 v2 (error) NOREPLICAS Not enough good replicas to write. 用偏移量检查数据是否一致 master_repl_offset：主服务器向从服务器发送的字节数\nslave_repl_offset: 从服务器接收到来来自主服务器发送的字节数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 进入redis-master容器中，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 # 可以看到主服务器向从服务器发送了字节数906 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 min_slaves_good_slaves:2 slave0:ip=172.17.0.2,port=6380,state=online,offset=906,lag=1 slave1:ip=172.17.0.4,port=6381,state=online,offset=906,lag=1 ... master_repl_offset:906 # 分别进入redis-slave1容器中，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息 # 应该可以看到slave_repl_offset的值也是906（前提是没有对从服务器执行写操作，且主从服务器数据一直同步，否则可能会不一致） 搭建哨兵模式的集群 基于主从复制+读写分离模式的集群，一旦主服务器发生故障，则需要手动切换到从服务器上，同时需要重新设置主从关系。如果采用哨兵模式，则不需要手动切换，当主服务器发生故障时，哨兵会自动切换到从服务器上，实现“故障自动恢复”的效果，保证集群的高可用性。\n哨兵模式概述 哨兵机制一般和主从复制模式整合使用，在基于哨兵的模式里会在一台或多台服务器上引入哨兵进程，这些节点叫哨兵节点。 哨兵节点一般不存储数据，主要作用是监控主从模式里的主服务器节点(哨兵节点之间也相互监控)。当哨兵节点监控的主服务器发生故障时，哨兵节点会主导“故障自动恢复”的过程，具体来讲就是会通过选举模式在该主服务器下属的从服务器中选择一个作为新的主服务器，并完成相应的数据和配置等更改操作。 基于哨兵模式的集群，可以让故障自动恢复，从而提升系统的可用性。实际项目中一般会配置多个主从模式集群，所以需要引入多个哨兵节点。\n搭建哨兵模式集群实战 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 清理环境，删除所有容器避免影响，使用 docker rm $(docker ps -aq) 或 docker container prune -f 命令 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker rm $(docker ps -aq) 2f25343c996e aa62f3456cb4 25bd36e835b9 # 按照上面的实战，再次创建一个一主二从的主从复制模式 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-master -v D:\\ArchitectPracticer\\Redis\\RedisConfSentinel:/redisConfig:rw -p 6379:6379 redis redis-server /redisConfig/redisMaster.conf 8227be97fad3ca13872c2c304d0f49fd918521ed31ca5ea51914d9bd7ed701a6 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-slave1 -v D:\\ArchitectPracticer\\Redis\\RedisConfSentinel:/redisConfig:rw -p 6380:6380 redis redis-server /redisConfig/redisSlave1.conf 4ce5f884fb26bd3760047e4c93b95356b3b70048f423c2fdff40e8cb8ec76b37 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-slave2 -v D:\\ArchitectPracticer\\Redis\\RedisConfSentinel:/redisConfig:rw -p 6381:6381 redis redis-server /redisConfig/redisSlave2.conf 6470580ea30f9903aa64b7d54ca5ecbd8777cbef0cea8ecd891cdcd07337793a # 进入redis-master容器中，通过redis-cli命令进入Redis客户端，通过info replication命令查看Redis服务器的主从模式状态信息,确保主从复制模式已经搭建成功 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-master bash root@8227be97fad3:/data# redis-cli 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 min_slaves_good_slaves:2 slave0:ip=172.17.0.3,port=6380,state=online,offset=196,lag=1 slave1:ip=172.17.0.4,port=6381,state=online,offset=196,lag=0 master_failover_state:no-failover master_replid:65bf7b2a0d40228c859adf93672af1fa88601443 master_replid2:0000000000000000000000000000000000000000 基础的主从复制模式搭建完成后，下面开始哨兵的搭建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 port 16379 # 哨兵节点的工作端口是16379 sentinel monitor master 172.17.0.2 6379 2 # 哨兵节点监控主服务器，主机ip是172.17.0.2，端口是6379，集群中至少2个哨兵节点才能确定该主服务器是否故障 dir / logfile \u0026#34;sentinel1.log\u0026#34; # 哨兵节点日志文件位置和名称 # 创建并启动哨兵节点容器，通过-v挂载了D:\\ArchitectPracticer\\Redis\\RedisConfSentinel目录 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name sentinel1 -v D:\\ArchitectPracticer\\Redis\\RedisConfSentinel:/redisConfig:rw -p 16379:16379 redis redis-sentinel /redisConfig/sentinel1.conf 59caeda82a6111e9e1c324e0c580e2591f4a4c7ba3dcc52d4f5e3cddb9c6e463 # 进入sentinel1容器中，通过redis-cli命令进入Redis客户端，通过info sentinel命令查看Redis服务器的哨兵模式状态信息 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it sentinel1 bash root@59caeda82a61:/data# redis-cli -h localhost -p 16379 localhost:16379\u0026gt; info sentinel # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_tilt_since_seconds:-1 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=master,status=ok,address=172.17.0.2:6379,slaves=2,sentinels=1 # 最后一句可以看到该主服务器的状态是ok，说明哨兵节点已经成功监控到主服务器，并且该主服务器的ip和端口也可看到，该主服务器下有2个从服务器，并且有一个哨兵节点 # 同样地，创建sentinel2.conf配置文件 port 16380 sentinel resolve-hostnames yes sentinel monitor master 172.17.0.2 6379 2 dir \u0026#34;/\u0026#34; logfile \u0026#34;sentinel2.log\u0026#34; # 创建并启动第二个哨兵节点容器，通过-v挂载了D:\\ArchitectPracticer\\Redis\\RedisConfSentinel目录 docker run -itd --name sentinel2 -v D:\\ArchitectPracticer\\Redis\\RedisConfSentinel:/redisConfig:rw -p 16380:16380 redis redis-sentinel /redisConfig/sentinel2.conf 2a742a70e80989b868a394856e95d97c58be40e1b892025463ab22646f85c759 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it sentinel2 bash root@2a742a70e809:/data# redis-cli -h localhost -p 16380 localhost:16380\u0026gt; info sentinel # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_tilt_since_seconds:-1 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=master,status=ok,address=172.17.0.2:6379,slaves=2,sentinels=2 # 最后一句可以看到该主服务器的状态是ok，说明哨兵节点已经成功监控到主服务器，并且该主服务器的ip和端口也可看到，该主服务器下有2个从服务器，并且有2个哨兵节点 至此，基于哨兵的一主二从的Redis集群已经搭建完成：两个哨兵节点sentinel1和sentinel2同时监控redis-master主服务器，主服务器下挂着两个从服务器redis-slave1和redis-slave2，并且主服务器和两个从服务器之间依然存在“主从复制模式”。实际项目里可以让哨兵节点监控多个集群\n哨兵节点的常用配置 1 2 3 4 5 6 7 # 哨兵节点监控主服务器后，如果主服务器挂了，需要多久才能确定该主服务器已经故障 ， # master是哨兵节点监控的服务器名称，需要和sentinel monitor命令中设置的服务器名称master一致 # 之前配置了 sentinel monitor master 172.17.0.2 6379 2，因而至少2个哨兵节点都超过60s没有收到master的响应，才能确定该主服务器已经故障 sentinel down-after-milliseconds master 60000 # 哨兵节点监控主服务器后，如果主服务器故障了，必须在180s内自动切换到其他从服务器，否则认定本次恢复动作失败。 sentinel failover-timeout master 180000 哨兵模式下的故障自动恢复效果 将redis-server容器停止或通过shutdown命令关闭redis-master，通过info sentinel命令观察哨兵节点的日志，通过info replication命令观察主从复制的状态信息，来确认哨兵节点的故障自动恢复效果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 关闭redis-master容器 127.0.0.1:6379\u0026gt; shutdown # 进入sentinel1容器，通过info sentinel命令观察哨兵节点的日志，发现主服务器已经由之前的主服务器172.17.0.2:6379，变成了新的主服务器172.17.0.3:6380 localhost:16379\u0026gt; info sentinel # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_tilt_since_seconds:-1 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=master,status=ok,address=172.17.0.3:6380,slaves=2,sentinels=2 #进入sentinel2容器，能够看到相同的信息。 # 进入redis-slave1容器，通过info replication命令观察主从复制的状态信息，发现redis-slave1已经成为主服务，并且之前的redis-slave2已经成为从服务器 localhost:6380\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=172.17.0.4,port=6381,state=online,offset=315538,lag=0 # 进入redis-slave2容器，通过info replication命令观察主从复制的状态信息，也发现redis-slave1已经成为主服务器 redis-cli -h localhost -p 6381 localhost:6381\u0026gt; info replication # Replication role:slave master_host:172.17.0.3 master_port:6380 master_link_status:up 通过上述实践，发现故障已经自动恢复\n通过日志观察故障恢复流程 通过观察哨兵的日志，查看故障自动恢复的流程\n关键词：\nsdown：主观宕机subjective down odown: 客观宕机objective down failover: 故障转移 vote-for-leader： 领导选举 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # 先查看sentinel2.log日志 root@2a742a70e809:/data# cat /sentinel2.log 1:X 03 Aug 2024 03:44:13.749 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 1:X 03 Aug 2024 03:44:13.749 * Redis version=7.2.5, bits=64, commit=00000000, modified=0, pid=1, just started 1:X 03 Aug 2024 03:44:13.749 * Configuration loaded 1:X 03 Aug 2024 03:44:13.749 * monotonic clock: POSIX clock_gettime 1:X 03 Aug 2024 03:44:13.749 * Running mode=sentinel, port=16380. 1:X 03 Aug 2024 03:44:13.749 * Sentinel ID is 750555c54a6c4e294749888502b1644dfd0f3ac7 1:X 03 Aug 2024 03:44:13.749 # +monitor master master 172.17.0.2 6379 quorum 2 1:X 03 Aug 2024 03:44:13.751 * +slave slave 172.17.0.3:6380 172.17.0.3 6380 @ master 172.17.0.2 6379 1:X 03 Aug 2024 03:44:13.756 * Sentinel new configuration saved on disk 1:X 03 Aug 2024 03:44:13.756 * +slave slave 172.17.0.4:6381 172.17.0.4 6381 @ master 172.17.0.2 6379 1:X 03 Aug 2024 03:44:13.760 * Sentinel new configuration saved on disk 1:X 03 Aug 2024 03:44:14.780 * +sentinel sentinel fc41e2130b8b8896db18204e1b1ca868161369e2 172.17.0.5 16379 @ master 172.17.0.2 6379 1:X 03 Aug 2024 03:44:14.784 * Sentinel new configuration saved on disk # 主服务器redis-master被sentinel2节点主观下线 1:X 03 Aug 2024 04:18:54.656 # +sdown master master 172.17.0.2 6379 # 主服务器redis-master被sentinel2节点客观下线，因为此时sentinel1节点也认为主观下线，共有两个节点满足主观下线条件quorum 2/2，从而客观下线 1:X 03 Aug 2024 04:18:54.727 # +odown master master 172.17.0.2 6379 #quorum 2/2 1:X 03 Aug 2024 04:18:54.727 # +new-epoch 1 # 尝试故障转移 1:X 03 Aug 2024 04:18:54.727 # +try-failover master master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:54.732 * Sentinel new configuration saved on disk # 领导选举 1:X 03 Aug 2024 04:18:54.732 # +vote-for-leader 750555c54a6c4e294749888502b1644dfd0f3ac7 1 1:X 03 Aug 2024 04:18:54.738 * fc41e2130b8b8896db18204e1b1ca868161369e2 voted for 750555c54a6c4e294749888502b1644dfd0f3ac7 1 1:X 03 Aug 2024 04:18:54.815 # +elected-leader master master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:54.815 # +failover-state-select-slave master master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:54.887 # +selected-slave slave 172.17.0.3:6380 172.17.0.3 6380 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:54.887 * +failover-state-send-slaveof-noone slave 172.17.0.3:6380 172.17.0.3 6380 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:54.958 * +failover-state-wait-promotion slave 172.17.0.3:6380 172.17.0.3 6380 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:55.604 * Sentinel new configuration saved on disk 1:X 03 Aug 2024 04:18:55.604 # +promoted-slave slave 172.17.0.3:6380 172.17.0.3 6380 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:55.604 # +failover-state-reconf-slaves master master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:55.662 * +slave-reconf-sent slave 172.17.0.4:6381 172.17.0.4 6381 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:55.880 # -odown master master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:56.656 * +slave-reconf-inprog slave 172.17.0.4:6381 172.17.0.4 6381 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:56.656 * +slave-reconf-done slave 172.17.0.4:6381 172.17.0.4 6381 @ master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:56.739 # +failover-end master master 172.17.0.2 6379 # 切换主服务器到新的主服务器172.17.0.3:6380 1:X 03 Aug 2024 04:18:56.739 # +switch-master master 172.17.0.2 6379 172.17.0.3 6380 1:X 03 Aug 2024 04:18:56.739 * +slave slave 172.17.0.4:6381 172.17.0.4 6381 @ master 172.17.0.3 6380 1:X 03 Aug 2024 04:18:56.739 * +slave slave 172.17.0.2:6379 172.17.0.2 6379 @ master 172.17.0.3 6380 1:X 03 Aug 2024 04:18:56.743 * Sentinel new configuration saved on disk 1:X 03 Aug 2024 04:19:26.747 # +sdown slave 172.17.0.2:6379 172.17.0.2 6379 @ master 172.17.0.3 6380 # 查看senttinel1.log日志 # 主服务器redis-master被sentinel1节点主观下线,可以看到比sentinel2节点快了1毫秒 1:X 03 Aug 2024 04:18:54.655 # +sdown master master 172.17.0.2 6379 1:X 03 Aug 2024 04:18:54.735 * Sentinel new configuration saved on disk 1:X 03 Aug 2024 04:18:54.735 # +new-epoch 1 1:X 03 Aug 2024 04:18:54.738 * Sentinel new configuration saved on disk # 领导选举 1:X 03 Aug 2024 04:18:54.738 # +vote-for-leader 750555c54a6c4e294749888502b1644dfd0f3ac7 1 1:X 03 Aug 2024 04:18:55.663 # +config-update-from sentinel 750555c54a6c4e294749888502b1644dfd0f3ac7 172.17.0.6 16380 @ master 172.17.0.2 6379 # 切换主服务器到新的主服务器172.17.0.3:6380 1:X 03 Aug 2024 04:18:55.663 # +switch-master master 172.17.0.2 6379 172.17.0.3 6380 1:X 03 Aug 2024 04:18:55.663 * +slave slave 172.17.0.4:6381 172.17.0.4 6381 @ master 172.17.0.3 6380 1:X 03 Aug 2024 04:18:55.663 * +slave slave 172.17.0.2:6379 172.17.0.2 6379 @ master 172.17.0.3 6380 # 由于只能由一个哨兵节点完成故障自动恢复，因此如果有多个哨兵节点同时监控到主服务器失效，那么最终只有一个哨兵节点通过竞争得到故障恢复的权力。 # 从上面的日志中，可以看到故障恢复的权力已经被sentinel2节点竞争得到，sentinel1只能在sdown之后处于停留状态，待sentinel2节点完成故障恢复之后重新切换到新的主服务器节点，继续监控新的主服务器节点和对应的从服务器节点 。 故障节点恢复后的表现 从上面的日志中可以看到redis-master服务器处于失效状态，但是在新的主从复制集群里会把该服务器当作从服务器。再重新启动redis-master容器，模拟故障排除后的效果。\n1 2 3 4 5 6 7 8 # 可以看到，redis-master重启后，自动以slave的身份接入。 redis-cli -h localhost -p 6380 localhost:6380\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=172.17.0.4,port=6381,state=online,offset=3096199,lag=1 slave1:ip=172.17.0.2,port=6379,state=online,offset=3096199,lag=1 由上可知，哨兵节点不仅能自动恢复故障，而且当故障节点恢复后，会自动把它加入到集群中，而无需人工干预。与简单的主从复制模式集群相比，哨兵模式的集群能更好地提升系统的可靠性。\n搭建Cluster集群 相比哨兵模式，cluster集群能支持扩容，且无需额外的节点来监控状态。\n哈希槽和cluster集群 cluster集群里有16384个哈希槽（hash slot），在写入数据时，会先用CRC16算法对key进行运算，并用16384对运算结果进行模运算，最终结果作为哈希槽的索引，将数据存入对应的哈希槽中。slotIndex=Hash_Slot=CRC16(key) % 16384。这里说的cluster集群有16384个哈希槽，并不意味着集群中一定要有16374个节点，哈希槽是虚拟的，是会被分配到若干台集群中的机器中的。\n比如，某cluster集群由三台Redis服务器组成，平均每台服务器可以分配16384/3=5461个哈希槽。由于哈希槽编号从0开始，所以编号[0,5460]会分配给第一台服务器，编号[5461,10922]分配给第二台服务器，[10923,16383]分配给第三台服务器。同理，如果有6台Redis服务器，平均每个服务器可以分配16384/6=2730个哈希槽。此外，cluster也支持主从复制，即分配到一定数量的Redis主服务器也可以携带一个或多个从服务器。如下图是一个三主三从的cluster集群。\n初步搭建cluster集群 搭建如上图所示的三主三从的cluster集群，其他类型的依次类推。\n** 1.首先创建三主三从服务器的配置文件**\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # 主服务器1的配置文件 clusterMaster1.conf port 6379 dir /redisConfig # 日志存放目录 logfile clusterMaster1.log # 日志文件名 cluster-enabled yes # 开启集群模式 cluster-config-file nodes-clusterMaster1.conf # 集群相关的配置文件，会自动生成 # 主服务器2的配置文件 clusterMaster2.conf port 6380 dir /redisConfig logfile clusterMaster2.log cluster-enabled yes cluster-config-file nodes-clusterMaster2.conf # 主服务器3的配置文件 clusterMaster3.conf port 6381 dir /redisConfig logfile clusterMaster3.log cluster-enabled yes cluster-config-file nodes-clusterMaster3.conf # 从服务器1的配置文件 clusterSlave1.conf port 16379 dir /redisConfig logfile clusterSlave1.log cluster-enabled yes cluster-config-file nodes-clusterSlaver1.conf # 从服务器2的配置文件 clusterSlave2.conf port 16380 dir /redisConfig logfile clusterSlave2.log cluster-enabled yes cluster-config-file nodes-clusterSlave2.conf # 从服务器3的配置文件 clusterSlave3.conf port 16381 dir /redisConfig logfile clusteSlave3.log cluster-enabled yes cluster-config-file nodes-clusterSlave3.conf 2. 启动集群中的每个容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 分别启动clusterMaster1 clusterMaster2 clusterMaster3 clusterSlave1 clusterSlave2 clusterSlave3 6个容器 # 每个容器只是容器名称，端口号和配置文件不同 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name clusterMaster1 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw -p 6379:6379 redis redis-server /redisConfig/clusterMaster1.conf fb368ad5ad39950afced6ca59c9be133d8440623f0f4aedd008cec2b6bcdd735 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name clusterMaster2 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw -p 6380:6380 redis redis-server /redisConfig/clusterMaster2.conf ccb9bf970d30c6273b5d7b9e82d3729520c53cb440a49766cc4e0c21f55d23d8 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name clusterMaster3 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw -p 6381:6381 redis redis-server /redisConfig/clusterMaster3.conf dcd5903265bf75182ded211dfb7728f97fc734f926bcba813332fe7cdb898aeb PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name clusterSlave1 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw -p 16379:16379 redis redis-server /redisConfig/clusterSlave1.conf 5d2ecf9131f7069cf410940fad6a85a48e7292fac4b709cc60116ebd57ffca92 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name clusterSlave2 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw -p 16380:16380 redis redis-server /redisConfig/clusterSlave2.conf 44e2e24b798af85be78c2c364e15440cf11447a645567d527833a5b95548dbef PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name clusterSlave3 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw -p 16381:16381 redis redis-server /redisConfig/clusterSlave3.conf ef29a379b55728b20833f4d2b90846d8de034ae9652a76c0acedbd80c53ee5ce # 查看容器列表，确保6个容器都处于Up状态 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ef29a379b557 redis \u0026#34;docker-entrypoint.s…\u0026#34; 3 minutes ago Up 3 minutes 6379/tcp, 0.0.0.0:16381-\u0026gt;16381/tcp clusterSlave3 44e2e24b798a redis \u0026#34;docker-entrypoint.s…\u0026#34; 4 minutes ago Up 4 minutes 6379/tcp, 0.0.0.0:16380-\u0026gt;16380/tcp clusterSlave2 5d2ecf9131f7 redis \u0026#34;docker-entrypoint.s…\u0026#34; 4 minutes ago Up 4 minutes 6379/tcp, 0.0.0.0:16379-\u0026gt;16379/tcp clusterSlave1 dcd5903265bf redis \u0026#34;docker-entrypoint.s…\u0026#34; 5 minutes ago Up 5 minutes 6379/tcp, 0.0.0.0:6381-\u0026gt;6381/tcp clusterMaster3 ccb9bf970d30 redis \u0026#34;docker-entrypoint.s…\u0026#34; 6 minutes ago Up 6 minutes 6379/tcp, 0.0.0.0:6380-\u0026gt;6380/tcp clusterMaster2 fb368ad5ad39 redis \u0026#34;docker-entrypoint.s…\u0026#34; 2 hours ago Up 2 hours 0.0.0.0:6379-\u0026gt;6379/tcp clusterMaster1 # 打开nodes-clusterMaster1.conf文件，如下： 8b9e6e09898be857fcd33e4a2611c42268ce7b1c :0@0,,tls-port=0,shard-id=358d229be66be4999268253234d3bb58623dbe83 myself,master - 0 0 0 connected vars currentEpoch 0 lastVoteEpoch 0 # 可以看到，当前节点属于master节点，只连接到myself自身，没同其他节点关联。其他nodes-*.conf文件类似，都是master节点，没有关联其他节点。稍后将用meet命令关联。 3.使用redis-cli \u0026ndash;cluster create命令创建集群 使用 docker inspect -f '{{.NetworkSettings.IPAddress}}' containerName 查看容器的IP地址\n1 2 3 4 5 6 7 8 9 10 11 12 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; clusterMaster1 172.17.0.2 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; clusterMaster2 172.17.0.3 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; clusterMaster3 172.17.0.4 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; clusterSlave1 172.17.0.5 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; clusterSlave2 172.17.0.6 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; clusterSlave3 172.17.0.7 为便于查看，列出统计表格如下：\n节点名称 IP地址 端口 查看Ip地址所用的Docker命令 clusterMaster1 172.17.0.2 6379 docker inspect -f \u0026lsquo;{{.NetworkSettings.IPAddress}}\u0026rsquo; clusterMaster1 clusterMaster2 172.17.0.3 6380 docker inspect -f \u0026lsquo;{{.NetworkSettings.IPAddress}}\u0026rsquo; clusterMaster2 clusterMaster3 172.17.0.4 6381 docker inspect -f \u0026lsquo;{{.NetworkSettings.IPAddress}}\u0026rsquo; clusterMaster3 clusterSlave1 172.17.0.5 16379 docker inspect -f \u0026lsquo;{{.NetworkSettings.IPAddress}}\u0026rsquo; clusterSlave1 clusterSlave2 172.17.0.6 16380 docker inspect -f \u0026lsquo;{{.NetworkSettings.IPAddress}}\u0026rsquo; clusterSlave2 clusterSlave3 172.17.0.7 16381 docker inspect -f \u0026lsquo;{{.NetworkSettings.IPAddress}}\u0026rsquo; clusterSlave3 之后，进入clusterMaster1节点，使用\u0026ndash;cluster create命令连接各个节点，这样所有的节点就在一个集群了。这里我也使用过cluster meet命令，但是使用这种方式后扩容时，添加的节点一直是从节点，具体原因未知\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # 进入clusterMaster1节点，创建集群，注意此处还没有设置主从关系，这里设置的是--cluster-replicas 0 # 为的是想要创建6379(主)-16379(从)这样的对应关系，否则如果交给redis-cli自动处理的话，会出现端口端口随机配对的情况 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it clusterMaster1 bash root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster create --cluster-replicas 0 172.17.0.2:6379 172.17.0.3:6380 172.17.0.4:6381 \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 3 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[0-5460] (5461 slots) master M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.2:6379) M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[0-5460] (5461 slots) master M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. # 从上面可以看出redis-cli会根据你输入的yes，自动给三个主节点平均分配哈希槽 # 然后查看clusterMaster节点的cluster info。 root@fb368ad5ad39:/data# redis-cli 127.0.0.1:6379\u0026gt; cluster info # 集群状态是fail cluster_state:fail # 分配的哈希槽为0 cluster_slots_assigned:0 cluster_slots_ok:0 cluster_slots_pfail:0 cluster_slots_fail:0 # 可以看到集群中有6个节点，但是集群状态是fail，说明集群还没有完成初始化。 # 原因是还没给每个节点分配哈希槽（Hash Slot） cluster_known_nodes:6 # cluster nodes查看节点信息，可以看到三个主节点 127.0.0.1:6379\u0026gt; cluster nodes 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723297213811 2 connected 5461-10922 e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723297212809 3 connected 10923-16383 b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723297211000 1 connected 0-5460 4.为三个主节点分配从节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 # 为主节点172.17.0.2:6379配置从节点172.17.0.5:16379 # 172.17.0.5:16379为要添加的从节点IP和端口 # 172.17.0.2:6379为要添加的从节点所属集群的任意一个节点的IP和端口 # --cluster-master-id b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c为要添加的从节点对应的主节点ID root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster add-node 172.17.0.5:16379 172.17.0.2:6379 --cluster-slave --cluster-master-id b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c \u0026gt;\u0026gt;\u0026gt; Adding node 172.17.0.5:16379 to cluster 172.17.0.2:6379 \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.2:6379) M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[0-5460] (5461 slots) master M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. \u0026gt;\u0026gt;\u0026gt; Send CLUSTER MEET to node 172.17.0.5:16379 to make it join the cluster. Waiting for the cluster to join . \u0026gt;\u0026gt;\u0026gt; Configure node as replica of 172.17.0.2:6379. [OK] New node added correctly. # 通过输出信息，可以看到添加从节点成功，也可以通过cluster nodes验证 127.0.0.1:6379\u0026gt; cluster nodes 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723297831286 2 connected 5461-10922 e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723297830283 3 connected 10923-16383 b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723297828000 1 connected 0-5460 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723297832289 1 connected # 按照如上步骤，依次添加另外两个从节点172.17.0.6:16380和172.17.0.7:16381 root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster add-node 172.17.0.6:16380 172.17.0.2:6379 --cluster-slave --cluster-master-id 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster add-node 172.17.0.7:16381 172.17.0.2:6379 --cluster-slave --cluster-master-id e2737cdc7073c3750ffb670bc618dc28cc939877 # 执行成功后，可以看到三主三从的集群搭建成功 127.0.0.1:6379\u0026gt; cluster nodes e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723298034325 3 connected 10923-16383 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723298033323 1 connected 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723298035332 2 connected fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723298033000 3 connected b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723298033000 1 connected 0-5460 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723298035000 2 connected 5461-10922 # 也可以这样查看 redis-cli --cluster check nodeHost:nodePort root@fb368ad5ad39:/data# redis-cli --cluster check 172.17.0.2:6379 172.17.0.2:6379 (b6d4a069...) -\u0026gt; 0 keys | 5461 slots | 1 slaves. 172.17.0.4:6381 (e2737cdc...) -\u0026gt; 0 keys | 5461 slots | 1 slaves. 172.17.0.3:6380 (8ba84e5b...) -\u0026gt; 0 keys | 5462 slots | 1 slaves. [OK] 0 keys in 3 masters. 0.00 keys per slot on average. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.2:6379) M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379 slots: (0 slots) slave replicates b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c S: 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380 slots: (0 slots) slave replicates 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c S: fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381 slots: (0 slots) slave replicates e2737cdc7073c3750ffb670bc618dc28cc939877 M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. 在cluster中读写数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 进入clusterSlave1容器，然后执行redis-cli -p 16379 root@5d2ecf9131f7:/data# redis-cli -p 16379 127.0.0.1:16379\u0026gt; set name farb # 写入数据时发现报错了，name应该放到哈希槽编号5798的主节点，该主节点的ip地址是172.17.0.3，端口是6380，但是一般来说用户希望透明地进行读写而不报错 (error) MOVED 5798 172.17.0.3:6380 127.0.0.1:16379\u0026gt; exit # 添加-c参数，表示开启集群模式，然后执行set name farb，发现写入成功 root@5d2ecf9131f7:/data# redis-cli -p 16379 -c 127.0.0.1:16379\u0026gt; set name farb -\u0026gt; Redirected to slot [5798] located at 172.17.0.3:6380 OK 172.17.0.3:6380\u0026gt; get name \u0026#34;farb\u0026#34; # 以上可以看到，redis-cli -c参数，在读或写时会自动地把数据定位到正确的服务器上，这种“自动定位”带来的“读写透明”效果正是开发项目所需要的。 模拟扩容和数据迁移动作 上面搭建的是3主3从的集群，键的读写会均摊到3个主节点上，cluster集群能很好地应对高并发的挑战。随着业务量的增大，对cluster集群的访问压力可能会增大，此时就需要对集群新增节点来承受更大的并发量。\n现在模拟扩容和数据迁移动作，扩容集群，添加一个主节点clusterMaster4和从节点clusterSlave4，然后把数据迁移到新节点上。\n1.新增主节点clusterMaster4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # D:\\ArchitectPracticer\\Redis\\RedisConfCluster目录下创建clusterMaster4.conf文件，内容如下 port 6382 dir /redisConfig logfile clusterMaster4.log cluster-enabled yes cluster-config-file nodes-clusterMaster4.conf cluster-require-full-coverage no appendonly yes appendfsync everysec cluster-slave-validity-factor 0 # 创建并运行容器 docker run -itd -p 6382:6382 --name clusterMaster4 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw redis redis-server /redisConfig/clusterMaster4.conf # 查看容器IP PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; clusterMaster4 172.17.0.8 2.新增从节点clusterSlave4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # D:\\ArchitectPracticer\\Redis\\RedisConfCluster目录下创建clusterSlave4.conf文件，内容如下 port 16382 dir /redisConfig logfile clusterSlave4.log cluster-enabled yes cluster-config-file nodes-clusterSlave4.conf cluster-require-full-coverage no appendonly yes appendfsync everysec cluster-slave-validity-factor 0 # 创建并运行容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd -p 16382:16382 --name clusterSlave4 -v D:\\ArchitectPracticer\\Redis\\RedisConfCluster:/redisConfig:rw redis redis-server /redisConfig/clusterSlave4.conf # 查看容器IP PS D:\\code\\blogs\\farb.github.io\u0026gt; docker inspect -f \u0026#34;{{.NetworkSettings.IPAddress}}\u0026#34; clusterSlave4 172.17.0.9 3. 使用\u0026ndash;cluster add-node命令将新节点加入到集群中 先看一下redis-cli \u0026ndash;cluster中的帮助信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 root@fb368ad5ad39:/data# redis-cli --cluster help Cluster Manager Commands: create host1:port1 ... hostN:portN --cluster-replicas \u0026lt;arg\u0026gt; check \u0026lt;host:port\u0026gt; or \u0026lt;host\u0026gt; \u0026lt;port\u0026gt; - separated by either colon or space --cluster-search-multiple-owners info \u0026lt;host:port\u0026gt; or \u0026lt;host\u0026gt; \u0026lt;port\u0026gt; - separated by either colon or space fix \u0026lt;host:port\u0026gt; or \u0026lt;host\u0026gt; \u0026lt;port\u0026gt; - separated by either colon or space --cluster-search-multiple-owners --cluster-fix-with-unreachable-masters reshard \u0026lt;host:port\u0026gt; or \u0026lt;host\u0026gt; \u0026lt;port\u0026gt; - separated by either colon or space --cluster-from \u0026lt;arg\u0026gt; --cluster-to \u0026lt;arg\u0026gt; --cluster-slots \u0026lt;arg\u0026gt; --cluster-yes --cluster-timeout \u0026lt;arg\u0026gt; --cluster-pipeline \u0026lt;arg\u0026gt; --cluster-replace rebalance \u0026lt;host:port\u0026gt; or \u0026lt;host\u0026gt; \u0026lt;port\u0026gt; - separated by either colon or space --cluster-weight \u0026lt;node1=w1...nodeN=wN\u0026gt; --cluster-use-empty-masters --cluster-timeout \u0026lt;arg\u0026gt; --cluster-simulate --cluster-pipeline \u0026lt;arg\u0026gt; --cluster-threshold \u0026lt;arg\u0026gt; --cluster-replace # 添加新节点，如果是添加主节点，只需指定新节点的IP和端口，后面跟上集群中的一个节点的IP和端口即可。 # 如果是添加从节点，需要指定新节点的IP和端口，后面跟上集群中的一个节点的IP和端口，并且指定--cluster-slave和--cluster-master-id 两个参数 add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id \u0026lt;arg\u0026gt; del-node host:port node_id call host:port command arg arg .. arg --cluster-only-masters --cluster-only-replicas set-timeout host:port milliseconds import host:port --cluster-from \u0026lt;arg\u0026gt; --cluster-from-user \u0026lt;arg\u0026gt; --cluster-from-pass \u0026lt;arg\u0026gt; --cluster-from-askpass --cluster-copy --cluster-replace backup host:port backup_directory help For check, fix, reshard, del-node, set-timeout, info, rebalance, call, import, backup you can specify the host and port of any working node in the cluster. Cluster Manager Options: --cluster-yes Automatic yes to cluster commands prompts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 # 进入集群中的一个节点容器，连接redis-cli,将扩容的主节点加入集群中 root@fb368ad5ad39:/data# redis-cli --cluster add-node 172.17.0.8:6382 172.17.0.2:6379 \u0026gt;\u0026gt;\u0026gt; Adding node 172.17.0.8:6382 to cluster 172.17.0.2:6379 \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.2:6379) M: 83df1063a9726b8cbe75c3a838674a8292a8b258 172.17.0.2:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: 7983ea1ae620a0de08edf3033f3e9b73c5b98f70 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: bd33358aa01625c99b7ea10832aa0340ded8816b 172.17.0.6:16380 slots: (0 slots) slave replicates 7983ea1ae620a0de08edf3033f3e9b73c5b98f70 M: 59593191f51ae43efd1663b0d045aaca0dbd0a1e 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: f2485056c3a66327274235a350cb23257931c0ac 172.17.0.5:16379 slots: (0 slots) slave replicates 83df1063a9726b8cbe75c3a838674a8292a8b258 S: ea1fec8d29809b8b68d2e38c300d9fc667fb7204 172.17.0.7:16381 slots: (0 slots) slave replicates 59593191f51ae43efd1663b0d045aaca0dbd0a1e [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. \u0026gt;\u0026gt;\u0026gt; Getting functions from cluster \u0026gt;\u0026gt;\u0026gt; Send FUNCTION LIST to 172.17.0.8:6382 to verify there is no functions in it \u0026gt;\u0026gt;\u0026gt; Send FUNCTION RESTORE to 172.17.0.8:6382 \u0026gt;\u0026gt;\u0026gt; Send CLUSTER MEET to node 172.17.0.8:6382 to make it join the cluster. [OK] New node added correctly. root@fb368ad5ad39:/data# redis-cli 127.0.0.1:6379\u0026gt; cluster nodes e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723300014894 3 connected 10923-16383 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723300013891 1 connected 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723300012887 2 connected fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723300012000 3 connected b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723300011000 1 connected 0-5460 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723300014000 2 connected 5461-10922 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382@16382 master - 0 1723300015897 0 connected # 可以看到新增的主节点已经加入到集群中了 127.0.0.1:6379\u0026gt; cluster nodes e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723300014894 3 connected 10923-16383 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723300013891 1 connected 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723300012887 2 connected fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723300012000 3 connected b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723300011000 1 connected 0-5460 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723300014000 2 connected 5461-10922 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382@16382 master - 0 1723300015897 0 connected # 继续添加从节点 root@fb368ad5ad39:/data# redis-cli --cluster add-node 172.17.0.9:16382 172.17.0.2:6379 --cluster-slave --cluster-master-id 8ae631285a8532aaeb324b404ab48352a25658ff root@fb368ad5ad39:/data# redis-cli --cluster add-node 172.17.0.9:16382 172.17.0.2:6379 --cluster-slave --cluster-master-id 8ae631285a8532aaeb324b404ab48352a25658ff \u0026gt;\u0026gt;\u0026gt; Adding node 172.17.0.9:16382 to cluster 172.17.0.2:6379 \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.2:6379) M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379 slots: (0 slots) slave replicates b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c S: 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380 slots: (0 slots) slave replicates 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c S: fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381 slots: (0 slots) slave replicates e2737cdc7073c3750ffb670bc618dc28cc939877 M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) M: 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382 slots: (0 slots) master [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. \u0026gt;\u0026gt;\u0026gt; Send CLUSTER MEET to node 172.17.0.9:16382 to make it join the cluster. Waiting for the cluster to join \u0026gt;\u0026gt;\u0026gt; Configure node as replica of 172.17.0.8:6382. [OK] New node added correctly. # 从节点添加到集群成功 127.0.0.1:6379\u0026gt; cluster nodes e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723300184000 3 connected 10923-16383 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723300185865 1 connected 25a08774618e7964f9324e386ce21a2af61bbb9a 172.17.0.9:16382@26382 slave 8ae631285a8532aaeb324b404ab48352a25658ff 0 1723300186869 0 connected 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723300184863 2 connected fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723300184000 3 connected b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723300185000 1 connected 0-5460 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723300186000 2 connected 5461-10922 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382@16382 master - 0 1723300183000 0 connected # 可以看到新增的主从节点都已经加入到集群中了，但是扩容的主节点现在还并没有分配哈希槽,因而不能保存数据 # 下面进行重新分片,有两种方法，一种是使用交互式命令窗口按照提示操作，第二种是指定redis-cli reshard 命令的其他多个参数 --cluster-from --cluster-to --cluster-slots。这里使用第一种 root@fb368ad5ad39:/data# redis-cli --cluster reshard 172.17.0.8:6382 \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.8:6382) M: 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382 slots: (0 slots) master 1 additional replica(s) M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380 slots: (0 slots) slave replicates 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379 slots: (0 slots) slave replicates b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c S: fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381 slots: (0 slots) slave replicates e2737cdc7073c3750ffb670bc618dc28cc939877 M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: 25a08774618e7964f9324e386ce21a2af61bbb9a 172.17.0.9:16382 slots: (0 slots) slave replicates 8ae631285a8532aaeb324b404ab48352a25658ff [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. # 这里询问要移动多少哈希槽？为了平均分配，这里输入4096(16384/4=4096)后回车。 How many slots do you want to move (from 1 to 16384)?4096 # 这里询问接收的节点Id是什么？（也就是要给哪个节点分配哈希槽，可以通过cluster nodes命令查看） What is the receiving node ID?8ae631285a8532aaeb324b404ab48352a25658ff # 这一步需要确认要从哪个节点移动哈希槽，输入all，要从所有节点移动哈希槽，目的是保证平均分配，当然你也可以自己指定节点的Id Please enter all the source node IDs. Type \u0026#39;all\u0026#39; to use all the nodes as source nodes for the hash slots. Type \u0026#39;done\u0026#39; once you entered all the source nodes IDs. Source node #1: all ... Moving slot 351 from b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c ... Moving slot 1361 from b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c Moving slot 1362 from b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c Moving slot 1363 from b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c Moving slot 1364 from b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c # 上面会显示从哪些节点移动哪些哈希槽，问你要不要继续提议的分片计划，输入yes回车 Do you want to proceed with the proposed reshard plan (yes/no)?yes # 然后会输出大量日志，且耗时较长，如果redis中的数据量更大，耗时会更长 # 因此生产环境应该在专门的维护时间段进行扩容升级 ... Moving slot 1364 from 172.17.0.2:6379 to 172.17.0.8:6382: # 然后使用redis-cli --cluster check 172.17.0.8:6382命令检查集群状态，发现4个主节点都分配了4096个哈希槽 root@fb368ad5ad39:/data# redis-cli --cluster check 172.17.0.8:6382 172.17.0.8:6382 (8ae63128...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 172.17.0.4:6381 (e2737cdc...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 172.17.0.3:6380 (8ba84e5b...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 172.17.0.2:6379 (b6d4a069...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. [OK] 0 keys in 4 masters. 0.00 keys per slot on average. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 172.17.0.8:6382) M: 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s) M: e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381 slots:[12288-16383] (4096 slots) master 1 additional replica(s) S: 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380 slots: (0 slots) slave replicates 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c M: 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379 slots: (0 slots) slave replicates b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c S: fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381 slots: (0 slots) slave replicates e2737cdc7073c3750ffb670bc618dc28cc939877 M: b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) S: 25a08774618e7964f9324e386ce21a2af61bbb9a 172.17.0.9:16382 slots: (0 slots) slave replicates 8ae631285a8532aaeb324b404ab48352a25658ff [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. # 第二种方法，172.17.0.8:6382指执行分配命令的节点， --cluster-slots N 指从每个from节点分配N个哈希槽 redis-cli --cluster reshard 172.17.0.8:6382 --cluster-from e2737cdc7073c3750ffb670bc618dc28cc939877,8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c,b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c --cluster-to 8ae631285a8532aaeb324b404ab48352a25658ff --cluster-slots 1024 故障自动恢复 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 root@fb368ad5ad39:/data# redis-cli -c 127.0.0.1:6379\u0026gt; get name -\u0026gt; Redirected to slot [5798] located at 172.17.0.8:6382 (nil) 172.17.0.8:6382\u0026gt; set name farb OK 172.17.0.8:6382\u0026gt; get name \u0026#34;farb\u0026#34; # 这里模拟节点故障，关闭节点172.17.0.8:6382 172.17.0.8:6382\u0026gt; shutdown (10.02s) not connected\u0026gt; exit root@fb368ad5ad39:/data# redis-cli -p 6379 127.0.0.1:6379\u0026gt; get name (error) CLUSTERDOWN The cluster is down 127.0.0.1:6379\u0026gt; exit root@fb368ad5ad39:/data# redis-cli 127.0.0.1:6379\u0026gt; cluster info cluster_state:fail cluster_slots_assigned:16384 cluster_slots_ok:12288 # 经过本人大量实验，需要设置clusterMaster4和clusterSlave4配置 cluster-slave-validity-factor 0 ，才可以将从节点提升为主节点 # 可以看到172.17.0.8:6382@16382 master,fail，之前的从节点提升为主节点172.17.0.9:16382@26382 master 127.0.0.1:6379\u0026gt; cluster nodes 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723389975343 2 connected fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723389977352 3 connected e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723389976348 3 connected 12288-16383 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723389974000 1 connected 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382@16382 master,fail - 1723389941225 1723389935203 7 connected 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723389975000 2 connected 6827-10922 b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723389975000 1 connected 1365-5460 25a08774618e7964f9324e386ce21a2af61bbb9a 172.17.0.9:16382@26382 master - 0 1723389974340 9 connected 0-1364 5461-6826 10923-12287 # 此时再次get name，可以看到成功从新的主节点172.17.0.9:16382得到数据 127.0.0.1:6379\u0026gt; get name -\u0026gt; Redirected to slot [5798] located at 172.17.0.9:16382 \u0026#34;farb\u0026#34; # 再次重启旧的主节点，发现旧的主节点已经变成新的主节点的从节点 172.17.0.9:16382\u0026gt; cluster nodes 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723478740183 2 connected b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 master - 0 1723478739000 1 connected 1365-5460 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723478742189 2 connected 6827-10922 25a08774618e7964f9324e386ce21a2af61bbb9a 172.17.0.9:16382@26382 myself,master - 0 1723478738000 13 connected 0-1364 5461-6826 10923-12287 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382@16382 slave 25a08774618e7964f9324e386ce21a2af61bbb9a 0 1723478738119 13 connected fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723478741186 3 connected 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723478741000 1 connected e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723478738000 3 connected 12288-16383 从节点重新恢复为主节点 原先的主节点宕机后，变成从节点，现在重新恢复为主节点\n1 2 3 4 # 进入该从节点的容器，连接redis-cli,执行cluster failover root@83fd72d8d210:/data# redis-cli -p 6382 -h 172.17.0.8 172.17.0.8:6382\u0026gt; cluster failover takeover OK 缩容：删除节点 只允许删除从节点和空的主节点，如果主节点分配了哈希槽，则需要先将哈希槽转移到其他节点，再进行删除\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 如果直接删除分配有哈希槽的主节点，则会报错，提示需要先重新分片 root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster del-node 172.17.0.9:16382 25a08774618e7964f9324e386ce21a2af61bbb9a \u0026gt;\u0026gt;\u0026gt; Removing node 25a08774618e7964f9324e386ce21a2af61bbb9a from cluster 172.17.0.9:16382 [ERR] Node 172.17.0.9:16382 is not empty! Reshard data away and try again. redis-cli --cluster reshard 172.17.0.2:6379 --cluster-from 8ae631285a8532aaeb324b404ab48352a25658ff --cluster-to b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c --cluster-slots 4096 ...... Moving slot 12286 from 8ae631285a8532aaeb324b404ab48352a25658ff Moving slot 12287 from 8ae631285a8532aaeb324b404ab48352a25658ff Do you want to proceed with the proposed reshard plan (yes/no)? yes ...... Moving slot 12286 from 172.17.0.8:6382 to 172.17.0.2:6379: Moving slot 12287 from 172.17.0.8:6382 to 172.17.0.2:6379: # 可以看到172.17.0.8:6382和172.17.0.9:16382都是从节点了 127.0.0.1:6379\u0026gt; cluster nodes fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723562047844 3 connected 25a08774618e7964f9324e386ce21a2af61bbb9a 172.17.0.9:16382@26382 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723562045834 17 connected 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723562046000 17 connected 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723562049853 2 connected 6827-10922 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723562046000 2 connected 8ae631285a8532aaeb324b404ab48352a25658ff 172.17.0.8:6382@16382 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723562048848 17 connected e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723562048000 3 connected 12288-16383 b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723562049000 17 connected 0-6826 10923-12287 # 执行删除节点操作 root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster del-node 172.17.0.9:16382 25a08774618e7964f9324e386ce21a2af61bbb9a \u0026gt;\u0026gt;\u0026gt; Removing node 25a08774618e7964f9324e386ce21a2af61bbb9a from cluster 172.17.0.9:16382 \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER FORGET messages to the cluster... \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER RESET SOFT to the deleted node. root@fb368ad5ad39:/data# redis-cli -p 6379 --cluster del-node 172.17.0.2:6379 8ae631285a8532aaeb324b404ab48352a25658ff \u0026gt;\u0026gt;\u0026gt; Removing node 8ae631285a8532aaeb324b404ab48352a25658ff from cluster 172.17.0.2:6379 \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER FORGET messages to the cluster... \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER RESET SOFT to the deleted node. # 此时集群中又是三主三从了。 127.0.0.1:6379\u0026gt; cluster nodes fc156444e5af0817468c95f8a86ec55310e06aed 172.17.0.7:16381@26381 slave e2737cdc7073c3750ffb670bc618dc28cc939877 0 1723562354046 3 connected 30e652ae7137b28a304a6954acc7dd99a070be08 172.17.0.5:16379@26379 slave b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 0 1723562356053 17 connected 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 172.17.0.3:6380@16380 master - 0 1723562353000 2 connected 6827-10922 808b97759fd358611f94edca21836c4d68d63467 172.17.0.6:16380@26380 slave 8ba84e5b7c76e8530529b41d8c6ee59f3d3edf0c 0 1723562354000 2 connected e2737cdc7073c3750ffb670bc618dc28cc939877 172.17.0.4:6381@16381 master - 0 1723562355050 3 connected 12288-16383 b6d4a069fdd4acf4d46133e56bfa79cb6d03b77c 172.17.0.2:6379@16379 myself,master - 0 1723562354000 17 connected 0-6826 10923-12287 cluster集群中的常用配置 cluster-enabled yes：开启cluster集群模式 cluster-config-file：cluster集群节点配置文件，Redis服务器第一次以cluster节点身份启动时自动生成，保存了cluster集群里本节点和其他节点之间的关联方式 dir: 指定cluster-config-file文件和日志文件保存的路径 logfile: 指定当前节点的日志文件名 cluster-node-timeout：cluster集群节点之间的超时时间，单位为毫秒，如果超过该时间，则认为节点已经离线，会向对应的从节点进行故障转移操作。 cluster-require-full-coverage：默认为yes。表示cluster集群中有节点失效时该集群是否继续对外提供写服务，出于容错性考虑，建议设置为no,如果设置为yes,那么集群中有节点失效时，该集群只提供只读服务。 cluster-migration-barrier：用来设置主节点的最小从节点数量。假设该值为1，当某主节点的从节点数量小于1时，就会从其他从节点个数大于1的主节点那边调剂1个从节点过来，这样做的目的是避免出现不包含从节点的主节点，因为一旦出现这种情况，当主节点失效时，就无法再用从节点进行故障恢复的动作。 cluster-slave-validity-factor: 如果设置成０，则无论从节点与主节点失联多久，从节点都会尝试升级成主节点。如果设置成正数，则cluster-node-timeout乘以cluster-slave-validity-factor得到的时间，是从节点与主节点失联后，此从节点数据有效的最长时间，超过这个时间，从节点不会启动故障迁移。假设cluster-node-timeout=5，cluster-slave-validity-factor=10，则如果从节点跟主节点失联超过50秒，此从节点不能成为主节点。注意，如果此参数配置为非0，将可能出现由于某主节点失联却没有从节点能顶上的情况，从而导致集群不能正常工作，在这种情况下，只有等到原来的主节点重新回归到集群，集群才恢复运作。 repl-diskless-load : mastar 节点有两种方式传输 RDB，slave 节点也有两种方式加载 master 传输过来的 RDB 数据。 传统方式：接受到数据后，先持久化到磁盘，再从磁盘加载 RDB 文件恢复数据到内存中，这是传统方式。 diskless-load：从 Socket 中一边接受数据，一边解析，实现无盘化。 一共有三个取值可配置： disabled：不使用 diskless-load 方式，即采用磁盘化的传统方式。 on-empty-db：安全模式下使用 diskless-load（也就 slave 节点数据库为空的时候使用 diskless-load）。 swapdb：使用 diskless-load 方式加载，slave 节点会缓存一份当前数据库的数据，再清空数据库，接着进行 Socket 读取实现加载。缓存一份数据的目的是防止读取 Socket 失败。 补充：使用cluster meet 我也实践了下cluster meet命令，但是没有得到预期的结果，不知道是Redis版本（7.2.5）问题还是啥原因。出现的问题是：三主三从的集群可以搭建成功，但是在扩容时，新加入的节点始终是从节点，下面是我的原始命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 注意这里meet之后的ip是容器所在的IP地址，不是localhost root@fb368ad5ad39:/data# redis-cli -p 6379 cluster meet 172.17.0.3 6380 OK root@fb368ad5ad39:/data# redis-cli -p 6379 cluster meet 172.17.0.4 6381 OK root@fb368ad5ad39:/data# redis-cli -p 6379 cluster meet 172.17.0.5 16379 OK root@fb368ad5ad39:/data# redis-cli -p 6379 cluster meet 172.17.0.6 16380 OK root@fb368ad5ad39:/data# redis-cli -p 6379 cluster meet 172.17.0.7 16381 OK # 一次只能添加一个哈希槽 redis-cli -h hostIp -p port Cluster AddSlots N # 添加哈希槽范围，依次可以添加多个哈希槽 redis-cli -h hostIp -p port Cluster ADDSLOTSRANGE \u0026lt;start slot\u0026gt; \u0026lt;end slot\u0026gt; [\u0026lt;start slot\u0026gt; \u0026lt;end slot\u0026gt; ...] Assign slots which are between \u0026lt;start-slot\u0026gt; and \u0026lt;end-slot\u0026gt; to current node. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # 给节点hostIp:port分配哈希槽N，其中N是哈希槽的编号，从0到16383 # 由于每次只能分配一个编号，所以这里写一个bash脚本，循环执行 `redis-cli -h hostIp -p port Cluster AddSlots N` # D:\\ArchitectPracticer\\Redis\\RedisConfCluster目录下新建SetMaster1HashSlots.sh，内容如下： # 分配哈希槽[0,5460]给clusterMaster1 for i in $(seq 0 5460) do redis-cli -h 172.17.0.2 -p 6379 Cluster AddSlots $i done # 以上脚本等价于 root@fb368ad5ad39:/data# redis-cli -h 172.17.0.2 -p 6379 172.17.0.2:6379\u0026gt; cluster addslotsrange 0 5460 OK # D:\\ArchitectPracticer\\Redis\\RedisConfCluster目录下新建SetMaster2HashSlots.sh，内容如下： # 分配哈希槽[5461,10922]给clusterMaster2 for i in $(seq 5461 10922) do redis-cli -h 172.17.0.3 -p 6380 Cluster AddSlots $i done # 以上脚本等价于 root@fb368ad5ad39:/data# redis-cli -h 172.17.0.3 -p 6380 172.17.0.3:6380\u0026gt; CLUSTER ADDSLOTSRANGE 5461 10922 OK # D:\\ArchitectPracticer\\Redis\\RedisConfCluster目录下新建SetMaster3HashSlots.sh，内容如下： # 分配哈希槽[10923,16383]给clusterMaster3 for i in $(seq 10923 16383) do redis-cli -h 172.17.0.4 -p 6381 Cluster AddSlots $i done # 以上脚本等价于 root@fb368ad5ad39:/data# redis-cli -h 172.17.0.4 -p 6381 172.17.0.4:6381\u0026gt; cluster addslotsrange 10923 16383 OK # 通过exit退出redis-cli，进入容器，然后依次执行脚本，会看到一直打印ok /redisConfig/SetMaster1HashSlots.sh /redisConfig/SetMaster21HashSlots.sh /redisConfig/SetMaster3HashSlots.sh # 运行完毕后，此时已经给clusterMaster1、clusterMaster2、clusterMaster3分别分配了哈希槽，进入clusterMaster1容器，查看cluster info如下： 127.0.0.1:6379\u0026gt; cluster info # 集群状态是ok，说明集群已经完成初始化 cluster_state:ok # 分配的哈希槽的个数为16384 cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 # 可以看到集群中有6个节点 cluster_known_nodes:6 # 集群中主节点个数为3 cluster_size:3 关联主节点和从节点 设置从节点的方式是用redis-cli命令进入redis服务器从节点，然后运行cluster replicate masterNodeId. masterNodeId是master节点的节点id，可以通过cluster nodes命令查看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 进入clusterMaster1容器,连接到redis-cli，然后查看集群节点id,很明显，第一列就是节点Id 127.0.0.1:6379\u0026gt; cluster nodes 94c321bf8580621f267e7a0b502f6c1bd120f203 172.17.0.5:16379@26379 master - 0 1722779543000 3 connected 8b9e6e09898be857fcd33e4a2611c42268ce7b1c 172.17.0.2:6379@16379 myself,master - 0 1722779542000 2 connected 0-5460 207623a24974859ede6b1a59a046cb10fdfb7d54 172.17.0.7:16381@26381 master - 0 1722779544247 5 connected 8794e2d834a7591630dced8cbaa073c1216de978 172.17.0.6:16380@26380 master - 0 1722779544000 4 connected fbb526d37ce8ef0067387d7810677200b5ed5d89 172.17.0.4:6381@16381 master - 0 1722779544000 0 connected 10923-16383 8192cc1bb0de71879b1f7174676260d3d5510a7f 172.17.0.3:6380@16380 master - 0 1722779543244 1 connected 5461-10922 # 设置clusterMaster1为clusterSlave1的主节点 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it clusterSlave1 bash root@5d2ecf9131f7:/data# redis-cli -p 16379 127.0.0.1:16379\u0026gt; cluster replicate 8b9e6e09898be857fcd33e4a2611c42268ce7b1c OK # 设置clusterMaster2为clusterSlave2的主节点 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it clusterSlave2 bash root@44e2e24b798a:/data# redis-cli -p 16380 127.0.0.1:16380\u0026gt; cluster replicate 8192cc1bb0de71879b1f7174676260d3d5510a7f OK # 设置clusterMaster3为clusterSlave3的主节点 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it clusterSlave3 bash root@ef29a379b557:/data# redis-cli -p 16381 127.0.0.1:16381\u0026gt; cluster replicate fbb526d37ce8ef0067387d7810677200b5ed5d89 OK # 至此，cluster集群三主三从节点已经搭建完成。可以进入任意一台服务器进行验证。 127.0.0.1:16381\u0026gt; cluster nodes 8794e2d834a7591630dced8cbaa073c1216de978 172.17.0.6:16380@26380 slave 8192cc1bb0de71879b1f7174676260d3d5510a7f 0 1722780289575 1 connected fbb526d37ce8ef0067387d7810677200b5ed5d89 172.17.0.4:6381@16381 master - 0 1722780291000 0 connected 10923-16383 207623a24974859ede6b1a59a046cb10fdfb7d54 172.17.0.7:16381@26381 myself,slave fbb526d37ce8ef0067387d7810677200b5ed5d89 0 1722780289000 0 connected 8192cc1bb0de71879b1f7174676260d3d5510a7f 172.17.0.3:6380@16380 master - 0 1722780290586 1 connected 5461-10922 94c321bf8580621f267e7a0b502f6c1bd120f203 172.17.0.5:16379@26379 slave 8b9e6e09898be857fcd33e4a2611c42268ce7b1c 0 1722780291589 2 connected 8b9e6e09898be857fcd33e4a2611c42268ce7b1c 172.17.0.2:6379@16379 master - 0 1722780290000 2 connected 0-5460 使用cluster meet命令创建集群之后，不论是使用cluster meet还是redis-cli \u0026ndash;cluster add-node添加的节点都是从节点。具体原因待以后继续调查。\n","date":"2024-07-31T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_07_cluster/","title":"基于Docker的Redis实战--搭建Redis集群"},{"content":"Can\u0026rsquo;t open or create append-only dir appendonlydir: Permission denied redis7配置sentinel时报错 Can\u0026rsquo;t resolve instance hostname.\n*** FATAL CONFIG FILE ERROR (Redis 7.2.5) *** sentinel monitor master localhost 6379 2\n哨兵节点监控主服务器，主机ip是172.17.0.2，端口是6379，集群中至少2个哨兵节点才能确定该主服务器是否故障 Reading the configuration file, at line 2\n\u0026lsquo;sentinel monitor redis-master localhost 6379 2\u0026rsquo; Can\u0026rsquo;t resolve instance hostname.\n加上这句解决问题 sentinel resolve-hostnames yes\n1:M 11 Aug 2024 15:34:39.576 # Unable to obtain the AOF file appendonly-clusterMaster4.aof.3.incr.aof length. stat: No such file or directory 不需要配置了appendfilename appendonly-clusterMaster4.aof\nFailed trying to load the MASTER synchronization DB from disk, check server logs. 根据报错提示，回到主节点可以看到错误日志,可以看到和从节点的连接丢失，没有同步成功。\n1 2 3 4 5 6 7 8 9 1:M 12 Aug 2024 15:56:25.216 * Starting BGSAVE for SYNC with target: replicas sockets 1:M 12 Aug 2024 15:56:25.222 * Background RDB transfer started by pid 220 220:C 12 Aug 2024 15:56:25.222 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB 1:M 12 Aug 2024 15:56:25.225 * Diskless rdb transfer, done reading from pipe, 1 replicas still up. 1:M 12 Aug 2024 15:56:25.231 * Connection with replica 172.17.0.9:16382 lost. 1:M 12 Aug 2024 15:56:25.235 * Replica 172.17.0.9:16382 asks for synchronization 1:M 12 Aug 2024 15:56:25.235 * Full resync requested by replica 172.17.0.9:16382 1:M 12 Aug 2024 15:56:25.236 * Current BGSAVE has socket target. Waiting for next BGSAVE for SYNC 1:M 12 Aug 2024 15:56:25.324 * Background RDB transfer terminated with success 修改redis.config中的配置,将主从服务器的属性repl-diskless-load设置为on-empty-db即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Replica can load the RDB it reads from the replication link directly from the # socket, or store the RDB to a file and read that file after it was completely # received from the master. # # In many cases the disk is slower than the network, and storing and loading # the RDB file may increase replication time (and even increase the master\u0026#39;s # Copy on Write memory and replica buffers). # However, parsing the RDB file directly from the socket may mean that we have # to flush the contents of the current database before the full rdb was # received. For this reason we have the following options: # # \u0026#34;disabled\u0026#34; - Don\u0026#39;t use diskless load (store the rdb file to the disk first) # \u0026#34;on-empty-db\u0026#34; - Use diskless load only when it is completely safe. # \u0026#34;swapdb\u0026#34; - Keep current db contents in RAM while parsing the data directly # from the socket. Replicas in this mode can keep serving current # data set while replication is in progress, except for cases where # they can\u0026#39;t recognize master as having a data set from same # replication history. # Note that this requires sufficient memory, if you don\u0026#39;t have it, # you risk an OOM kill. repl-diskless-load disabled 然后重启主从服务器，再次查看主节点日志，发现同步成功\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1:C 12 Aug 2024 15:56:32.400 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode 1:C 12 Aug 2024 15:56:32.401 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 1:C 12 Aug 2024 15:56:32.402 * Redis version=7.2.5, bits=64, commit=00000000, modified=0, pid=1, just started 1:C 12 Aug 2024 15:56:32.403 * Configuration loaded 1:M 12 Aug 2024 15:56:32.404 * monotonic clock: POSIX clock_gettime 1:M 12 Aug 2024 15:56:32.405 * Running mode=cluster, port=6382. 1:M 12 Aug 2024 15:56:32.407 * Node configuration loaded, I\u0026#39;m 8ae631285a8532aaeb324b404ab48352a25658ff 1:M 12 Aug 2024 15:56:32.408 * Server initialized 1:M 12 Aug 2024 15:56:32.414 * Reading RDB base file on AOF loading... 1:M 12 Aug 2024 15:56:32.416 * Loading RDB produced by version 7.2.5 1:M 12 Aug 2024 15:56:32.416 * RDB age 961 seconds 1:M 12 Aug 2024 15:56:32.417 * RDB memory usage when created 1.59 Mb 1:M 12 Aug 2024 15:56:32.418 * RDB is base AOF 1:M 12 Aug 2024 15:56:32.419 * Done loading RDB, keys loaded: 0, keys expired: 0. 1:M 12 Aug 2024 15:56:32.420 * DB loaded from base file appendonly-clusterMaster4.2.base.rdb: 0.006 seconds 1:M 12 Aug 2024 15:56:32.422 * DB loaded from incr file appendonly-clusterMaster4.2.incr.aof: 0.001 seconds 1:M 12 Aug 2024 15:56:32.422 * DB loaded from append only file: 0.012 seconds 1:M 12 Aug 2024 15:56:32.424 * Opening AOF incr file appendonly-clusterMaster4.2.incr.aof on server start 1:M 12 Aug 2024 15:56:32.425 * Ready to accept connections tcp 1:M 12 Aug 2024 15:56:33.495 * Replica 172.17.0.9:16382 asks for synchronization 1:M 12 Aug 2024 15:56:33.496 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for \u0026#39;a4e7ecbdc1e68bb729f8e293cdd37af350bcc946\u0026#39;, my replication IDs are \u0026#39;a3393f87f433bfd8bc8c205a0911ffa83a72831d\u0026#39; and \u0026#39;0000000000000000000000000000000000000000\u0026#39;) 1:M 12 Aug 2024 15:56:33.497 * Replication backlog created, my new replication IDs are \u0026#39;16dd21acae0e5ba18ee4699070c0046ef26ac227\u0026#39; and \u0026#39;0000000000000000000000000000000000000000\u0026#39; 1:M 12 Aug 2024 15:56:33.498 * Delay next BGSAVE for diskless SYNC 1:M 12 Aug 2024 15:56:34.442 * Cluster state changed: ok 1:M 12 Aug 2024 15:56:38.373 * Starting BGSAVE for SYNC with target: replicas sockets 1:M 12 Aug 2024 15:56:38.375 * Background RDB transfer started by pid 20 20:C 12 Aug 2024 15:56:38.375 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB 1:M 12 Aug 2024 15:56:38.376 * Diskless rdb transfer, done reading from pipe, 1 replicas still up. 1:M 12 Aug 2024 15:56:38.388 * Background RDB transfer terminated with success 1:M 12 Aug 2024 15:56:38.389 * Streamed RDB transfer with replica 172.17.0.9:16382 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming 1:M 12 Aug 2024 15:56:38.390 * Synchronization with replica 172.17.0.9:16382 succeeded ","date":"2024-07-28T00:00:00Z","permalink":"https://farb.github.io/p/docker-redis-error/","title":"基于Docker的Redis实战--报错总结篇"},{"content":"Redis持久化机制概述 对于Redis而言，持久化机制是指把内存中的数据存为硬盘文件，当Redis重启或服务器故障时，能根据持久化的硬盘文件恢复数据。Redis有两种持久化方式，分别是AOF(Append Only File,只追加文件)和RDB（Redis database,基于Redis数据库）\n基于AOF的持久化机制 AOF会以日志的方式记录每个Redis的写命令，并在Redis服务器重启时重新执行AOF日志文件中的命令，从而恢复数据。 AOF持久化默认配置关闭，如果打开，每当发生写的命令，该命令就会被记录到AOF缓冲区里，AOF缓冲区会根据事先配置的策略定期与硬盘文件进行同步操作。 当AOF文件大到一定程度后会被重写，在不影响持久化结果的前提下进行压缩。\nAOF重写：随着持久化数据的增多，对应的AOF文件会越来越大，可能会影响性能，此时Redis会创建新的AOF文件替代现有的，在数据恢复时，效果相同，但新文件不会包含冗余命令，所以文件会比原来的小。 当Redis发生故障重启时，根据AOF日志文件恢复数据的过程如下：\n创建一个伪客户端（fake client）,不连接任何网络，除此之外和真实的客户端都一样； 该伪客户端从AOF日志文件中依次读取命令并执行，直到完成所有命令。 AOF的持久化机制具有实时存储的特性，因此可以在读写关键数据时开启。\n基于RDB的持久化机制 Redis默认的持久化机制就RDB，RDB的持久化方式会把当前内存中的所有Redis键值对数据以快照的方式保存到硬盘文件，如果需要恢复数据，就把快照文件读取到内存。 RDB快照文件是经压缩的二进制文件，它的存储路径可以在redis.conf中指定，也可以在redis运行时通过命令设置。 Redis的RDB持久化机制触发机制有两种：\nsave和bgsave等命令手动触发； 通过redis.conf配置文件里设置的方式定期把数据写入快照。 基于RDB的持久化方式适合数据备份和灾备场景，但RDB无法实现即使备份，两次备份之间必然会丢数据。\nAOF持久化机制实践 AOF配置文件的说明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 开启AOF功能，默认是关闭的 appendonly yes # 开启aof功能后，通过appendfsync设置持久化策略 appendfsync always/everysec/no # always: 每次写命令时都会触发持久化动作，这种方式可能影响Redis性能。 # everysec: 每秒触发一次持久化动作，平衡了持久化需求和性能，一般取这个值。 # no: 由操作系统决定持久化的频率，这种性能最好，但每次持久化操作的间隔可能较长，当故障发生时可能会丢失数据。 dir aofDir # dir指定保存持久化文件的目录 appendfilename aofFileName # 指定持久化文件的名称，默认文件名为appendonly.aof auto-load-truncated # 定义aof文件的加载策略。当AOF持久化文件损坏时启动Redis是否会自动加载，默认为yes no-appendfsync-on-rewrite yes/no # 平衡性能和安全性。字面意思是：AOF重写时是否禁用AOF追加。默认为no # 如果为yes,则会提高重写性能，但可能会丢失写的数据。 # 如果为no，则不会丢失数据，但重写性能可能会降低。 auto-aof-rewrite-percentage # 指定自动重写的条件。默认是100，即如果当前的AOF文件比上次执行重写时的文件大100%时会再次触发重写操作。如果为0，则不触发。 auto-aof-rewrite-min-size # 指定自动AOF重写的AOF文件的最低要求大小。默认为64MB # 注意： auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size 必须同时满足条件才会触发。 注意：也可以通过bgrewriteaof命令手动触发AOF重写\n实践AOF持久化 Redis 7 中引入的 Multi-Part AOF (MP-AOF) 是一种改进的持久化机制，旨在优化 AOF (Append Only File) 的性能和效率，尤其是在高并发写入场景下。传统的 AOF 机制在主进程处理客户端请求的同时，还需要负责 AOF 日志的写入和重写，这可能导致性能瓶颈。\nMP-AOF 的主要目标是减少主进程的负担，通过将 AOF 日志的写入和重写操作分离到独立的后台线程中，从而提高整体的系统吞吐量。MP-AOF 将 AOF 文件分为两部分：\nBase RDB 文件：这部分是数据库的快照，类似于 RDB 文件，用于快速恢复数据集的基本状态。 Incremental AOF 文件：这部分包含自上次快照以来的所有写操作，用于增量更新数据库状态。 appendonly.aof.1.incr.aof 文件就是 MP-AOF 架构下的 Incremental AOF 文件的一个实例。这个文件包含了自上次 RDB 快照之后的所有写入操作。\n以下是 MP-AOF 的几个关键特点：\n分离写操作：MP-AOF 将写操作的记录和重写任务分配给单独的线程，减少了主进程的负载。 异步重写：AOF 的重写操作不再阻塞主进程，而是由后台线程异步完成。 高效恢复：在服务器启动时，首先加载 Base RDB 文件来快速恢复大部分数据，然后应用 Incremental AOF 文件中的操-作来更新数据集，这种分阶段的恢复过程比传统 AOF 更高效。 减少磁盘 I/O：通过减少主进程的磁盘 I/O 操作，提高了系统的整体响应速度。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 创建redis-server 容器，使用-v参数将宿主机的路径绑定为配置文件路径，rw指定有对配置目录的读写权限 docker run -itd --name redis-server -v D:/ArchitectPracticer/Redis/RedisConf:/redisConfig:rw -p 6379:6379 redis:latest redis-server /redisConfig/redis.conf # 进入容器并启动redis-cli，执行set和get命令，然后查看AOF的文件 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server bash root@74551bec3ecc:/data# redis-cli 127.0.0.1:6379\u0026gt; set name farb OK 127.0.0.1:6379\u0026gt; set age 18 OK 127.0.0.1:6379\u0026gt; set height 180 OK 127.0.0.1:6379\u0026gt; get name \u0026#34;farb\u0026#34; # 在Redis 7.2.5中可以看到AOF文件生成了3个，默认在appendonlydir目录。其中incr.aof文件是增量文件，base.rdb文件是基础文件。 PS D:\\ArchitectPracticer\\Redis\\RedisConf\\appendonlydir\u0026gt; ls 目录: D:\\ArchitectPracticer\\Redis\\RedisConf\\appendonlydir Mode LastWriteTime Length Name ---- ------------- ------ ---- -a---- 2024/7/28 22:43 88 appendonly.aof.1.base.rdb -a---- 2024/7/28 22:45 120 appendonly.aof.1.incr.aof -a---- 2024/7/28 22:43 88 appendonly.aof.manifest # 打开appendonly.aof.1.incr.aof，可以看到写入的命令，get命令没有记录。 *2 $6 SELECT $1 0 *3 $3 set $4 name $4 farb *3 $3 set $3 age $2 18 *3 $3 set $6 height $3 180 观察重写AOF的文件的效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 向list中写入数据 127.0.0.1:6379\u0026gt; rpush namelist alice (integer) 1 127.0.0.1:6379\u0026gt; rpush namelist bob (integer) 2 127.0.0.1:6379\u0026gt; rpush namelist candy (integer) 3 # 观察aof文件如下 rpush $8 namelist $3 bob *3 $5 rpush $8 namelist $5 candy 手动执行bgrewriteaof命令，再次查看aof日志文件,可以看到之前的appendonly.aof.1.incr.aof已经删除，而appendonly.aof.2.incr.aof文件生成了，并且是空的，打开appendonly.aof.2.base.rdb可以看到重写的内容。一般不会使用bgrewriteaof命令，而是通过auto-aof-rewrite-percentage和auto-aof-rewrite-min-size两个参数控制AOF重写策略。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 PS D:\\ArchitectPracticer\\Redis\\RedisConf\\appendonlydir\u0026gt; ls 目录: D:\\ArchitectPracticer\\Redis\\RedisConf\\appendonlydir Mode LastWriteTime Length Name ---- ------------- ------ ---- -a---- 2024/7/29 0:09 132 appendonly.aof.2.base.rdb -a---- 2024/7/29 0:09 0 appendonly.aof.2.incr.aof -a---- 2024/7/29 0:09 88 appendonly.aof.manifest REDIS0011�\tredis-ver\u00057.2.5� redis-bits�@�\u0005ctime�2m�f�\bused-mem°�\u000fnamelist\u0001\u0002\u001a\u001a�alice\u0006�bob\u0004�candy # appendonly.aof.manifest文件内容变成： file appendonly.aof.2.base.rdb seq 2 type b file appendonly.aof.2.incr.aof seq 2 type i # 也就是说这个清单文件记录了base和incr两个文件名，并记录了这两个文件的顺序号和类型。当前是第二个序列，且b是base,i是incr。 再次向list中写入一条数据，然后查看aof日志文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 127.0.0.1:6379\u0026gt; rpush namelist hugh (integer) 4 127.0.0.1:6379\u0026gt; bgrewriteaof Background append only file rewriting started # 观察appendonly.aof.manifest文件如下 file appendonly.aof.3.base.rdb seq 3 type b file appendonly.aof.3.incr.aof seq 3 type i # 观察appendonly.aof.3.incr.aof文件为空 # 观察appendonly.aof.3.base.rdb文件如下: REDIS0011�\tredis-ver\u00057.2.5� redis-bits�@�\u0005ctime�C��f�\bused-mem��T\u000e�\baof-base�\u0001�namelist\u0001\u0002�alice\u0006�bob\u0004�candy\u0006�hugh\u0005 经过上面的实践和观察，发现Redis7之前AOF重写都是在同一个文件名中进行的，而Redis7之后，AOF重写是分离到独立的3个文件，appendonly.aof.manifest文件记录了rdb和incr文件的名称、序列号和类型，incr文件记录了写入的命令，而rdb文件记录了重写的内容，且incr和rdb每次重写后序列号都会自增。\n模拟数据恢复的流程 上面redis中已经创建了一个namelist，现在模拟一下数据恢复的流程，先通过flushall命令清空redis数据库，模拟宕机，然后在incr的aof文件中删除最后的flushall命令（如果不删除，恢复数据时会执行flushall,把之前恢复的数据再次清空），然后删除旧的容器redis-server,并重新创建启动redis-server，然后查看namelist，发现namelist已经恢复，说明数据已经恢复。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 清空数据库并查看aof文件 127.0.0.1:6379\u0026gt; flushall OK 127.0.0.1:6379\u0026gt; keys * (empty array) # 观察appendonly.aof.3.incr.aof文件如下： *2 $6 SELECT $1 0 *1 $8 flushall # 删除flushall的相关命令并保存文件 # 退出redis-cli 127.0.0.1:6379\u0026gt; exit # 退出容器 root@f501aa313152:/data# exit exit # 强制删除容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker rm -f redis-server redis-server # 创建redis-server容器并运行 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-server -p 6379:6379 -v D:\\ArchitectPracticer\\Redis\\RedisConf:/redisConfig:rw redis:latest redis-server /redisConfig/redis.conf 2b939fe1c091990c6755770078c45fb37637ce89c7d6baa441d4d818dc17647d # 进入redis-server容器，运行bash PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server bash # 进入redis-cli，可以看到之前aof中的数据已经恢复了 root@2b939fe1c091:/data# redis-cli 127.0.0.1:6379\u0026gt; lrange namelist 0 -1 1) \u0026#34;alice\u0026#34; 2) \u0026#34;bob\u0026#34; 3) \u0026#34;candy\u0026#34; 4) \u0026#34;hugh\u0026#34; 修复AOF文件 数据恢复时，如果AOF文件损坏，可以通过以下步骤修复AOF文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 redis-check-aof [--fix|--truncate-to-timestamp $timestamp] \u0026lt;file.manifest|file.aof\u0026gt; # redis7之前，直接指定appendonlyfile.aof文件即可；Redis7之后，需要指定appendonly.aof.manifest文件，默认目录为appendonlydir root@2b939fe1c091:/data# redis-check-aof --fix /redisConfig/appendonlydir/appendonly.aof.manifest Start checking Multi Part AOF Start to check BASE AOF (RDB format). [offset 0] Checking RDB file /redisConfig/appendonlydir/appendonly.aof.3.base.rdb [offset 26] AUX FIELD redis-ver = \u0026#39;7.2.5\u0026#39; [offset 40] AUX FIELD redis-bits = \u0026#39;64\u0026#39; [offset 52] AUX FIELD ctime = \u0026#39;1722262595\u0026#39; [offset 67] AUX FIELD used-mem = \u0026#39;939216\u0026#39; [offset 79] AUX FIELD aof-base = \u0026#39;1\u0026#39; [offset 81] Selecting DB ID 0 [offset 138] Checksum OK [offset 138] \\o/ RDB looks OK! \\o/ [info] 1 keys read [info] 0 expires [info] 0 already expired RDB preamble is OK, proceeding with AOF tail... AOF analyzed: filename=appendonly.aof.3.base.rdb, size=138, ok_up_to=138, ok_up_to_line=1, diff=0 BASE AOF appendonly.aof.3.base.rdb is valid Start to check INCR files. INCR AOF appendonly.aof.3.incr.aof is empty All AOF files and manifest are valid # 从上面的输出可以看到，先检查rdb是否有效，再检查增量文件是否有效 RDB持久化机制实践 编写配置文件，生成DRB快照 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 创建配置文件redis.conf，并配置以下内容： save 600 1 # 600s内有\u0026gt;=1个键被修改就会生成快照 save 300 100 # 300s内有\u0026gt;=100个键被修改就会生成快照 save 60 1000 # 60s内有\u0026gt;=1000个键被修改就会生成快照 # save 600 1 300 100 60 1000 这种写法等同 # 注意：以上三个条件是或的关系，RDB持久化文件只是当条件满足就生成快照，因此无法即时保存当前状态的内存数据，可能会丢失数据。 dbfilename dump.rdb dir /redisConfig # 默认的RDB文件保存路径和文件名 stop-writes-on-bgsave-error yes/no # 当RDB持久化执行bgsave失败时，是否停止写入操作,默认为yes rdbcompression yes/no # 是否压缩RDB文件，默认为yes rdbchecksum yes/no # 用rdb快照文件恢复数据时是否开启对快照文件的校验。默认是yes,如果是no,就无法确保文件是否正确 创建并运行容器\n1 2 3 4 5 6 7 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker rm redis-server PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-server -v D:\\ArchitectPracticer\\Redis\\RedisConfRdb:/redisConfig:rw -p 6379:6379 redis:latest redis-server /redisConfig/redis.conf 440981babaef495ceae188f98e962d764c5130669bfdaf112538c48391b9a201 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server bash root@440981babaef:/data# redis-cli 127.0.0.1:6379\u0026gt; set name farb OK 用快照文件恢复数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 删除之前包含数据的redis-server容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker rm redis-server redis-server # 重新创建并运行容器，配置指向之前包含快照文件的目录 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-server -v D:\\ArchitectPracticer\\Redis\\RedisConfRdb:/redisConfig:rw -p 6379:6379 redis:latest redis-server /redisConfig/redis.conf f2221a4c78afaa6e3c122f9cc026b48f89153ffc0e153bc42133fb0f9b33db80 # 进入redis-server容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server bash # 可以看到有数据存在，说明恢复了数据 root@f2221a4c78af:/data# redis-cli 127.0.0.1:6379\u0026gt; get name \u0026#34;farb\u0026#34; save 和 bgsave save命令用于立即生成RDB快照，而bgsave命令用于后台生成RDB快照，两者的区别在于，save命令会阻塞Redis服务器，直到快照生成完毕，而bgsave命令不会阻塞Redis服务器，当bgsave命令执行时，Redis服务器仍然可以接受其他命令。 save命令和bgsave命令的调用方式如下：\n1 2 3 4 5 6 7 8 127.0.0.1:6379\u0026gt; save OK 127.0.0.1:6379\u0026gt; bgsave Background saving started # lastsave命令用于获取最近一次成功生成RDB快照的时间戳，由此可知bgsave是否执行完成 127.0.0.1:6379\u0026gt; lastsave (integer) 1722355373 注意：实际项目中，如果Redis内存数据很多，那么一旦执行save命令，Redis服务器就会长时间暂停执行命令，造成大量连接阻塞，直到快照生成完毕，从而导致线上问题。当用户输入bgsave命令时，Redis会创建一个新的进程，在该进程里把内存里的数据写入快照，在写的过程中，Redis服务器仍然可以接受其他客户端的命令，因此，bgsave命令可以减少Redis服务器的阻塞，从而提高Redis性能。\n如何选用持久化方式 对比两种持久化方式 AOF：\n优点： 可采用一秒写一次持久化文件，数据持久化更及时，文件末尾追加的方式性能更好 缺点：AOF持久化的文件一般比RDB快照体积大，恢复数据比快照慢 RDB：\n优点：快照体积小，恢复数据快，bgsave创建快照可以不阻塞其他客户端命令的执行 缺点：无法即时持久化数据，需要满足条件或手动创建快照 一般项目里会同时使用这两种持久化方式。当出现数据误删时，可以使用AOF持久化文件恢复数据，一般情况下，可以使用RDB快照文件恢复数据。\n综合使用两种持久化方式 一般可以如下设置redis.conf配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 save 600 1 # 600s内有\u0026gt;=1个键被修改就会生成快照 save 300 100 # 300s内有\u0026gt;=100个键被修改就会生成快照 save 60 1000 # 60s内有\u0026gt;=1000个键被修改就会生成快照 # 注意：以上三个条件是或的关系，RDB持久化文件只是当条件满足就生成快照，因此无法即时保存当前状态的内存数据，可能会丢失数据。 dbfilename dump.rdb dir /redisConfig # 默认的RDB文件保存路径和文件名 # 开启AOF功能，默认是关闭的 appendonly yes # 开启aof功能后，通过appendfsync设置持久化策略 appendfsync everysec 如上设置redis.conf之后，重新创建并运行容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker rm redis-server redis-server PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-server -v D:\\ArchitectPracticer\\Redis\\RedisConfRdb:/redisConfig:rw -p 6379:6379 redis:latest redis-server /redisConfig/redis.conf 807be71c3f456b0490c5e50c880d7b3e313e3813fe94ea523b538864d618605c PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server bash root@807be71c3f45:/data# redis-cli 127.0.0.1:6379\u0026gt; set name farb OK 127.0.0.1:6379\u0026gt; bgsave Background saving started 执行完毕之后，可以看到，redisConfig目录下既生成了dump.db快照文件，也生成了appendonlydir目录，该目录下包含3个aof相关的文件。两种持久化方式都开启的情况下，默认会使用AOF持久化文件恢复数据。\n查看持久化状态的命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 127.0.0.1:6379\u0026gt; info persistence # Persistence loading:0 async_loading:0 current_cow_peak:0 current_cow_size:0 current_cow_size_age:0 current_fork_perc:0.00 current_save_keys_processed:0 current_save_keys_total:0 rdb_changes_since_last_save:0 rdb_bgsave_in_progress:0 # rdb上次保存时间 rdb_last_save_time:1722357138 rdb_last_bgsave_status:ok rdb_last_bgsave_time_sec:0 rdb_current_bgsave_time_sec:-1 rdb_saves:1 rdb_last_cow_size:307200 rdb_last_load_keys_expired:0 rdb_last_load_keys_loaded:0 # 启用了aof aof_enabled:1 aof_rewrite_in_progress:0 aof_rewrite_scheduled:0 aof_last_rewrite_time_sec:-1 aof_current_rewrite_time_sec:-1 # aof上次后台重写状态成功 aof_last_bgrewrite_status:ok aof_rewrites:0 aof_rewrites_consecutive_failures:0 # aof上次写入数据成功 aof_last_write_status:ok aof_last_cow_size:0 module_fork_in_progress:0 module_fork_last_cow_size:0 aof_current_size:56 aof_base_size:0 aof_pending_rewrite:0 aof_buffer_length:0 aof_pending_bio_fsync:0 aof_delayed_fsync:0 ","date":"2024-07-27T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_06_persistency/","title":"基于Docker的Redis实战--Redis数据持久化操作"},{"content":"切换数据库操作 默认情况下，Redis服务器在启动时会创建16个数据库，不同的应用程序可以连到不同的数据库\n查看和设置默认的数据库个数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 启动一个redis-server容器，注意，-v参数是将宿主机的路径映射到docker容器中的路径，路径不能加引号 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-server -v D:\\ArchitectPracticer\\Redis\\RedisConf\\redis.conf:/redisConfig/redis.conf -p 6379:6379 redis:latest redis-server /redisConfig/redis.conf 6f245e0ac03b486dd05b414ba14a4260c23330074c7faff8ba112798614c1ea4 # 进入容器，并查看数据库的个数，默认为16 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server /bin/bash root@6f245e0ac03b:/data# redis-cli 127.0.0.1:6379\u0026gt; config get databases 1) \u0026#34;databases\u0026#34; 2) \u0026#34;16\u0026#34; # 修改宿主机的redis.conf配置文件databases 12,将数据库个数改为12 # 先停止容器，再启动容器(直接重启restart也可以)，再次查看数据库的个数为12 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker stop redis-server redis-server PS D:\\code\\blogs\\farb.github.io\u0026gt; docker start redis-server redis-server PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server /bin/bash root@6f245e0ac03b:/data# redis-cli 127.0.0.1:6379\u0026gt; config get databases 1) \u0026#34;databases\u0026#34; 2) \u0026#34;12\u0026#34; 用select命令切换数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 通过client list命令中的db=0可知，当前客户端用的是0号数据库 127.0.0.1:6379\u0026gt; client list id=3 addr=127.0.0.1:39034 laddr=127.0.0.1:6379 fd=8 name= age=111 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= # 在0号数据库设置salary之后，可以获取值 127.0.0.1:6379\u0026gt; set salary 666 OK 127.0.0.1:6379\u0026gt; get salary \u0026#34;666\u0026#34; # 当切换到1号数据库时就读取不到 127.0.0.1:6379\u0026gt; select 1 OK 127.0.0.1:6379[1]\u0026gt; get salary (nil) # 再次切换回0号数据库时，可以读取到 127.0.0.1:6379[1]\u0026gt; select 0 OK 127.0.0.1:6379\u0026gt; get salary \u0026#34;666\u0026#34; Redis事务操作 事务具有ACID特性，即原子性、一致性、隔离性和持久性。通过事务，可以让一段代码全部执行，或者全都不执行\n事务的概念和ACID特性 A:Atomicity(原子性)，即事务是一个不可分割的实体，事务中的操作要么全部执行，要么全都不执行。 C:Consistency(一致性)，即事务前后数据完整性必须一致。 I:Isolation(隔离性)，一个事务内部操作对其他事务是隔离的，并发执行的各个事务互不干扰。 D:Durability(持久性)，一个事务一旦提交，它对数据库的改变就是持久性的，哪怕数据库出现故障，事务执行后的操作也该丢失。\n实现Redis事务的相关命令 Redis有4个命令和事务有关： multi:开启redis事务 exec:提交事务 discard:取消事务 watch:监视指定的键值对，从而让事务有条件地执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 可以看到，开启事务之前和提交事务后，执行命令会立即返回结果 # 开始事务后，命令执行后不直接返回结果，而是返回QUEUED,表示放到了事务队列中。 # 当exec执行后，会一次性地执行事务队列中的命令。 127.0.0.1:6379\u0026gt; set name farb OK 127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set age 18 QUEUED 127.0.0.1:6379(TX)\u0026gt; set height 180 QUEUED 127.0.0.1:6379(TX)\u0026gt; exec 1) OK 2) OK 127.0.0.1:6379\u0026gt; get age \u0026#34;18\u0026#34; 通过discard命令撤销事务中的操作 1 2 3 4 5 6 7 8 9 10 11 12 # 执行multi开启事务后，执行的set和get命令进入事务队列， # 最后取消事务后，get sex返回nil，表示键不存在，说明事务没执行，符合预期。 127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set sex male QUEUED 127.0.0.1:6379(TX)\u0026gt; get name QUEUED 127.0.0.1:6379(TX)\u0026gt; discard OK 127.0.0.1:6379\u0026gt; get sex (nil) Redis持久化和事务持久性 Redis持久化方式有两种：AOF（Append Only File）和RDB(Redis Database) Redis的AOF持久化方式可以确保事务的持久性，而RDB不能，因为RDB的持久化方式需要满足一定的条件才能触发。 如果刚好在没满足触发条件时Redis服务器发生故障，则无法将事务影响的数据持久化到硬盘上，从而下次重启时无法恢复数据，从而导致事务持久性失效。 而AOF每个写命令都会持久化到硬盘，因而可以保证事务的持久性。\n1 2 3 4 5 6 7 8 9 # 可以通过下面命令实现基于AOF的持久化，并将配置保存到redis.conf配置文件 127.0.0.1:6379\u0026gt; config set appendfsync always OK 127.0.0.1:6379\u0026gt; config rewrite # 通过以下方式实现基于RDB的持久化 127.0.0.1:6379\u0026gt; config set dir / 127.0.0.1:6379\u0026gt; config set dbfilename redis.rdb 127.0.0.1:6379\u0026gt; config rewrite 用watch命令监视指定键 其他客户端C2修改watch监控的变量，会阻止客户端C1中的事务对该变量的修改，因为客户端C1监控时的值和更新时刻的值已经发生了变化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 在第一个控制台执行以下事务，在执行exec前，在第二个控制台连接新的客户端，更新salary的值为666888 127.0.0.1:6379\u0026gt; watch salary OK 127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set salary 1000 QUEUED # 因为在执行exec的时刻，监控的salary已经发生了改变，因而事务执行失败，结果返回nil 127.0.0.1:6379(TX)\u0026gt; exec (nil) # 返回的是第二个客户端修改的值 127.0.0.1:6379\u0026gt; get salary \u0026#34;666888\u0026#34; # 注意：unwatch只能撤销对所有键的监控，如果指定一个键则会报错 127.0.0.1:6379\u0026gt; unwatch OK # 在第二个客户端更新salary PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it redis-server /bin/bash root@6f245e0ac03b:/data# redis-cli 127.0.0.1:6379\u0026gt; get salary \u0026#34;666\u0026#34; 127.0.0.1:6379\u0026gt; set salary 666888 OK 地理位置相关操作 用geoadd命令存储地理位置 已知上海的经纬度是东经120°52′到122°12′，北纬30°40′到31°53′。\n1 2 3 4 5 6 7 8 9 10 geoadd key [NX|XX] [CH] longitude latitude member [longitude latitude member ...] # 分别将上海区域的四个角的经纬度坐标加到key为shanghai的有序集合中 127.0.0.1:6379\u0026gt; geoadd shanghai 120.52 31.53 wn (integer) 1 127.0.0.1:6379\u0026gt; geoadd shanghai 120.52 30.40 ws (integer) 1 127.0.0.1:6379\u0026gt; geoadd shanghai 122.12 31.53 en (integer) 1 127.0.0.1:6379\u0026gt; geoadd shanghai 122.12 30.40 es 获取地理位置的经纬度信息 1 2 3 4 5 6 7 8 9 10 geopos key [member [member ...]] 127.0.0.1:6379\u0026gt; geopos shanghai (empty array) # 获取上海西北角的经纬度，不传member或者member不存在，都没有返回值 127.0.0.1:6379\u0026gt; geopos shanghai wn 1) 1) \u0026#34;120.52000075578689575\u0026#34; 2) \u0026#34;31.53000103201371473\u0026#34; 127.0.0.1:6379\u0026gt; geopos shanghai notexist 1) (nil) 查询指定范围内的地理信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 georadius key longitude latitude radius M|KM|FT|MI [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count [ANY]] [ASC|DESC] [STORE key|STOREDIST key] # longitude latitude是中心点 # radius是半径 # M|KM|FT|MI是单位 # [WITHCOORD]加上该参数会把对应地理信息的经纬度一起返回 # [WITHDIST] 会把和中心点的距离一起返回 # [WITHHASH] 会返回地理信息的哈希编码 # [COUNT count [ANY]] 指定返回数据的数量 # [ASC|DESC] 指定返回的顺序 # [STORE key|STOREDIST key] 会将返回结果或者返回的距离存储到缓存中 # 下面返回key为shanghai的数据集中，距离中心点（上海西南角）200KM的所有点，同时返回点的坐标，距离，并以升序排列 127.0.0.1:6379\u0026gt; georadius shanghai 120.52 30.40 200 KM withcoord withDist asc 1) 1) \u0026#34;ws\u0026#34; 2) \u0026#34;0.0001\u0026#34; 3) 1) \u0026#34;120.52000075578689575\u0026#34; 2) \u0026#34;30.39999952668997452\u0026#34; 2) 1) \u0026#34;wn\u0026#34; 2) \u0026#34;125.6858\u0026#34; 3) 1) \u0026#34;120.52000075578689575\u0026#34; 2) \u0026#34;31.53000103201371473\u0026#34; 3) 1) \u0026#34;es\u0026#34; 2) \u0026#34;153.4932\u0026#34; 3) 1) \u0026#34;122.11999744176864624\u0026#34; 2) \u0026#34;30.39999952668997452\u0026#34; 4) 1) \u0026#34;en\u0026#34; 2) \u0026#34;197.6902\u0026#34; 3) 1) \u0026#34;122.11999744176864624\u0026#34; 2) \u0026#34;31.53000103201371473\u0026#34; 查询地理位置间的距离 1 2 3 4 5 6 7 geodist key member1 member2 [M|KM|FT|MI] # 返回key为shanghai的数据集合中，ws和en的距离，单位为km， # 可以看到，上海西南到东北的距离大约是198km # 如果有任何一个坐标名称不存在坐标，则返回nil 127.0.0.1:6379\u0026gt; geodist shanghai ws en KM \u0026#34;197.6902\u0026#34; 位图的应用 和编程语言中的位操作是一个道理，就是二进制运算。\nsetbit 和 getbit 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 setbit key offset value # offset表示偏移量 # value表示设置的值，为0或1 127.0.0.1:6379\u0026gt; setbit myBitmap 0 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit myBitmap 1 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit myBitmap 2 0 (integer) 0 127.0.0.1:6379\u0026gt; setbit myBitmap 3 0 (integer) 0 # 2不在0和1的范围，所以报错 127.0.0.1:6379\u0026gt; setbit myBitmap 5 2 (error) ERR bit is not an integer or out of range 127.0.0.1:6379\u0026gt; getbit myBitmap 1 (integer) 1 127.0.0.1:6379\u0026gt; getbit myBitmap 2 (integer) 0 # 键不存在返回0 127.0.0.1:6379\u0026gt; getbit notExist 5 (integer) 0 用bitop对位图进行运算 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 支持4种逻辑运算，destkey是结果的存储键 bitop AND|OR|XOR|NOT destkey key [key ...] 127.0.0.1:6379\u0026gt; setbit b1 0 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit b1 1 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit b1 3 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit b2 2 1 (integer) 0 # 不小心写错了名字，可以看到结果执行不成功，返回0 127.0.0.1:6379\u0026gt; bitop and res bit1 bit2 (integer) 0 # 1011 \u0026amp; 0100 = 0 127.0.0.1:6379\u0026gt; bitop and res b1 b2 (integer) 1 127.0.0.1:6379\u0026gt; get res \u0026#34;\\x00\u0026#34; # 1011 | 0100 = 1111 127.0.0.1:6379\u0026gt; bitop or res b1 b2 (integer) 1 127.0.0.1:6379\u0026gt; getbit res 2 (integer) 1 # not 1011 = 0100 127.0.0.1:6379\u0026gt; bitop not res b1 (integer) 1 127.0.0.1:6379\u0026gt; getbit res 1 (integer) 0 127.0.0.1:6379\u0026gt; getbit res 2 (integer) 1 #1011 xor 0100 = 1111 127.0.0.1:6379\u0026gt; bitop xor res b1 b2 (integer) 1 127.0.0.1:6379\u0026gt; getbit res 0 (integer) 1 127.0.0.1:6379\u0026gt; getbit res 3 (integer) 1 bitcount操作 bitcount统计键key的位图中1出现的次数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 bitcount key [start end [BYTE|BIT]] # start end表示统计的字节组范围 127.0.0.1:6379\u0026gt; setbit user1 0 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit user1 3 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit user1 7 1 (integer) 0 # 这个不难理解，结果存储的格式是10001001，一个字节中有3个1 127.0.0.1:6379\u0026gt; bitcount user1 (integer) 3 # 默认单位是BYTE，也就是统计第0到0个字节范围中的1，其实就是第一个字节，结果还是3 127.0.0.1:6379\u0026gt; bitcount user1 0 0 (integer) 3 # 如果单位是BIT，则前6位中的1有2个 127.0.0.1:6379\u0026gt; bitcount user1 0 5 BIT (integer) 2 慢查询实战 慢查询相关的配置参数 slow-log-slower-than: 单位为微秒。即超过该参数指定时间的查询会记录到日志中。 slowlog-max-len: 慢查询日志里记录的日志条数，当超过该条数时，会删除最老的一条日志。 1 2 3 4 5 6 # 可以直接修改redis.conf配置文件或者通过命令修改 127.0.0.1:6379\u0026gt; config set slowlog-log-slower-than 1 OK 127.0.0.1:6379\u0026gt; config set slowlog-max-len 100 OK 127.0.0.1:6379\u0026gt; config rewrite 用slowlog get命令观察慢查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 为了演示慢查询，上面设置了 config set slowlog-log-slower-than 1 # 即超过1毫秒的命令都会记录到慢日志中 127.0.0.1:6379\u0026gt; slowlog get 1) 1) (integer) 3 2) (integer) 1721923737 3) (integer) 3 4) 1) \u0026#34;get\u0026#34; 2) \u0026#34;name\u0026#34; 5) \u0026#34;127.0.0.1:45308\u0026#34; 6) \u0026#34;\u0026#34; 2) 1) (integer) 2 2) (integer) 1721923735 3) (integer) 5 4) 1) \u0026#34;set\u0026#34; 2) \u0026#34;name\u0026#34; 3) \u0026#34;farb\u0026#34; 慢查询相关命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 获取指定数量的慢查询日志 slowlog get [count] 127.0.0.1:6379\u0026gt; slowlog get 1 1) 1) (integer) 5 2) (integer) 1721923903 3) (integer) 3 4) 1) \u0026#34;slowlog\u0026#34; 2) \u0026#34;get\u0026#34; 3) \u0026#34;3\u0026#34; 5) \u0026#34;127.0.0.1:45308\u0026#34; 6) \u0026#34;\u0026#34; # 获取慢查询的长度 slowlog len # 清空慢查询日志 slowlog reset 127.0.0.1:6379\u0026gt; slowlog len (integer) 7 127.0.0.1:6379\u0026gt; slowlog reset OK 127.0.0.1:6379\u0026gt; slowlog len (integer) 1 ","date":"2024-07-24T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_05_db_in_action/","title":"基于Docker的Redis实战--Redis数据库操作实践"},{"content":"Redis服务器管理客户端的命令 获取或设置客户端的名字 1 2 3 4 5 6 7 8 9 10 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker start firstRedis firstRedis PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it firstRedis /bin/bash root@380d98e7beb9:/data# redis-cli 127.0.0.1:6379\u0026gt; client getname # 获取客户端名称 (nil) 127.0.0.1:6379\u0026gt; client setname client1 # 设置客户端名称 OK 127.0.0.1:6379\u0026gt; client getname \u0026#34;client1\u0026#34; 通过client list查看客户端信息 1 2 3 4 5 6 7 8 9 10 11 12 13 127.0.0.1:6379\u0026gt; client list id=3 addr=127.0.0.1:32982 laddr=127.0.0.1:6379 fd=8 name=client1 age=133 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= # id:客户端的编号 # addr:客户端的地址 # name:客户端名称 # age:客户端的连接时长，单位是s # idle：客户端的空闲时长，单位是s # db：客户端用到的服务器数据库索引号，默认每个redis服务器有16个数据库，且默认使用0号数据库 # cmd: 客户端最近执行的命令 # user:登录服务器用到的用户名 # 如果有多个客户端连接，则返回多行 通过client pause暂停客户端的命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 client pause timeout [WRITE|ALL] # 如果服务端压力过大，则可暂停执行客户端的命令 # timeout表示暂停的毫秒数 127.0.0.1:6379\u0026gt; client pause 10000 OK 127.0.0.1:6379\u0026gt; set name val2 OK (3.89s) # 客户端暂停10s后，执行set命令时不会立即执行，而是会卡住，最后返回结果和卡住的时间。 127.0.0.1:6379\u0026gt; client pause 10000 OK 127.0.0.1:6379\u0026gt; get name \u0026#34;val2\u0026#34; (2.71s) # 默认参数为ALL，读写都会暂停 # 如果只指定写的命令暂停，那么读的命令不会暂停 127.0.0.1:6379\u0026gt; client pause 10000 write OK 127.0.0.1:6379\u0026gt; get name \u0026#34;val2\u0026#34; 127.0.0.1:6379\u0026gt; set name val3 OK (4.15s) 通过client kill中断客户端的连接 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 client kill ip:port|[ID client-id]|[TYPE NORMAL|MASTER|SLAVE|REPLICA|PUBSUB]|[USER username]|[ADDR ip:port]|[LADDR ip:port]|[SKIPME YES|NO] [[ID client-id]|[TYPE NORMAL|MAS # 可以看到终端客户端的连接支持很多参数 127.0.0.1:6379\u0026gt; client list id=3 addr=127.0.0.1:32982 laddr=127.0.0.1:6379 fd=8 name=client1 age=1420 idle=391 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=0 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=1928 events=r cmd=set user=default redir=-1 resp=2 lib-name= lib-ver= id=4 addr=127.0.0.1:41212 laddr=127.0.0.1:6379 fd=9 name= age=179 idle=179 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=0 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=1928 events=r cmd=command|docs user=default redir=-1 resp=2 lib-name= lib-ver= id=5 addr=127.0.0.1:41528 laddr=127.0.0.1:6379 fd=10 name= age=8 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= 127.0.0.1:6379\u0026gt; client kill 127.0.0.1:32982 OK 127.0.0.1:6379\u0026gt; client kill 127.0.0.1:41212 OK 127.0.0.1:6379\u0026gt; client list id=5 addr=127.0.0.1:41528 laddr=127.0.0.1:6379 fd=10 name= age=190 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= # 查看中断的客户端，执行get命令时，发现报错。 127.0.0.1:6379\u0026gt; get name Error: Broken pipe not connected\u0026gt; shutdown关闭服务器和客户端 1 2 127.0.0.1:6379\u0026gt; shutdown # shutdown 会终止服务器上的所有客户端连接，并终止服务器 查看Redis服务器的详细信息 info命令查看服务器信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 127.0.0.1:6379\u0026gt; info # Server 服务端信息 redis_version:7.2.5 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:c2b7a5cd72a5634f redis_mode:standalone os:Linux 5.15.153.1-microsoft-standard-WSL2 x86_64 arch_bits:64 monotonic_clock:POSIX clock_gettime multiplexing_api:epoll atomicvar_api:c11-builtin gcc_version:12.2.0 process_id:1 process_supervised:no run_id:7284acf78bb2982dc66fec7c06a0fcb79ab0865a tcp_port:6379 server_time_usec:1721658345403020 uptime_in_seconds:21 uptime_in_days:0 hz:10 configured_hz:10 lru_clock:10382313 executable:/data/redis-server config_file: io_threads_active:0 listener0:name=tcp,bind=*,bind=-::*,port=6379 # Clients 已连接的客户端信息 connected_clients:1 cluster_connections:0 maxclients:10000 client_recent_max_input_buffer:8 client_recent_max_output_buffer:0 blocked_clients:0 tracking_clients:0 clients_in_timeout_table:0 total_blocking_keys:0 total_blocking_keys_on_nokey:0 # Memory 服务器内存的相关信息 used_memory:917080 used_memory_human:895.59K used_memory_rss:14802944 used_memory_rss_human:14.12M used_memory_peak:1135136 used_memory_peak_human:1.08M used_memory_peak_perc:80.79% used_memory_overhead:868656 used_memory_startup:865744 used_memory_dataset:48424 used_memory_dataset_perc:94.33% allocator_allocated:1456640 allocator_active:1572864 allocator_resident:7090176 total_system_memory:16626606080 total_system_memory_human:15.48G used_memory_lua:31744 used_memory_vm_eval:31744 used_memory_lua_human:31.00K used_memory_scripts_eval:0 number_of_cached_scripts:0 number_of_functions:0 number_of_libraries:0 used_memory_vm_functions:32768 used_memory_vm_total:64512 used_memory_vm_total_human:63.00K used_memory_functions:184 used_memory_scripts:184 used_memory_scripts_human:184B maxmemory:0 maxmemory_human:0B maxmemory_policy:noeviction allocator_frag_ratio:1.08 allocator_frag_bytes:116224 allocator_rss_ratio:4.51 allocator_rss_bytes:5517312 rss_overhead_ratio:2.09 rss_overhead_bytes:7712768 mem_fragmentation_ratio:16.55 mem_fragmentation_bytes:13908752 mem_not_counted_for_evict:0 mem_replication_backlog:0 mem_total_replication_buffers:0 mem_clients_slaves:0 mem_clients_normal:1928 mem_cluster_links:0 mem_aof_buffer:0 mem_allocator:jemalloc-5.3.0 active_defrag_running:0 lazyfree_pending_objects:0 lazyfreed_objects:0 # Persistence 持久化相关信息 loading:0 async_loading:0 current_cow_peak:0 current_cow_size:0 current_cow_size_age:0 current_fork_perc:0.00 current_save_keys_processed:0 current_save_keys_total:0 rdb_changes_since_last_save:0 rdb_bgsave_in_progress:0 rdb_last_save_time:1721658324 rdb_last_bgsave_status:ok rdb_last_bgsave_time_sec:-1 rdb_current_bgsave_time_sec:-1 rdb_saves:0 rdb_last_cow_size:0 rdb_last_load_keys_expired:0 rdb_last_load_keys_loaded:16 aof_enabled:0 aof_rewrite_in_progress:0 aof_rewrite_scheduled:0 aof_last_rewrite_time_sec:-1 aof_current_rewrite_time_sec:-1 aof_last_bgrewrite_status:ok aof_rewrites:0 aof_rewrites_consecutive_failures:0 aof_last_write_status:ok aof_last_cow_size:0 module_fork_in_progress:0 module_fork_last_cow_size:0 # Stats 服务器相关的统计信息 total_connections_received:1 total_commands_processed:1 instantaneous_ops_per_sec:0 total_net_input_bytes:41 total_net_output_bytes:205205 total_net_repl_input_bytes:0 total_net_repl_output_bytes:0 instantaneous_input_kbps:0.00 instantaneous_output_kbps:0.00 instantaneous_input_repl_kbps:0.00 instantaneous_output_repl_kbps:0.00 # 拒绝连接数，超过最大连接数后，连接会被拒绝 rejected_connections:0 sync_full:0 sync_partial_ok:0 sync_partial_err:0 expired_keys:0 expired_stale_perc:0.00 expired_time_cap_reached_count:0 expire_cycle_cpu_milliseconds:0 evicted_keys:0 evicted_clients:0 total_eviction_exceeded_time:0 current_eviction_exceeded_time:0 keyspace_hits:0 keyspace_misses:0 pubsub_channels:0 pubsub_patterns:0 pubsubshard_channels:0 latest_fork_usec:0 total_forks:0 migrate_cached_sockets:0 slave_expires_tracked_keys:0 active_defrag_hits:0 active_defrag_misses:0 active_defrag_key_hits:0 active_defrag_key_misses:0 total_active_defrag_time:0 current_active_defrag_time:0 tracking_total_keys:0 tracking_total_items:0 tracking_total_prefixes:0 unexpected_error_replies:0 total_error_replies:0 dump_payload_sanitizations:0 total_reads_processed:2 total_writes_processed:3 io_threaded_reads_processed:0 io_threaded_writes_processed:0 reply_buffer_shrinks:1 reply_buffer_expands:0 eventloop_cycles:213 eventloop_duration_sum:13918 eventloop_duration_cmd_sum:389 instantaneous_eventloop_cycles_per_sec:9 instantaneous_eventloop_duration_usec:62 acl_access_denied_auth:0 acl_access_denied_cmd:0 acl_access_denied_key:0 acl_access_denied_channel:0 # Replication 数据库主从复制相关的信息 role:master connected_slaves:0 master_failover_state:no-failover master_replid:35faf12e5068ef7be8ccb60da6198a1964e11907 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 # CPU Redis服务器所在机器的相关信息 used_cpu_sys:0.009357 used_cpu_user:0.019368 used_cpu_sys_children:0.000207 used_cpu_user_children:0.000866 used_cpu_sys_main_thread:0.027521 used_cpu_user_main_thread:0.000000 # Modules # Errorstats # Cluster 集群相关信息 cluster_enabled:0 # Keyspace 包含了和数据库相关的统计信息，如键数量和超时时间等 db0:keys=16,expires=0,avg_ttl=0 查看客户端连接状况 1 2 3 4 5 6 7 8 9 10 11 12 127.0.0.1:6379\u0026gt; info clients # Clients connected_clients:1 #已连接的客户端数 cluster_connections:0 maxclients:10000 client_recent_max_input_buffer:8 client_recent_max_output_buffer:0 blocked_clients:0 tracking_clients:0 clients_in_timeout_table:0 total_blocking_keys:0 total_blocking_keys_on_nokey:0 观察最大连接数 1 2 3 4 5 6 7 8 # 通过info Clients可以看到默认的最大客户端连接数是10000 # 也可以通过config get获取 127.0.0.1:6379\u0026gt; config get maxclients 1) \u0026#34;maxclients\u0026#34; 2) \u0026#34;10000\u0026#34; # 如果发现1w个连接不够用，可以设置大一些 config set maxclients 200000 value 查看每秒执行多少指令 1 2 3 4 5 # Info stats中下列项表示每秒执行的操作 instantaneous_ops_per_sec:0 # 当发现集群里面Redis服务器的该数值过大或过小，就需要观察负载均衡的相关配置 # 当发现数据库压力过大而该值较小时，就需要调整缓存策略 观察内存用量 Redis在内存中缓存数据，如果缓存数据过多，或者大量键没有设置过期时间，就会造成内存使用过大，从而导致OOM。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 127.0.0.1:6379\u0026gt; info memory # Memory used_memory:964832 used_memory_human:942.22K used_memory_rss:15634432 used_memory_rss_human:14.91M used_memory_peak:1185104 used_memory_peak_human:1.13M used_memory_peak_perc:81.41% used_memory_overhead:868656 used_memory_startup:865744 used_memory_dataset:96176 used_memory_dataset_perc:97.06% allocator_allocated:1795584 allocator_active:1949696 allocator_resident:7467008 total_system_memory:16626606080 total_system_memory_human:15.48G used_memory_lua:31744 used_memory_vm_eval:31744 used_memory_lua_human:31.00K used_memory_scripts_eval:0 number_of_cached_scripts:0 number_of_functions:0 number_of_libraries:0 used_memory_vm_functions:32768 used_memory_vm_total:64512 used_memory_vm_total_human:63.00K used_memory_functions:184 used_memory_scripts:184 used_memory_scripts_human:184B maxmemory:0 maxmemory_human:0B maxmemory_policy:noeviction allocator_frag_ratio:1.09 allocator_frag_bytes:154112 allocator_rss_ratio:3.83 allocator_rss_bytes:5517312 rss_overhead_ratio:2.09 rss_overhead_bytes:8167424 mem_fragmentation_ratio:16.56 mem_fragmentation_bytes:14690272 mem_not_counted_for_evict:0 mem_replication_backlog:0 mem_total_replication_buffers:0 mem_clients_slaves:0 mem_clients_normal:1928 mem_cluster_links:0 mem_aof_buffer:0 mem_allocator:jemalloc-5.3.0 active_defrag_running:0 lazyfree_pending_objects:0 lazyfreed_objects:0 # used_memory_human:操作系统分配给Redis多少内存 # used_memory_peak_human:1.13M Redis服务器用到的内存峰值 # used_memory_lua_human:31.00K Lua脚本所占用的内存 # used_memory_scripts_human:184B 脚本所占用的内存 # mem_clients_slaves:0 客户端因主从复制而使用的内存用量 用command命令查看Redis命令 1 2 3 4 5 6 7 8 9 10 11 command # 返回服务器保护的所有命令信息 command count # 统计当前Redis服务器命令个数 command info [command-name [command-name ...]] # 获取指定命令的详细信息 command getkeys command [arg [arg ...]] # 获取指定命令的所有键 127.0.0.1:6379\u0026gt; command getkeys set name farb 1) \u0026#34;name\u0026#34; 查看并修改服务器的常用配置 查看服务器的配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 config get * # 获取所有的服务器配置 # 获取以p开头的配置，支持通配符模糊匹配 127.0.0.1:6379\u0026gt; config get p* 1) \u0026#34;proc-title-template\u0026#34; 2) \u0026#34;{title} {listen-addr} {server-mode}\u0026#34; 3) \u0026#34;proto-max-bulk-len\u0026#34; 4) \u0026#34;536870912\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;6379\u0026#34; 7) \u0026#34;protected-mode\u0026#34; 8) \u0026#34;no\u0026#34; 9) \u0026#34;pidfile\u0026#34; 10) \u0026#34;\u0026#34; 11) \u0026#34;propagation-error-behavior\u0026#34; 12) \u0026#34;ignore\u0026#34; 修改服务器配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 config set parameter value [parameter value ...] # parameter是配置项，value是值，支持多个项一起配置 # 通过config set命令修改的配置无需重启即可生效 127.0.0.1:6379\u0026gt; config set requirepass 123456 OK # 默认连接到Redis服务器不需要密码，此处设置密码 127.0.0.1:6379\u0026gt; quit root@380d98e7beb9:/data# redis-cli # 退出并重新登录客户端后，获取配置发现提示没有权限 127.0.0.1:6379\u0026gt; config get p* (error) NOAUTH Authentication required. # 使用auth password登录 127.0.0.1:6379\u0026gt; auth 123456 OK 127.0.0.1:6379\u0026gt; config get req* 1) \u0026#34;requirepass\u0026#34; 2) \u0026#34;123456\u0026#34; # 先关闭Redis服务器，从而docker容器自动关闭 # 再启动容器并进入，然后查看密码，发现密码已清空 # 从而说明，config set虽然不需要重启服务器生效，但是重启服务器之后设置就会失效 127.0.0.1:6379\u0026gt; shutdown PS D:\\code\\blogs\\farb.github.io\u0026gt; docker start firstRedis firstRedis PS D:\\code\\blogs\\farb.github.io\u0026gt; docker exec -it firstRedis /bin/bash root@380d98e7beb9:/data# redis-cli 127.0.0.1:6379\u0026gt; config get requirepass 1) \u0026#34;requirepass\u0026#34; 2) \u0026#34;\u0026#34; 用config rewrite命令改写Redis配置文件 1 2 3 4 5 6 7 # 执行完config set之后，再执行config rewrite就会将配置保存到redis.conf文件 # 如果配置文件不存在就会报错 127.0.0.1:6379\u0026gt; config set requirepass 123456 OK 127.0.0.1:6379\u0026gt; config rewrite (error) ERR The server is running without a config file # 下面说明如何生成reids.conf 启动Redis服务器时加载配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 1.创建文件 D:\\ArchitectPracticer\\Redis\\RedisConf\\redis.conf 并设置内容如下 port 6379 bind 127.0.0.1 timeout 300 # port为端口号，bind为绑定的ip,timeout为连上的客户端空闲300s后，服务器将终止该客户端的连接，这些均是默认值 # 上面的路径和文件名都是可以改变的 # 2.使用redis.conf配置文件启动容器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redisWithConfig -v D:\\ArchitectPracticer\\Redis\\RedisConf\\redis.conf:/redisConfig/redis.conf -p 6379:6379 redis:latest redis-server/redisConfig/redis.conf d2944577be148ee004cce434a72db5e5a3d9264d0129130c1e61616fc199a5cf docker: Error response from daemon: driver failed programming external connectivity on endpoint redisWithConfig (82c4756e055f9861e0804672db4e0b9ac108558b6e7e8e85b3f15af71319e932): Bind for 0.0.0.0:6379 failed: port is already allocated. # 因为之前已经创建了一个firstRedis容器占用了6379端口，所以先要删除之前的容器 docker rm firstRedis PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redisWithConfig -v D:\\ArchitectPracticer\\Redis\\RedisConf\\redis.conf:/redisConfig/redis.conf -p 6379:6379 redis:latest redis-server /redisConfig/redis.conf ca7280d0f6de05f0d26067e21b68ed9a231480f66b051a456662305fcfedda88 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca7280d0f6de redis:latest \u0026#34;docker-entrypoint.s…\u0026#34; 3 seconds ago Up 2 seconds 0.0.0.0:6379-\u0026gt;6379/tcp redisWithConfig # -itd指定以分离的交互式终端运行， # --name设置容器的名称 # -v 指定本机和Docker内目录的映射关系，注意先本机路径，再docker路径 # -p 指定docker的6379端口映射到主机的6379端口，注意先docker，再本机 # redis:latest 为最新的redis镜像 # 再用redis-server /redisConfig/redis.conf指定启动容器时默认运行的命令 # 3.验证保存配置 docker exec -it redisWithConfig /bin/bash root@ca7280d0f6de:/data# redis-cli 127.0.0.1:6379\u0026gt; config get requirepass 1) \u0026#34;requirepass\u0026#34; 2) \u0026#34;\u0026#34; 127.0.0.1:6379\u0026gt; config set requirepass 123456 OK 127.0.0.1:6379\u0026gt; config rewrite OK 多个客户端连接远端服务器 多个Redis客户端连接远端服务器 启动三个容器，一个容器启动Redis服务器，两个容器启动两个Redis客户端，模拟两个客户端远程连接到服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 启动一个容器，保护Redis服务器 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -itd --name redis-server redis:latest bbd384d02e177ab6b65ca7f0670707d250b16ec0bf1596c75d0db879ed9e2065 # 启动客户端1，并设置值 # --link redis-server:server 参数项连接到了redis-server服务器上，:server表示服务器的别名 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -it --name redis-client1 --link redis-server:server redis:latest /bin/bash root@10038abf0e0f:/data# redis-cli -h server -p 6379 server:6379\u0026gt; set name farbguo OK # 启动客户端2，并读取值 PS D:\\code\\blogs\\farb.github.io\u0026gt; docker run -it --name redis-client2 --link redis-server:server redis:latest /bin/bash root@b8d623344268:/data# redis-cli -h server -p 6379 server:6379\u0026gt; get name \u0026#34;farbguo\u0026#34; 通过docker inspect观察IP地址 1 2 3 4 5 6 7 8 9 10 11 12 13 docker inspect redis-client1 # 在redis-server所在容器中查看客户端1的信息，会返回很长信息，下面仅截取部分。 \u0026#34;Networks\u0026#34;: { \u0026#34;bridge\u0026#34;: { \u0026#34;IPAMConfig\u0026#34;: null, \u0026#34;Links\u0026#34;: null, \u0026#34;Aliases\u0026#34;: null, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:11:00:04\u0026#34;, \u0026#34;NetworkID\u0026#34;: \u0026#34;aa279f1a1aca3000771c18447f8fa16439fc4339cf3522f19bfad3abf7cbbba9\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;f8e8ef3128c0f83b00a89b7ad53d5ee8f3916b50a44b718fbef478ea1b57a895\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.4\u0026#34;, \u0026#34;IPPrefixLen\u0026#34;: 16, 查看所有客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 # 在redis-client2容器上查看所有客户端 server:6379\u0026gt; client list id=4 addr=172.17.0.5:38928 laddr=172.17.0.3:6379 fd=9 name= age=892 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= id=5 addr=172.17.0.4:59982 laddr=172.17.0.3:6379 fd=8 name= age=5 idle=5 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=0 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=1928 events=r cmd=command|docs user=default redir=-1 resp=2 lib-name= lib-ver= # 以上发现，id为4的客户端name为空，下面修改之后就有值了。 server:6379\u0026gt; client setname client2 OK server:6379\u0026gt; client getname \u0026#34;client2\u0026#34; server:6379\u0026gt; client list id=4 addr=172.17.0.5:38928 laddr=172.17.0.3:6379 fd=9 name=client2 age=992 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22426 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= id=5 addr=172.17.0.4:59982 laddr=172.17.0.3:6379 fd=8 name= age=105 idle=105 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=0 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=1928 events=r cmd=command|docs user=default redir=-1 resp=2 lib-name= lib-ver= 通过info查看服务器状态 1 2 3 4 5 # 可以在任何一台客户端上查看服务器状态信息， # 通过info section命令，可以查看每个配置节点的信息 server:6379\u0026gt; info keyspace # Keyspace db0:keys=1,expires=0,avg_ttl=0 注意：在任何一个客户端使用shutdown命令都可以关闭服务器和所有连接的客户端。生产环境务必注意，否则可能造成数据丢失，导致事故\n","date":"2024-07-22T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_04_server_and_client/","title":"基于Docker的Redis实战--实践Redis服务器和客户端的操作"},{"content":"键操作命令 exists判断键是否存在 1 2 3 4 5 6 exists key [key ...] # 判断key是否存在，可以一次指定多个key。返回值是key存在的个数。 127.0.0.1:6379\u0026gt; exists key key1 key2 key3 (integer) 3 # 因为key3不存在，所以返回前3个存在的key数量。 keys命令查找键 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 keys pattern # 可以使用通配符或正则表达式查找键，？代替一位字符，*匹配零个、一个或多个字符。 # 注意：keys * 可以返回所有的键，但是项目中的键可能很多，全部返回没有意义，生产环境还会造成性能风险。 127.0.0.1:6379\u0026gt; keys key? 1) \u0026#34;key1\u0026#34; 2) \u0026#34;key2\u0026#34; 127.0.0.1:6379\u0026gt; keys key* 1) \u0026#34;key1\u0026#34; 2) \u0026#34;key\u0026#34; 3) \u0026#34;key2\u0026#34; 127.0.0.1:6379\u0026gt; keys key 1) \u0026#34;key\u0026#34; 127.0.0.1:6379\u0026gt; keys * 1) \u0026#34;blogUrl\u0026#34; 2) \u0026#34;hkey\u0026#34; 3) \u0026#34;key1\u0026#34; 4) \u0026#34;k3\u0026#34; 5) \u0026#34;key\u0026#34; 6) \u0026#34;key2\u0026#34; 7) \u0026#34;sortedSet\u0026#34; scan命令查找键 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 scan cursor [MATCH pattern] [COUNT count] [TYPE type] # scan类似于分页，cursor是游标的位置，从0开始启动迭代， # 默认pattern返回所有key, 默认count每次返回10个key # 返回的值是下次游标的迭代位置和key的数组，如果游标返回0，表明迭代结束 # keys是以阻塞的方式返回键，scan是以非阻塞的方式查找并返回键 # 如果待查找的键的数量很多耗时可能较长，Redis的单线程可能导致无法执行其他命令， # 严重的话会导致系统卡顿，因此使用时注意是开发还是生产环境，键的数量多少。 127.0.0.1:6379\u0026gt; scan 0 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;key1\u0026#34; 2) \u0026#34;hkey\u0026#34; 3) \u0026#34;key\u0026#34; 4) \u0026#34;key2\u0026#34; 5) \u0026#34;blogUrl\u0026#34; 6) \u0026#34;k3\u0026#34; 7) \u0026#34;sortedSet\u0026#34; 127.0.0.1:6379\u0026gt; set name farb OK 127.0.0.1:6379\u0026gt; set sex man OK 127.0.0.1:6379\u0026gt; set age 18 OK 127.0.0.1:6379\u0026gt; set height 180 OK 127.0.0.1:6379\u0026gt; scan 0 1) \u0026#34;7\u0026#34; 2) 1) \u0026#34;key1\u0026#34; 2) \u0026#34;hkey\u0026#34; 3) \u0026#34;name\u0026#34; 4) \u0026#34;key2\u0026#34; 5) \u0026#34;key\u0026#34; 6) \u0026#34;height\u0026#34; 7) \u0026#34;blogUrl\u0026#34; 8) \u0026#34;k3\u0026#34; 9) \u0026#34;sex\u0026#34; 10) \u0026#34;age\u0026#34; 127.0.0.1:6379\u0026gt; scan 7 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;sortedSet\u0026#34; 重命名键 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 rename key newkey # 将旧键key重命名为新键newKey，如果newKey之气已经存在，则会覆盖之前的值 renamenx key newkey # 如果新键名newKey不存在则重命名 127.0.0.1:6379\u0026gt; rename sex gender OK 127.0.0.1:6379\u0026gt; get gender \u0026#34;man\u0026#34; 127.0.0.1:6379\u0026gt; get sex (nil) # name已存在，所以不会成功 127.0.0.1:6379\u0026gt; renamenx gender name (integer) 0 127.0.0.1:6379\u0026gt; renamenx gender sex (integer) 1 del命令删除键 1 2 3 4 5 6 del key [key ...] # 支持一次性删除多个键，返回值删除键的个数 # 因为keyn不存在，key存在，故返回1 127.0.0.1:6379\u0026gt; del key keyn (integer) 1 关于键生存时间的命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 pttl key ttl key # pttl以毫秒返回，ttl以秒返回。 # key不存在，返回-2 # key存在但没设置生存时间，返回-1 # 可以使用set命令时通过ex或px指定key的生存时间 # 也可以通过 expire key seconds [NX|XX|GT|LT] # 或 pexpire key milliseconds [NX|XX|GT|LT]指定生存时间 127.0.0.1:6379\u0026gt; pttl key (integer) -2 127.0.0.1:6379\u0026gt; pttl key1 (integer) -1 127.0.0.1:6379\u0026gt; set mykey myval ex 300 OK 127.0.0.1:6379\u0026gt; ttl mykey (integer) 293 HyperLogLog相关命令 HyperLogLog对象能高效地统计基数，每个HyperLogLog对象大概只需要12KB内存就能计算2^64的元素的基数。\npfadd添加键值对 1 2 3 4 5 6 7 pfadd key [element [element ...]] # 可以对同一个键添加多个值 127.0.0.1:6379\u0026gt; pfadd Perter Math Computer Music (integer) 1 127.0.0.1:6379\u0026gt; pfcount Perter (integer) 3 pfcount统计基数值 1 2 3 4 5 6 7 8 9 10 11 pfcount key [key ...] # 查看一个或多个键的基数,统计的是多个键中有多少个不重复的数据，是一个近似值，当基数量很大时结果未必精确。 127.0.0.1:6379\u0026gt; pfadd set1 1 2 3 (integer) 1 127.0.0.1:6379\u0026gt; pfadd set2 2 4 5 (integer) 1 127.0.0.1:6379\u0026gt; pfcount set1 set2 (integer) 5 127.0.0.1:6379\u0026gt; pfcount nonExistKey (integer) 0 pfmerge进行合并操作 1 2 3 4 5 6 7 8 pfmerge destkey [sourcekey [sourcekey ...]] # 将一个或多个hyperLogLog对象合并成一个，destKey是合并后的HyperLogLog对象的键， # 如果destKey不存在，则创建 127.0.0.1:6379\u0026gt; pfmerge set3 set1 set2 OK 127.0.0.1:6379\u0026gt; pfcount set3 (integer) 5 统计网站访问总人数 1 2 3 4 5 127.0.0.1:6379\u0026gt; pfadd totalUserCount u1 u2 u3 u1 u3 (integer) 1 127.0.0.1:6379\u0026gt; pfcount totalUserCount (integer) 3 # pfcount会自动去重同一个用户 Lua脚本相关命令 lua是一种轻量的脚本语言，可以嵌入到应用程序中，能以较小的代价定制功能。\n把lua脚本装载到缓存里 1 2 3 4 5 6 7 8 9 script load scriptContent # 把脚本scriptContent装载到缓存里，不执行脚本，返回脚本的sha1校验和 127.0.0.1:6379\u0026gt; script load \u0026#39;return 1+2\u0026#39; \u0026#34;e13c398af9f2658ef7050acf3b266f87cfc2f6ab\u0026#34; # 判断指定校验和的脚本是否存在 127.0.0.1:6379\u0026gt; script exists e13c398af9f2658ef7050acf3b266f87cfc2f6ab 1) (integer) 1 evalsha执行缓存中的脚本 1 2 3 4 5 6 evalsha sha1 numkeys [key [key ...]] [arg [arg ...]] #sha1为载入缓存中的lua脚本的校验和，numKeys是参数的个数 # key指定脚本中用到的键，arg指定脚本中的参数 127.0.0.1:6379\u0026gt; evalsha e13c398af9f2658ef7050acf3b266f87cfc2f6ab 0 (integer) 3 清空缓存中的脚本 1 2 3 4 5 6 7 8 9 script flush [ASYNC|SYNC] # 清空缓存中的所有脚本，可以指定异步还是同步 127.0.0.1:6379\u0026gt; script exists e13c398af9f2658ef7050acf3b266f87cfc2f6ab 1) (integer) 1 127.0.0.1:6379\u0026gt; script flush OK 127.0.0.1:6379\u0026gt; script exists e13c398af9f2658ef7050acf3b266f87cfc2f6ab 1) (integer) 0 eval 执行lua脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 eval script numkeys [key [key ...]] [arg [arg ...]] # script为脚本内容，numKeys为参数的个数 # key为脚本中用的键，arg为脚本中的实参 127.0.0.1:6379\u0026gt; eval \u0026#39;return {KEYS[1],ARGV[1]}\u0026#39; 1 name farb 1) \u0026#34;name\u0026#34; 2) \u0026#34;farb\u0026#34; # KEYS 和ARGV是全局变量，是固定写法，区分大小写 127.0.0.1:6379\u0026gt; eval \u0026#39;return KEYS[1],argv[1]\u0026#39; 1 age 18 (error) ERR user_script:1: Script attempted to access nonexistent global variable \u0026#39;argv\u0026#39; script: 33f078271bc288ca9d4c04eab1a00d97877ae05c, on @user_script:1. 127.0.0.1:6379\u0026gt; eval \u0026#39;return KEYS[1],ARGV[1]\u0026#39; 1 age 18 \u0026#34;age\u0026#34; # 如果脚本出现死循环等需要结束脚本的运行，可以执行script kill 127.0.0.1:6379\u0026gt; script kill (error) NOTBUSY No scripts in execution right now. 排序相关命令 可以对列表、集合和有序集合等数据进行升降序排列。\n用sort命令排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 sort key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern ...]] [ASC|DESC] [ALPHA] [STORE destination] # 可以通过asc参数升序排列，通过desc降序排列 127.0.0.1:6379\u0026gt; rpush salary 100 90 200 400 300 (integer) 5 # 原始顺序 127.0.0.1:6379\u0026gt; lrange salary 0 -1 1) \u0026#34;100\u0026#34; 2) \u0026#34;90\u0026#34; 3) \u0026#34;200\u0026#34; 4) \u0026#34;400\u0026#34; 5) \u0026#34;300\u0026#34; # 排序后 127.0.0.1:6379\u0026gt; sort salary desc 1) \u0026#34;400\u0026#34; 2) \u0026#34;300\u0026#34; 3) \u0026#34;200\u0026#34; 4) \u0026#34;100\u0026#34; 5) \u0026#34;90\u0026#34; #对集合进行排序 127.0.0.1:6379\u0026gt; sadd nameSet Peter Tom Mary (integer) 3 127.0.0.1:6379\u0026gt; sort nameSet asc (error) ERR One or more scores can\u0026#39;t be converted into double # 默认是按照数值进行排序的，如果元素是字符串则报错， # 需要使用alpha参数，表示按照字典序排序 127.0.0.1:6379\u0026gt; sort nameSet asc alpha 1) \u0026#34;Mary\u0026#34; 2) \u0026#34;Peter\u0026#34; 3) \u0026#34;Tom\u0026#34; # 有序集合排序同理，即使有分数权重 127.0.0.1:6379\u0026gt; zadd nameZset 1 farb 2 jack 3 ben (integer) 3 127.0.0.1:6379\u0026gt; sort nameZset asc (error) ERR One or more scores can\u0026#39;t be converted into double 127.0.0.1:6379\u0026gt; sort nameZset asc alpha 1) \u0026#34;ben\u0026#34; 2) \u0026#34;farb\u0026#34; 3) \u0026#34;jack\u0026#34; 用by参数指定排序模式 1 2 3 4 5 6 7 8 9 10 11 # by后面可以匹配模式，包括正则表达式或通配符 127.0.0.1:6379\u0026gt; rpush vipLevel vip1 vip3 vip2 (integer) 3 127.0.0.1:6379\u0026gt; lrange vipLevel 0 -1 1) \u0026#34;vip1\u0026#34; 2) \u0026#34;vip3\u0026#34; 3) \u0026#34;vip2\u0026#34; 127.0.0.1:6379\u0026gt; sort vipLevel by vip* 1) \u0026#34;vip1\u0026#34; 2) \u0026#34;vip2\u0026#34; 3) \u0026#34;vip3\u0026#34; 用limit参数返回部分排序结果 1 2 3 4 5 6 7 8 # [LIMIT offset count] # 和mysql中的分页原理一致，offset表示跳过的元素个数，count表示要返回的个数 127.0.0.1:6379\u0026gt; rpush nums 1 9 0 4 8 3 2 7 (integer) 8 127.0.0.1:6379\u0026gt; sort nums limit 0 3 asc 1) \u0026#34;0\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;2\u0026#34; sort命令里get参数的用法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 127.0.0.1:6379\u0026gt; set 2 jack OK 127.0.0.1:6379\u0026gt; set 1 farb OK 127.0.0.1:6379\u0026gt; set 3 ben OK 127.0.0.1:6379\u0026gt; rpush scores 2 3 1 (integer) 3 # sort后面加上get，会把排序结果的值作为键，用每个键再去获取值 # get后面使用*表示所有键，也可以使用其他匹配模式 127.0.0.1:6379\u0026gt; sort scores get * 1) \u0026#34;farb\u0026#34; 2) \u0026#34;jack\u0026#34; 3) \u0026#34;ben\u0026#34; 通过store参数提升性能 1 2 3 4 5 6 7 8 # 通过对数据排序后，将结果缓存到其他key中， # 这样可以避免对相同数据重复排序，从而提升性能 127.0.0.1:6379\u0026gt; sort scores desc store score-desc (integer) 3 127.0.0.1:6379\u0026gt; lrange score-desc 0 -1 1) \u0026#34;3\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;1\u0026#34; ","date":"2024-07-20T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_03_common_used_command/","title":"基于Docker的Redis实战--实践Redis的常用命令"},{"content":"基本数据类型包括字符串（string）类型、哈希(hash)类型、列表(list)类型、集合类型(set)和有序集合(sorted set或zset)类型\n针对字符串的命令 读写字符串的set和get命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 set key value [NX|XX] [GET] [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL] # key和value分别是待设置字符串的键和值，value需要字符串类型。如果key对应的值已经存在，则再次set时会覆盖旧值。 # nx (if not exist)： 如果不存在时再执行 # xx ：如果存在则执行 # get: 获取旧值，如果旧值不存在则返回nil # ex: 过期时间，单位为秒。必须是整数，不能是表达式。 # px: 过期时间，单位为微秒。必须是整数，不能是表达式。 # exat: 在某个unix秒的时间点过期 # pxat: 在某个unix毫秒的时间点过期 # keepttl: 保留key之前旧值的生存时间。 # set之后，可以使用get获取key对应的值。 127.0.0.1:6379\u0026gt; set key val ex 100 OK 127.0.0.1:6379\u0026gt; ttl key (integer) 96 127.0.0.1:6379\u0026gt; set key val1 keepttl OK 127.0.0.1:6379\u0026gt; get key \u0026#34;val1\u0026#34; 127.0.0.1:6379\u0026gt; ttl key (integer) 78 127.0.0.1:6379\u0026gt; 设置和获取多个字符串的命令 1 2 3 4 5 6 7 8 9 10 11 mset key value [key value ...] mget key [key ...] # mset mget不能指定ex,px（ex,px不报错但不生效）,nx,xx等参数（报错）， 127.0.0.1:6379\u0026gt; mset key1 val1 key2 value2 k3 v3 OK 127.0.0.1:6379\u0026gt; mget key1 key2 k3 1) \u0026#34;val1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;v3\u0026#34; 对整数类型的值进行增量和减量操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 增量和减量操作，都需要key对应的值为整数，否则报错。 incr key # 对key对应的值+1，如果key不存在，则默认key对应的值为0 # incrby key increment # 对key对应的值+increment decr key decrby key increment #减量操作 127.0.0.1:6379\u0026gt; incr key (integer) 1 127.0.0.1:6379\u0026gt; incrby key 9 (integer) 10 127.0.0.1:6379\u0026gt; decr key (integer) 9 127.0.0.1:6379\u0026gt; decrby key 2 (integer) 7 127.0.0.1:6379\u0026gt; getset命令获取旧值设置新值 1 2 3 4 5 6 7 8 9 getset key value # 如果key不存在，则返回nil，并设置新值；如果key存在，则返回旧值，并设置新值 127.0.0.1:6379\u0026gt; get key \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; getset key 3 \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; get key \u0026#34;3\u0026#34; 针对字符串的其他操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 getrange key start end # 获取key对应值的子字符串，start和end表示起始位置，start从0开始，end也可以从右向左，最右边的索引为-1 127.0.0.1:6379\u0026gt; set key 029-12345678 OK 127.0.0.1:6379\u0026gt; getrange key 4 11 \u0026#34;12345678\u0026#34; 127.0.0.1:6379\u0026gt; getrange key 4 -1 \u0026#34;12345678\u0026#34; setrange key offset value # 相当于字符串的替换操作，从offset位置开始，把值替换为value 127.0.0.1:6379\u0026gt; setrange key 4 87654321 (integer) 12 127.0.0.1:6379\u0026gt; get key \u0026#34;029-87654321\u0026#34; strlen key # 统计字符串长度的命令 append key value # 将value追加到原值的末尾 127.0.0.1:6379\u0026gt; append key *** (integer) 15 127.0.0.1:6379\u0026gt; get key \u0026#34;029-87654321***\u0026#34; 针对哈希类型变量的命令 设置并获取哈希值 1 2 3 4 5 6 7 8 9 10 11 hset key field value [field value ...] # field 和value可以理解为对象的属性和属性值,返回值为属性的个数 hget key field # hget必须指定key和字段名称 127.0.0.1:6379\u0026gt; hset hkey name farb sex male (integer) 2 127.0.0.1:6379\u0026gt; hget hkey name \u0026#34;farb\u0026#34; 127.0.0.1:6379\u0026gt; hsetnx命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 hsetnx key field value # 当key不存在或者key和field对应value不存在时，设置value，后面只能跟一对key和value 127.0.0.1:6379\u0026gt; hget hkey name \u0026#34;farb\u0026#34; 127.0.0.1:6379\u0026gt; hsetnx hkey name jack (integer) 0 127.0.0.1:6379\u0026gt; hsetnx hkey age 18 (integer) 1 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; hsetnx hNotExistKey name Alice (integer) 1 127.0.0.1:6379\u0026gt; hget hNotExistKey name \u0026#34;Alice\u0026#34; key的相关操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 hkeys key # 查看哈希类型的所有字段field，找不到的话就返回empty array信息 127.0.0.1:6379\u0026gt; hkeys hkey 1) \u0026#34;name\u0026#34; 2) \u0026#34;sex\u0026#34; 3) \u0026#34;age\u0026#34; hvals key # 查看所有field对应的值，找不到的话就返回empty array信息 127.0.0.1:6379\u0026gt; hvals hkey 1) \u0026#34;farb\u0026#34; 2) \u0026#34;male\u0026#34; 3) \u0026#34;18\u0026#34; hgetall key # 以键值对的形式查看key对应的哈希类型数据，找不到的话就返回empty array信息 127.0.0.1:6379\u0026gt; hgetall hkey 1) \u0026#34;name\u0026#34; 2) \u0026#34;farb\u0026#34; 3) \u0026#34;sex\u0026#34; 4) \u0026#34;male\u0026#34; 5) \u0026#34;age\u0026#34; 6) \u0026#34;18\u0026#34; hexists命令判断值是否存在 1 2 3 4 5 6 7 8 9 hexists key field # 判断key和field对应的value是否存在,key不存在也返回0 127.0.0.1:6379\u0026gt; hexists hkey name (integer) 1 127.0.0.1:6379\u0026gt; hexists hkey height (integer) 0 127.0.0.1:6379\u0026gt; hexists nonExists name (integer) 0 哈希类型数据的删除操作 1 2 3 4 5 6 7 8 hdel key field [field ...] # 删除key指定的field数据，可以传入多个字段,返回值删除的字段数 127.0.0.1:6379\u0026gt; hdel hkey sex age (integer) 2 127.0.0.1:6379\u0026gt; hgetall hkey 1) \u0026#34;name\u0026#34; 2) \u0026#34;farb\u0026#34; 针对列表类型变量的命令 读写列表的命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 lpush key element [element ...] # 将元素依次插入到名为key的列表左侧 lindex key index # 从键名为key的列表中从左侧读取第index个元素，下标从0开始 127.0.0.1:6379\u0026gt; lpush mylist 1 2 3 4 (integer) 4 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;4\u0026#34; 2) \u0026#34;3\u0026#34; 3) \u0026#34;2\u0026#34; 4) \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; lindex mylist 1 \u0026#34;3\u0026#34; rpush key element [element ...] # 将元素依次插入到名为key的列表右侧 127.0.0.1:6379\u0026gt; rpush mylist 2 3 4 (integer) 7 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;4\u0026#34; 2) \u0026#34;3\u0026#34; 3) \u0026#34;2\u0026#34; 4) \u0026#34;1\u0026#34; 5) \u0026#34;2\u0026#34; 6) \u0026#34;3\u0026#34; 7) \u0026#34;4\u0026#34; 127.0.0.1:6379\u0026gt; lpushx 和rpushx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 lpushx key element [element ...] # 当key存在时，在key对应的列表左侧添加元素 127.0.0.1:6379\u0026gt; lpushx mylist 5 6 (integer) 9 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;6\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;4\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;2\u0026#34; 6) \u0026#34;1\u0026#34; 7) \u0026#34;2\u0026#34; 8) \u0026#34;3\u0026#34; 9) \u0026#34;4\u0026#34; rpushx key element [element ...] # 当key存在时，在key对应的列表右侧添加元素 127.0.0.1:6379\u0026gt; rpushx mylist 5 6 (integer) 11 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;6\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;4\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;2\u0026#34; 6) \u0026#34;1\u0026#34; 7) \u0026#34;2\u0026#34; 8) \u0026#34;3\u0026#34; 9) \u0026#34;4\u0026#34; 10) \u0026#34;5\u0026#34; 11) \u0026#34;6\u0026#34; 用list模拟堆栈和队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 栈：后进先出，所以可以使用lpush、lpop命令或者rpush、rpop命令模拟栈 127.0.0.1:6379\u0026gt; lpush stack1 1 2 (integer) 2 127.0.0.1:6379\u0026gt; lrange stack1 0 -1 1) \u0026#34;2\u0026#34; 2) \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; lpop stack1 \u0026#34;2\u0026#34; # 队列：先进先出，所以可以使用lpush、rpop或者rpush、lpop命令来模拟队列 127.0.0.1:6379\u0026gt; rpush queue 1 2 (integer) 2 127.0.0.1:6379\u0026gt; lpop queue \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; 用lrange获取指定区间内的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 lrange key start stop # key为list键名，start为起始位置，从0开始，stop为结束位置，最后一个元素可以为-1 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;6\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;4\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;2\u0026#34; 6) \u0026#34;1\u0026#34; 7) \u0026#34;2\u0026#34; 8) \u0026#34;3\u0026#34; 9) \u0026#34;4\u0026#34; 10) \u0026#34;5\u0026#34; 11) \u0026#34;6\u0026#34; 127.0.0.1:6379\u0026gt; lrange mylist 1 3 1) \u0026#34;5\u0026#34; 2) \u0026#34;4\u0026#34; 3) \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; 用lset修改列表数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 lset key index element # 将名为key的列表的第index个元素修改为element 127.0.0.1:6379\u0026gt; lset mylist 0 7 OK 127.0.0.1:6379\u0026gt; lset mylist -1 7 OK 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;7\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;4\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;2\u0026#34; 6) \u0026#34;1\u0026#34; 7) \u0026#34;2\u0026#34; 8) \u0026#34;3\u0026#34; 9) \u0026#34;4\u0026#34; 10) \u0026#34;5\u0026#34; 11) \u0026#34;7\u0026#34; 删除列表数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 rpop key [count] # 从右边弹出count个元素 lpop key [count] # 从左边弹出count个元素 lrem key count element # 当count=0时，删除该列表中所有值是element的元素； # 当count\u0026gt;0时，从左到右删除数量为count个、值是element的元素； # 当count\u0026lt;0时，从右往左删除数量为count个、值是element的元素； 127.0.0.1:6379\u0026gt; lpop mylist \u0026#34;7\u0026#34; 127.0.0.1:6379\u0026gt; rpop mylist \u0026#34;7\u0026#34; 127.0.0.1:6379\u0026gt; lrem mylist 0 5 (integer) 2 127.0.0.1:6379\u0026gt; lrange mylist 0 -1 1) \u0026#34;4\u0026#34; 2) \u0026#34;3\u0026#34; 3) \u0026#34;2\u0026#34; 4) \u0026#34;1\u0026#34; 5) \u0026#34;2\u0026#34; 6) \u0026#34;3\u0026#34; 7) \u0026#34;4\u0026#34; 针对集合的命令 读写集合 1 2 3 4 5 6 7 8 9 10 11 sadd key member [member ...] # 给名为key的集合中添加元素，元素会自动去重 smembers key # 读取集合key中的所有元素 127.0.0.1:6379\u0026gt; sadd myset 1 2 2 3 (integer) 3 127.0.0.1:6379\u0026gt; smembers myset 1) \u0026#34;1\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;3\u0026#34; 列表和集合类数据的区别 列表存储数据时具有有序性，要么从左侧push，要么从右侧push。而集合不具有有序性。 列表存储的数据可以存在重复元素，而集合会自动去重。 用sismember判断元素是否存在 1 2 3 4 5 6 7 sismember key member # 判断集合key中是否存在member,存在返回1，不存在返回0 127.0.0.1:6379\u0026gt; sismember myset 2 (integer) 1 127.0.0.1:6379\u0026gt; sismember myset 4 (integer) 0 获取集合的交集、并集和差集 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sinter key [key ...] # 获取多个key对应集合的交集 127.0.0.1:6379\u0026gt; sadd myset2 2 3 4 (integer) 3 127.0.0.1:6379\u0026gt; sinter myset myset2 1) \u0026#34;2\u0026#34; 2) \u0026#34;3\u0026#34; sunion key [key ...] # 获取多个集合对应的并集 127.0.0.1:6379\u0026gt; sunion myset myset2 1) \u0026#34;1\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;3\u0026#34; 4) \u0026#34;4\u0026#34; sdiff key [key ...] # 获取多个key对应的差集 127.0.0.1:6379\u0026gt; sdiff myset myset2 1) \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; sdiff myset2 myset 1) \u0026#34;4\u0026#34; 用srem命令删除集合数据 1 2 3 4 5 srem key member [member ...] # 删除集合key中的元素，并返回删除的元素个数 127.0.0.1:6379\u0026gt; srem myset 1 (integer) 1 有序集合的命令 有序集合的读写 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 zadd key [NX|XX] [GT|LT] [CH] [INCR] score member [score member ...] # 给名为key的集合添加分数和元素 # NX 有序集合中的元素不存在时才添加 # XX 有序集合中的元素存在时添加 # GT 当元素存在，且当分数大于旧分数时执行，不阻止添加元素。 # LT 当元素存在，且当分数小于旧分数时执行，不阻止添加元素。 # CH 修改返回的值为添加的元素数量+修改分数的元素数量（分数相同的时不更新） # INCR 给分数添加，使用此参数时，只能添加一个元素 # score 分数或权重 # member 元素 zrange key start stop [BYSCORE|BYLEX] [REV] [LIMIT offset count] [WITHSCORES] # 读取名为key的有序集合中score排名区间在start到stop之间的数据 # ByScore 按分数范围查询 # Rev 是否反序 # Limit offset count 和mysql的分页查询一样 # withScores 返回分数 127.0.0.1:6379\u0026gt; zadd sortedSet 6 farb (integer) 1 127.0.0.1:6379\u0026gt; zadd sortedSet GT 5 farb (integer) 0 127.0.0.1:6379\u0026gt; zadd sortedSet GT 8 farb (integer) 0 127.0.0.1:6379\u0026gt; zrange sortedSet -1 100 1) \u0026#34;farb\u0026#34; 127.0.0.1:6379\u0026gt; zrange sortedSet -1 100 WITHScores 1) \u0026#34;farb\u0026#34; 2) \u0026#34;8\u0026#34; 127.0.0.1:6379\u0026gt; zadd sortedSet GT 2 jack 3 lucy (integer) 2 127.0.0.1:6379\u0026gt; zrange sortedSet 0 100 REV WITHSCORES 1) \u0026#34;farb\u0026#34; 2) \u0026#34;8\u0026#34; 3) \u0026#34;lucy\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;jack\u0026#34; 6) \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; zrange sortedSet 0 100 byscore 1) \u0026#34;jack\u0026#34; 2) \u0026#34;lucy\u0026#34; 3) \u0026#34;farb\u0026#34; 127.0.0.1:6379\u0026gt; zrange sortedSet 0 100 byscore withScores 1) \u0026#34;jack\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;lucy\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;farb\u0026#34; 6) \u0026#34;8\u0026#34; zincrby修改元素的分数 1 2 3 4 5 zincrby key increment member # 给名为key的有序集合中的member元素增加分数increment,返回值是最终分数 127.0.0.1:6379\u0026gt; zincrby sortedSet 10 farb \u0026#34;18\u0026#34; zscore 获取指定元素的分数 1 2 3 4 5 zscore key member # 只能返回一个元素的分数，否则报错 127.0.0.1:6379\u0026gt; zscore sortedSet farb \u0026#34;18\u0026#34; zrank查看有序集合中的排名 1 2 3 4 5 6 7 8 9 10 11 12 13 14 zrank key member [WITHSCORE] # 正序排名，索引从0开始 zrevrank key member [WITHSCORE] # 倒序排名 127.0.0.1:6379\u0026gt; zrank sortedSet jack withScore 1) (integer) 0 2) \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; zrank sortedSet farb withScore 1) (integer) 2 2) \u0026#34;18\u0026#34; 127.0.0.1:6379\u0026gt; zrevrank sortedSet farb WithScore 1) (integer) 0 2) \u0026#34;18\u0026#34; 删除有序集合中的值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 zrem key member [member ...] # 一次允许删除多个元素 127.0.0.1:6379\u0026gt; zrem sortedSet jack lucy (integer) 2 127.0.0.1:6379\u0026gt; zrange sortedSet 0 100 1) \u0026#34;farb\u0026#34; zremrangebyrank key start stop # 删除排名在start和stop之间的元素 127.0.0.1:6379\u0026gt; zadd myzset 1 one 2 two 3 three 4 four (integer) 4 127.0.0.1:6379\u0026gt; zrange myzset 1 4 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34; 3) \u0026#34;four\u0026#34; 127.0.0.1:6379\u0026gt; zrange myzset 0 4 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; 4) \u0026#34;four\u0026#34; 127.0.0.1:6379\u0026gt; zrange myzset 0 3 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; 4) \u0026#34;four\u0026#34; 127.0.0.1:6379\u0026gt; zremrangebyrank myzset 0 2 (integer) 3 127.0.0.1:6379\u0026gt; zrange myzset 0 3 1) \u0026#34;four\u0026#34; zremrangebyscore key min max # 删除分数在min和max之间的元素 127.0.0.1:6379\u0026gt; zrange myzset 0 100 withScores 1) \u0026#34;one\u0026#34; 2) \u0026#34;1.5\u0026#34; 3) \u0026#34;two\u0026#34; 4) \u0026#34;2.6\u0026#34; 5) \u0026#34;three\u0026#34; 6) \u0026#34;3.7\u0026#34; 7) \u0026#34;four\u0026#34; 8) \u0026#34;4.8\u0026#34; 127.0.0.1:6379\u0026gt; zremrangebyscore myzset 2 4 (integer) 2 127.0.0.1:6379\u0026gt; zrange myzset 0 100 withScores 1) \u0026#34;one\u0026#34; 2) \u0026#34;1.5\u0026#34; 3) \u0026#34;four\u0026#34; 4) \u0026#34;4.8\u0026#34; ","date":"2024-07-13T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_02_basic_type/","title":"基于Docker的Redis实战--实践Redis的基本数据类型"},{"content":"下载Docker desktop，配置可用镜像地址。\ndocker 镜像可用地址： https://www.aabcc.top/archives/m7NPfx1D\nRedis客户端AnotherRedisDesktopManager： https://gitee.com/qishibo/AnotherRedisDesktopManager/releases\n必要的docker技能 docker镜像相关的命令 1 2 3 4 5 6 7 8 # 查看本机所有镜像 docker images # 拉取镜像,imageName为镜像名，比如ubuntu,tag为标签，如果没有指定，默认为latest docker pull imageName:tag # 删除本地镜像,可指定镜像名和标签，也可以指定镜像Id docker rmi [imageName:tag | imageId] docker容器相关的命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #基于镜像创建容器并运行容器 # -it 表示终端交互式操作 （interactive terminal） # ubuntu:latest指定待运行的镜像 # /bin/bash 表示容器启动后要执行的命令 docker run -it ubuntu:latest /bin/bash # 查看运行中的容器 docker ps # 查看所有的容器 docker ps -a # 停止容器 docker stop containterId # 启动容器 docker start containerName # 删除容器,删除容器前必须停止容器，否则报错 docker rm containerId # 容器重命名(docker run之后，如果不指定--name参数，则会随机生成一个容器名) docker rename oldName newName # 进入容器后，通过第一次exit可以退出容器 安装和配置基于docker的Redis环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # 下载最新redis镜像 docker pull redis:latest # 查看镜像 docker images # 启动redis容器 # -it表示终端交互式操作，d表示后台运行 # --name 指定容器名称 # -p 指定容器的6379端口映射到宿主机（运行docker的机器）6379端口 # redis:latest 为启动容器的镜像 docker run -itd --name firstRedis -p 6379:6379 redis:latest # 查看容器日志 docker logs firstRedis # 进入容器 # docker exec 表示在运行的容器中执行命令 # -it 表示以交互式终端执行命令 # firstRedis为容器名 # /bin/bash 为需要执行的命令 docker exec -it firstRedis /bin/bash # 通过redis-cli命令进入redis客户端，可以执行set ,get命令 # 通过两次exit可以退出到windows命令行。第一次exit是退出redis-cli客户端到容器内部，第二次exit是退出容器。 # 停止容器，可以通过docker ps -a 对比容器前后状态 docker stop firstRedis # 启动容器 docker start firstRedis # 重启容器 docker restart firstRedis ## start和restart的区别是：start会挂载容器所关联的文件系统，restart不会。如果更改了redis启动时需要加载的配置项参数，那么重启时需要先stop，再start。 # 查看redis版本 docker start firstRedis docker exec -it firstRedis /bin/bash # 查看redis客户端版本 redis-cli --version # 查看reis服务端版本 redis-server --version # 如果要停止redis服务，可以通过exit退出容器，也可以通过redis-cli的shutdown命令关闭服务。 ","date":"2024-07-13T00:00:00Z","permalink":"https://farb.github.io/p/redis_in_action_01_build_env/","title":"基于Docker的Redis实战--构建Redis开发环境"},{"content":" 文章很长，要有耐心，没耐心的等有耐心了再看，保证有所收获。要想成为某个领域的大师，只有一个秘诀：无他，唯手熟尔。所以一定要多练。\n目录 构建Redis开发环境 实践Redis的基本数据类型 实践Redis的常用命令 ","date":"2024-06-20T00:00:00Z","permalink":"https://farb.github.io/p/docker-redis-study/","title":"基于Docker的Redis实战"},{"content":"需求描述 显示一个字符串，后面紧跟着一个图标。 当字符串较短时，正常显示文本，当字符串较长（超过屏幕宽度减去图片宽度和元素的间距总和）时，显示跑马灯效果。\n代码展示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Entry @Component struct MarqueeDemo { @State text: string = \u0026#39;这是一个短字符串\u0026#39; @State isShowMarquee: boolean = false build() { Column() { Row() { if (this.isShowMarquee) { Marquee({ start: true, src: this.text }) .width(300) } else { Text(this.text) .fontSize(14) .onAreaChange((oldValue, newValue) =\u0026gt; { // oldValue为区域变化之前的值 // newValue为区域变化之后的值 // newValue.width为变化之后的实际占位虚拟像素 if (newValue.width \u0026gt; 280) { this.isShowMarquee = true } } ).margin({ left: 10 }) } Image($r(\u0026#39;app.media.product\u0026#39;)) .width(20) .margin(10) } Button(\u0026#39;切换字符串长度\u0026#39;) .onClick(() =\u0026gt; { this.text = \u0026#39;这是一个很长的字符串，目的是为了测试跑马灯效果\u0026#39; }) } .width(\u0026#39;100%\u0026#39;) } } 效果呈现 ","date":"2024-05-15T00:00:00Z","permalink":"https://farb.github.io/p/harmony-ui-marquee/","title":"鸿蒙界面开发--跑马灯综合问题"},{"content":"Redis 使用场景及常见面试题 缓存穿透及应对措施 缓存穿透： 查询一个缓存中不存在的数据，并且数据库中也查询不到，从而无法写入缓存，导致每次查询都直接请求到数据库，给数据库造成巨大压力，这种情况大概率遭到了攻击。\n解决方案一： 对不存在的key缓存一个空数据，缺点是会导致内存不断增大。\n解决方案二： 使用布隆过滤器，在查询缓存之前先去布隆过滤器中查询一遍。\n关于布隆过滤器，查看这篇文章，讲解的很细。 布隆(Bloom Filter)过滤器——全面讲解，建议收藏\n缓存击穿及应对措施 缓存击穿： 对于一个设置了过期时间的热点key,恰好在某个时间点过期，且大量并发请求同时访问这个key，于是所有请求直接访问数据库，可能会瞬间把DB压垮。\n解决方案1： 互斥锁。当缓存失效时，不立即访问db,先使用redis的setnx设置一个互斥锁，当操作成功返回时再进行db操作并写入缓存，否则重试get缓存的方法。\n解决方案2： 设置当前key逻辑过期。 大致思路：\n在设置key的时候，设置一个过期时间字段一起存入缓存中，不给当前key设置过期时间。 当查询的时候，从redis中取出数据后判断添加的过期时间字段是否过期。 如果过期，则启动新的线程进行数据同步，当前线程正常返回数据，但这个数据可能不是最新的。 两种方案各有利弊。如果选择数据的强一致性，建议使用互斥锁的方案，性能上可能不高，因为锁需要等待，也有可能产生死锁的问题。\n如果优先考虑高可用性，性能比较高，建议选择给key添加逻辑过期时间，但是数据同步做不到强一致性。\n缓存雪崩及应对措施 缓存雪崩： 在同一时间段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。\n解决方案：\n给不同的key设置随机过期时间 利用redis集群提高服务的可用性（哨兵和集群模式） 给缓存业务添加降级限流策略（降级可作为系统的保底策略，适用于穿透、击穿和雪崩） 给业务添加多级缓存 （Guava和Caffeine） 如何对数据库的数据和缓存的数据进行同步？（读写一致性） 主要分为延时一致性和强一致性的同步。\n延时一致性的业务场景： 比如发表文章、发布商品的场景，不需要实时性很高，像这些场景的业务就可以采用延时一致的解决方案。\n强一致性的业务场景： 比如抢券、秒杀的场景，实时性要求非常高，需要知道是否有券或者商品剩余，这些实时性非常高的场景可以使用强一致性的同步方案。\n允许延时一致的业务采用的异步通知\n使用MQ中间件，更新数据后，再更新缓存 使用Canal中间件，不需要修改业务代码，伪装为mysql的一个从节点，canal通过读取binlog数据更新缓存 强一致性的业务使用Redisson的读写锁进行同步\n共享锁： 获取读锁ReadLock,加锁之后，其他线程可以共享读操作 排他锁： 也叫独占锁WriteLock,加锁之后，阻塞其他线程读写操作。 通过使用排他锁，就可以保证在写数据的时候不会让其他线程读取数据，避免了脏数据。需要注意的是，获取读写锁的读方法和写方法需要使用同一把锁。 延时双删 如果是写操作，我们先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据，其中这个延时多久不太好确定（数据库主节点同步到从节点的时间不确定多久），在延时的过程中可能出现脏数据（如果延时的时间小于数据同步的时间，那么读取的数据可能是旧数据），并不能保证强一致性。\nRedis的持久化 Redis中有两种持久化方式：RDB和AOF。\nRDB（Redis Database Backup file）是一个快照文件，它是把Redis内存中存储的数据保存到磁盘上，方便从RDB的快照文件中恢复数据。\n1 2 3 4 5 6 7 8 redis-cli save # 由redis主进程执行rdb，会阻塞所有命令 bgsave # 开启子进程执行rdb,避免主进程受影响 # x秒内，如果至少有y个key被修改，则执行bgsave save 900 1 save 300 10 save 60 10000 AOF（Append Only File）是追加文件，当redis操作写命令的时候，都会存储在这个文件中。当需要恢复数据时，重新执行该文件的命令即可恢复数据。\n修改redis.config 文件来修改配置\n1 2 3 4 5 6 7 8 9 10 11 12 # AOF 默认是关闭的，默认是no,开启需要设置为yes appendonly yes # AOF文件的名称 appendfilename \u0026#34;appendonly.aof\u0026#34; # 每执行一次写命令，立即记录到aof文件 appendfsync always # 写命令执行完先放入aof缓冲区，每隔一秒将缓冲区的数据写到aof文件，是默认方案 appendfsync everysec # 写命令执行完先放入aof缓冲区，由操作系统决定何时将缓冲区内容写入磁盘 appendfsync no 配置项 刷盘时机 优点 缺点 always 同步刷盘 可靠性高，几乎不丢数据 性能影响大 everysec 每秒刷盘 性能适中 最多丢失1秒数据 no 操作系统控制 性能最好 可靠性较差，可能丢失大量数据 bgrewriteaof命令对aof文件执行重写，用最少的命令达到相同效果\n1 2 3 4 5 # AOF 文件比上次文件增长超过多少百分比则触发重写 auto-aof-rewrite-percentage 100 # AOF文件体积最小多大以上才触发重写 auto-aof-rewrite-min-size 64mb RDB AOF 持久化方式 定时对整个内存做快照 记录每次执行的命令 数据完整性 不完整，两次备份之间会丢失 相对完整，取决于刷盘策略 文件大小 会有压缩，文件体积小 记录命令，文件体积很大 宕机恢复速度 很快 慢 数据恢复优先级 低，因为数据完整性不如AOF 高，因为数据完整性更高 系统资源占用 高，大量CPU和内存消耗 低，主要是IO磁盘资源，但AOF重写时会占用大量CPU和内存 使用场景 可以容忍数分钟的数据丢失，追求更快的启动速度 对数据安全性要求较高 这两种存储方式，哪种恢复的更快呢\nRDB是二进制文件，在保存的时候体积也是比较小的，它恢复的较快，但是它有可能会丢失数据，通常也会使用AOF恢复数据，虽然AOF的恢复速度慢，但是它丢失的数据风险较小，在AOF文件中可以设置刷盘策略，使用较多的是每秒批量写入一次命令。\nRedis的数据过期策略 惰性删除： key的过期时间到期后，不会自动删除，而是当再次查询时，先检查key是否过期，如果过期则删除，否则直接返回该key\n定期清理： 每隔一段时间，对一些key进行检查，删除过期的key。定期清理有两种模式：\nslow模式是定时任务，执行频率默认为10hz,每次不超过25ms,通过修改redis.conf的hz选项调整次数。 fast模式执行频率不固定，每次事件循环会尝试执行，但每次间隔不低于2ms,每次耗时不超过1ms。 Redis的过期删除策略，是惰性删除和定期删除两种策略配合使用。 Redis的数据淘汰策略 数据的淘汰策略： 当Redis的内存不够用时，再向redis中添加新的key时，那么redis就会按照某种规则将内存中的数据删除掉，这种规则称为内存的淘汰策略。\nnoeviction: 不淘汰任何key，但是内存满时不允许写入任何数据，直接报错，这是默认策略。 volatile-ttl: 对设置了ttl（Time to live 存活时间）的key，比较key的剩余ttl值，ttl越小越先被淘汰。 allkeys-random: 全体key随机进行淘汰 volatile-random: 对设置了ttl的key，随机进行淘汰 allkeys-lru: 对全体key，按照lru算法淘汰 volatile-lru: 对设置了ttl的key按照lru算法淘汰 allkeys-lfu: 对所有key按照lfu算法淘汰 volatile-lfu: 对设置了ttl的key,按照lfu算法淘汰 1 2 3 4 5 # redis.conf中设置 maxmemory-policy allkeys-lru # redis实例动态设置 CONFIG SET maxmemory-policy allkeys-lru LRU（Least Recently Used）算法 ：最近最少使用。用当前时间减去最后一次访问时间，这个值越大淘汰优先级越高。\nLFU（Least Frequently Used）算法 : 最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。\n使用建议：\n优先使用allkeys-lru淘汰策略。充分利用LRU算法的优势，把最常访问的数据保留在缓存中，如果业务有明显的冷热数据区分，建议使用。 如果业务中数据访问频率差别不大，没有明显的冷热数据区分，建议使用随机淘汰策略allkeys-random。 如果业务中有置顶的需求，可以使用volatile-lru策略，同时置顶数据不要设置过期时间，那么这些数据就会一直不被删除，会淘汰其他设置过期时间的数据。 如果业务中有短时高频访问的数据，建议使用allkeys-lfu或volatile-lfu策略。 问：数据库中有1000w数据，Redis只能缓存20w数据，如何保证redis中的数据都是热点数据？\n答：使用allkeys-lru（最近最少访问的数据优先淘汰）淘汰策略，留下来的都是经常访问的热点数据。\n问：Redis的内存使用完了会发生什么？\n答：主要看设置的数据淘汰策略是什么，如果是默认的noevction,内存满后继续添加key会报错。其他的策略都会淘汰某些key后，继续写入。\n分布式锁 分布式锁一般是多个进程同步数据时加的锁，而平时代码中的写的lock，是同一个进程下多个线程同步时加的锁。\n通常情况下，使用分布式锁的场景有：集群情况下的定时任务、抢券、幂等性场景\nRedis分布式锁主要利用Redis的setnx命令，setnx是SET if not exist的简写。\n1 2 3 4 5 # 获取锁,NX是互斥，EX是设置超时,EX必须设置，否则可能因为业务超时或服务宕机等原因而无法释放锁。添加超时时间后，到期会自动释放锁 SET lock value NX EX 10 # 释放锁，删除即可 DEL key 问：Redis分布式锁如何合理地控制锁的有效时长？\n答：1.根据业务执行时间预估（不靠谱）；2.给锁续期\nRedisson分布式锁的看门狗（Watch Dog）机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public void redisLock() { // 获取锁（可重入锁） RLock lock=redissonClient.getLock(\u0026#34;lockKey\u0026#34;); // 尝试获取锁，参数含义分别是获取锁的最大等待时间（期间会重试），锁自动释放时间(默认30)，时间单位 // boolean isLock=lock.tryLock(10,30,TimeUnit.SECONDS); // 加锁、设置过期时间等操作都是通过lua脚本完成 boolean isLock=lock.tryLock(10,TimeUnit.SECONDS); if (isLock) { try{ System.out.println(\u0026#34;获取锁成功\u0026#34;); }finally{ // 释放锁 lock.unlock(); } } } lua学习教程 https://www.runoob.com/lua/lua-tutorial.html\nredisson的分布式锁是可重入的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public void add1(){ RLock lock=redissonClient.getLock(\u0026#34;locker\u0026#34;); boolean isLcok=lock.tryLock(); // 执行业务 add2(); // 释放锁 lock.unlock(); } public void add2(){ RLock lock=redissonClient.getLock(\u0026#34;locker\u0026#34;); // 如果是同一个线程，则可以获取锁，否则互斥 boolean isLcok=lock.tryLock(); // 执行业务 // 释放锁 lock.unlock(); } 通过哈希结构区分锁的不同线程访问记录。field保存线程唯一标识，value保存重入次数。\nredisson分布式锁的主从一致性 在哨兵模式等主从同步模式中，如果主节点Master没有成功同步数据到从节点Slave时，有一个请求线程获取了一个锁，与此同时，Master主节点宕机了，然后会从一个从节点Salve中选举一个主节点，又一个请求线程获取了同一个锁。这种场景就会导致多个线程获取同一把锁，失去了锁的意义，可能或导致脏数据。\nRedLock(红锁)： 不能只在一个redis实例上创建锁，而应该在多个（n/2+1）实例上创建锁，（n/2+1）表示至少一半的实例。\n官方不建议使用红锁解决主从不一致问题。因为实现复杂，且高并发下性能差，运维繁琐。\n那如何解决这一问题呢？ Redis是AP思想（高可用），应该使用CP思想的Zookeeper。\n分布式锁FAQ 问：Redis分布式锁如何实现？ 答：在redis中提供了一个命令setnx(set if not exists)，由于redis是单线程的，用来命令之后，只能有一个客户端对某个key设置值，在没有过期或者删除key时，其他客户端是不能设置这个key的。\n问：如何控制redis分布式锁的有效时长呢？\n答：redis的setnx指令不好控制这个问题，可以采用redisson框架实现。在redisson中可以手动加锁，并且可以控制锁的失效时间和等待时间，当锁住的业务还没执行完毕时，redisson中引入了看门狗机制，就是说每隔一段时间就检查当前业务是否持有锁，如果持有锁就增加锁的持有时间，当业务执行完成后释放锁就可以了。还有一个好处是，在高并发场景下，如果客户1获取了锁，客户2来了后并不会马上拒绝，它会不断尝试获取锁，如果客户1释放锁之后，客户2会马上持有锁，性能也得到了提升。\n问：redisson的分布式锁是可以重入的吗？\n答：是可重入的。这样做是为了避免死锁的发生。这个重入其实在内部就是判断是否是当前线程持有的锁，如果是就会计数器加1，如果释放锁就会减1。在存储数据的时候采用的是hash结构，大key可以按照业务进行定制，小key是线程的唯一标识，value是当前线程的重入次数。\n问： redisson的分布式锁能解决主从一致性的问题吗？\n答： 不能。比如，当线程1加锁成功后，master节点数据会异步复制到从节点slave，此时当前持有redis锁的master节点宕机，slave节点被提升为新的master节点，之前的master节点变成slave节点，假如现在又来了一个线程2，两个线程持有同一把锁，执行业务可能导致脏数据问题。其实Redis采用的是高并发思想（AP），可以考虑使用强一致性思想的Zookeeper（CP）。\nRedis集群方案 主从复制 单节点的Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。一般是一主多从，主节点负责写，从节点负责读。主节点将数据同步到从节点。 全量同步原理：\n从节点请求主节点同步数据（replicationId,offset） 主节点判断是否是第一次请求，是第一次请求就与从节点同步版本信息（replicationId和offset） 主节点执行bgsave,生成rdb文件后，发送给从节点执行 在rdb生成执行期间，主节点会以命令的方式记录到缓冲区（一个日志文件repl_baklog） 把生成的命令日志文件发送到从节点执行，从而完成全量数据同步 增量同步原理：\n从节点从主节点请求同步数据，主节点判断不是第一次请求，不是第一次请求就获取从节点的offset值 主节点从命令日志文件中获取offset值之后的数据，发送到从节点进行数据同步 哨兵模式 Redis提供了哨兵Sentinel机制来实现主从集群的自动故障恢复。 哨兵的作用：\n监控：Sentinel会不断检查Master和Slave是否按预期工作； 自动故障恢复：如果master故障，Sentinel会自动将一个slave提升为master，当故障实例恢复后以新的master为主； 通知：Sentinel充当redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis客户端。 这样，通过哨兵模式就可以实现redis的高并发高可用。\n服务状态监控 Sentinel基于心跳机制监测服务状态，每隔1s向集群的实例发送ping命令：\n主观下线： 如果某个Sentinel节点发现某个实例在规定时间内没有响应，则认为该实例主观下线； 客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过sentinel实例数量的一半 哨兵选主规则：\n首先判断主节点与从节点的断开时间长短，如果超过指定值就排除该从节点； 然后判断从节点的slave-priority的值，越小优先级越高； 如果slave-priority的值一样，则判断slave节点的offset值，越大说明从主节点同步的数据越多，优先级也就越高； 最后时判断slave节点的运行id大小，越小优先级越高 Redis集群（哨兵模式）脑裂问题 集群脑裂redis的主节点、从节点和哨兵集群Sentinel处于不同的网络分区，使得sentinel没有能够检测到主节点的心跳，所以就通过选举的方式提升一个从节点作为主节点，这样就存在了两个主节点master，就像大脑裂开了一样，这样会导致客户端还在老的主节点那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会将老的主节点降级为从节点，这时再从新的master同步数据，就会导致数据丢失。\n解决办法： Redis中有两个配置参数：\nmin-replicas-to-write 1 表示最少的slave节点为1个 min-replicas-max-lag 5 表示数据复制和同步的延迟不能超过5秒 达不到这两个要求的就拒绝请求，可以避免大量数据丢失。\n一般规模的应用使用一主一从+哨兵就可以了，单节点不超过10GB内存，如果Redis内存不足则可以给不同的服务分配独立的Redis主从节点。\n分片集群 ","date":"2024-05-02T00:00:00Z","permalink":"https://farb.github.io/p/redis-study/","title":"Redis系统学习"},{"content":"1. Git rebase 和 Git merge git merge相比git rebase使用更简单，网上对于这两种git工作流的看法也是两个流派。 有人喜欢merge , 有人喜欢rebase。聪明的人不会做偏执狂，团队中让用哪种，咱就用那种就对了，都了解一下没啥坏处。\n在宏观上，git rebase生成的线条和节点更简单清晰，git merge因为会自动合并，当团队成员较多时，产生的线条和节点不太清晰。 微观上，git rebase会创建提交的副本让提交历史更加线性化，git merge会创建自动合并的提交。\n点击下面的链接详细了解两种工作流。\nhttps://www.cnblogs.com/FraserYu/p/11192840.html\nhttps://zhuanlan.zhihu.com/p/686538265\n这里推荐一个动画学习git的网站：https://learngitbranching.js.org/?locale=zh_CN\n2. Git rebase 命令行 1 2 3 4 5 6 7 8 9 10 11 12 13 git remote -v # 查看远程仓库，如果没有origin仓库需要加一下 git remote add upstream remoteUrl # 将远程仓库加到上游 git remote -v # 再次查看远程仓库 git branch -r # 查看远程仓库的分支 # 以下几个命令需要经常使用 git remote update upstream # 更新上游仓库origin代码 git rebase upstream/master # rebase上游仓库master分支的代码到当前分支 # 如果有冲突，需要解决，解决之后git rebase --continue ,然后再推送 # 必须强制推送，因为本地合并的代码已经是确定要保留的代码，如果没有强制推送，则会提示先pull，如果真的pull的话，会导致代码混乱 git push -f ","date":"2024-04-25T00:00:00Z","permalink":"https://farb.github.io/p/git_rebase/","title":"Git rebase 命令行操作"},{"content":"1. 使用svg图片填充颜色fillColor时，不生效 原因可能是其他网站上的svg格式和华为提供的格式有区别。解决方案如下：\n2. Text的子组件Span使用时注意点 Text和Span都有内容时，Text的内容会被Span覆盖 Text的赋予属性（如字体大小和颜色）时，Span会继承，如果Span有一个属性重新赋值，则其他属性也不会继承。 ","date":"2024-04-22T00:00:00Z","permalink":"https://farb.github.io/p/harmony-faq/","title":"鸿蒙界面开发--常见问题"},{"content":"实验经历 之前集成了utterance，但是它必须登录才能发布评论，而且博客发布到国内的gitee上的话，无法展示。所以今天换成了Waline。\nWaline官网\n参考文档 https://waline.js.org/guide/get-started/\n跟着Waline官方这个文档一步步来，就可以。主要思想就是部署一个数据库和nodejs的服务端。数据库部署在LeanCloud,服务端部署在Vercel上。 需要注意的是，Vercel上部署的应用，需要绑定自己的域名才可以，据说是DNS污染，因此买了个域名farb.top。\nHugo Stack中如何配置 找到配置文件： config_default\\params.toml 修改评论系统的provider以及[comments.waline]节点下的serverURL为你自己的后端服务地址。代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 ## Comments [comments] enabled = true provider = \u0026#34;waline\u0026#34; ## 修改点 [comments.waline] serverURL = \u0026#34;https://blog.comment.farb.top\u0026#34; ## 修改点 lang = \u0026#34;zh-cn\u0026#34; ## 修改点 visitor = \u0026#34;\u0026#34; avatar = \u0026#34;\u0026#34; emoji = [\u0026#34;https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo\u0026#34;] requiredMeta = [\u0026#34;name\u0026#34;, \u0026#34;email\u0026#34;] placeholder = \u0026#34;\u0026#34; 效果展示 ","date":"2024-04-21T00:00:00Z","permalink":"https://farb.github.io/p/hugo_stack_waline/","title":"Hugo+Stack主题快速集成评论系统Waline"},{"content":"开源贡献列表 项目名称 MR链接 Magicodes.IE https://github.com/dotnetcore/Magicodes.IE/pull/551 WeLinkEmoji(华为内源) https://www.openx.com/WeLinkEmoji HandyControl https://github.com/HandyOrg/HandyControl/pull/1434 ","date":"2024-04-21T00:00:00Z","permalink":"https://farb.github.io/p/hugo_stack_open_source/","title":"开源贡献"},{"content":"参考博客 大神博客底部js: https://icloudnative.io/\n网站引入js 将js添加到文件layouts\\partials\\footer\\custom.html中。 原理就是计算当前时间-博客的生日，然后将计算结果渲染到对应的标签中。函数每隔1s执行一次。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;script defer language=\u0026#34;javascript\u0026#34;\u0026gt; var uptime_1 = \u0026#34;本站已经开心运行 \u0026#34;; var uptime_2 = \u0026#34; 天 \u0026#34;; var uptime_3 = \u0026#34; 小时 \u0026#34;; var uptime_4 = \u0026#34; 分 \u0026#34;; var uptime_5 = \u0026#34; 秒\u0026#34;; function show_date_time() { window.setTimeout(show_date_time, 1e3); BirthDay = new Date(\u0026#34;8/4/2024 22:54:23\u0026#34;); today = new Date(); timeold = today.getTime() - BirthDay.getTime(); sectimeold = timeold / 1e3; secondsold = Math.floor(sectimeold); msPerDay = 24 * 60 * 60 * 1e3; e_daysold = timeold / msPerDay; daysold = Math.floor(e_daysold); e_hrsold = (e_daysold - daysold) * 24; hrsold = Math.floor(e_hrsold); e_minsold = (e_hrsold - hrsold) * 60; minsold = Math.floor((e_hrsold - hrsold) * 60); seconds = Math.floor((e_minsold - minsold) * 60); document.getElementById(\u0026#39;span_show_age\u0026#39;).innerHTML = uptime_1 + daysold + uptime_2 + hrsold + uptime_3 + minsold + uptime_4 + seconds + uptime_5; } show_date_time(); \u0026lt;/script\u0026gt; 最终效果 ","date":"2024-04-20T00:00:00Z","permalink":"https://farb.github.io/p/hugo_stack_show_age/","title":"Hugo+Stack主题显示博客运行时间"},{"content":"参考文章 https://stack.jimmycai.com/config/header-footer\nhttps://stack.jimmycai.com/config/footer\numami\nVercount官网\n推荐使用Vercount，不推荐使用不蒜子。理由：不蒜子网站太老了，作者没有维护的意思，Vercount官网更现代化，开源，点开看看就知道了。我集成的时候官网才几百的访客。看GitHub提交记录，也就最近3个月刚成立的项目，很年轻，有活力。\n集成Vercount 我使用的是Hugo+Stack主题，根据Stack官方文档，在主题根目录下，新建一个自定义文件layouts\\partials\\footer\\custom.html。\n网站引入vercount的js 然后将Vercount的js添加到该文件中。\n1 \u0026lt;script defer src=\u0026#34;https://cn.vercount.one/js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 网站底部加入统计整个站的信息 根据Stack文档，自定义网站的footer信息。在param.toml文件中的customText加入以下标签。\n1 2 3 4 5 [footer] customText = \u0026#34;\u0026#34;\u0026#34;网站总访客数：\u0026lt;span id=\u0026#39;busuanzi_value_site_uv\u0026#39;\u0026gt;Loading\u0026lt;/span\u0026gt;\u0026lt;br/\u0026gt; 网站总访问量：\u0026lt;span id=\u0026#39;busuanzi_value_site_pv\u0026#39;\u0026gt;Loading\u0026lt;/span\u0026gt; \u0026#34;\u0026#34;\u0026#34; since = 2024 博客页面加入统计当前博客的信息 在博客详情页面layouts\\partials\\article\\components\\footer.html,添加统计博客的访问情况。\n1 2 3 4 5 6 \u0026lt;footer class=\u0026#34;article-footer\u0026#34;\u0026gt; // 略 \u0026lt;section\u0026gt; 页面浏览量\u0026lt;span id=\u0026#34;busuanzi_value_page_pv\u0026#34;\u0026gt;Loading\u0026lt;/span\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/footer\u0026gt; 集成Umami https://umami.is/\nUmami是一个网站分析工具，它可以分析出一个网站的详细访问数据，包括请求PV、UV、国家来源、来源于哪个网站、用户的操作系统、浏览器等等。 注册账号，添加网站成功后，开启共享URL，然后将这个url放到自己的网站即可。 参考这个链接启用。 https://umami.is/docs/enable-share-url\n1 2 3 4 5 6 [footer] customText = \u0026#34;\u0026#34;\u0026#34;网站总访客数：\u0026lt;span id=\u0026#39;busuanzi_value_site_uv\u0026#39; style=\u0026#39;margin-right:50px\u0026#39;\u0026gt;Loading\u0026lt;/span\u0026gt; 网站总访问量：\u0026lt;span id=\u0026#39;busuanzi_value_site_pv\u0026#39; style=\u0026#39;margin-right:50px\u0026#39;\u0026gt;Loading\u0026lt;/span\u0026gt; \u0026lt;a href=\u0026#39;https://eu.umami.is/share/y6kXo4CE3oYHXQ37/farb.github.io\u0026#39; style=\u0026#39;color:blue\u0026#39; target=\u0026#39;_blank\u0026#39;\u0026gt;网站访问详细统计\u0026lt;/a\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;span id=\u0026#39;span_show_age\u0026#39; style=\u0026#39;margin-right:50px\u0026#39;/\u0026gt; \u0026#34;\u0026#34;\u0026#34; 最终效果 Vercount集成效果如下：\nUmami集成效果如下： ","date":"2024-04-20T00:00:00Z","permalink":"https://farb.github.io/p/hugo_stack_vercount/","title":"Hugo+Stack主题集成Vercount统计网站访问信息"},{"content":"参考文章 https://shitao5.org/posts/hugo-stack/\nhttps://stack.jimmycai.com/config/header-footer\n时间格式修改 在 param.toml文件中修改格式如下：\n1 2 3 [dateFormat] published = \u0026#34;2006-01-02\u0026#34; # 发布日期格式 lastUpdated = \u0026#34;2006-01-02 15:04:05\u0026#34; # 最后修改时间格式，一定要对应go的日期格式 位置修改 参考官方文档，在博客项目下创建一个目录layouts\\partials\\article\\components，一定要和stack主题的路径对应上，思想就是hugo生成静态页面时，使用自定义的页面替换stack主题的页面。\ndetails.html页面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 \u0026lt;div class=\u0026#34;article-details\u0026#34;\u0026gt; // 略... \u0026lt;footer class=\u0026#34;article-time\u0026#34;\u0026gt; // 发布日期代码块 {{ if $showDate }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;date\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Date.Format (or .Site.Params.dateFormat.published \u0026#34;Jan 02, 2006\u0026#34;) -}} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} // 阅读时间代码块 {{ if $showReadingTime }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--reading\u0026#34;\u0026gt; {{ T \u0026#34;article.readingTime\u0026#34; .ReadingTime }} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} // 剪切到这里，并修改标签和上面的代码块一致 {{ if ne .Lastmod .Date }} \u0026lt;div class=\u0026#34;article-lastmod\u0026#34;\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time\u0026gt; {{ T \u0026#34;article.lastUpdatedOn\u0026#34; }} {{ .Lastmod.Format ( or .Site.Params.dateFormat.lastUpdated \u0026#34;Jan 02, 2006 15:04 MST\u0026#34; ) }} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{- end -}} \u0026lt;/footer\u0026gt; {{ end }} // 略... \u0026lt;/div\u0026gt; footer.html页面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;footer class=\u0026#34;article-footer\u0026#34;\u0026gt; // 略... // 这一块是默认的最后更新时间代码块，将这块代码剪切到details.html的正确位置 {{- if ne .Lastmod .Date -}} \u0026lt;section class=\u0026#34;article-lastmod\u0026#34;\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;span\u0026gt; {{ T \u0026#34;article.lastUpdatedOn\u0026#34; }} {{ .Lastmod.Format ( or .Site.Params.dateFormat.lastUpdated \u0026#34;Jan 02, 2006 15:04 MST\u0026#34; ) }} \u0026lt;/span\u0026gt; \u0026lt;/section\u0026gt; {{- end -}} \u0026lt;/footer\u0026gt; ","date":"2024-04-19T00:00:00Z","permalink":"https://farb.github.io/p/hugo_stack_lastmod/","title":"Hugo+Stack主题修改最后更新时间位置和时间格式"},{"content":"ArkTs自定义弹框 效果图：\n难点主要在于Dialog内部的自定义内容布局。涉及Stack布局及Stack嵌套、Body中使用了Scroll，最主要的是Scroll中的Column中使用了padding，给Header和Footer保留空间的高度。\n此外还涉及到父子组件双向通信使用@State、@ObjectLink和@Observed， 涉及父孙组件双向通信使用@Provide和@Consume。\n一个小技巧：通过在子组件中定义closeDialog?:()=\u0026gt;void,在子组件中关闭父组件中定义的dialog实例。\n实现代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 // 一个内容可以滚动的单选列表 @Entry @Component struct CustomDialogPage { @Provide selectedStudent: Student = new Student() dialogController: CustomDialogController = new CustomDialogController({ builder: MyCustomDialog({ cancel: this.onCancel, confirm: this.onConfirm }), alignment: DialogAlignment.Bottom, offset: { dy: 0, dx: 0 }, // 弹窗相对alignment所在位置的偏移量，即设置弹框相对于底部向上偏移10个vp autoCancel: true, // 点击弹框外的地方自动关闭 customStyle: true // 弹窗容器样式是否自定义。默认值：false，弹窗容器的宽度根据栅格系统自适应，不跟随子节点；高度自适应子节点，最大为窗口高度的90%；圆角为24vp }) onCancel() { // 注入取消钩子 console.log(\u0026#39;onCancel\u0026#39;) } onConfirm() { // 注入确定钩子 console.log(\u0026#39;您点击了确定\u0026#39;) } build() { Column() { Button(\u0026#39;显示自定义弹窗\u0026#39;) .onClick(() =\u0026gt; { this.dialogController.open() }) Text(\u0026#39;子组件当前选中的学生是：\u0026#39; + this.selectedStudent.name) .fontColor(Color.Red) } .margin(10) .width(\u0026#39;100%\u0026#39;) } } /** * 自定义弹窗组件 */ @CustomDialog struct MyCustomDialog { @State students: Student[] = [] controller: CustomDialogController cancel: () =\u0026gt; void confirm: () =\u0026gt; void aboutToAppear() { this.students = this.loadData() } loadData(): Array\u0026lt;Student\u0026gt; { // 加一个英文字符串，模拟器和预览器中不支持中文搜索 let names: string[] = [\u0026#39;Farb\u0026#39;, \u0026#39;小明\u0026#39;, \u0026#39;小红\u0026#39;, \u0026#39;小刚\u0026#39;, \u0026#39;小美\u0026#39;, \u0026#39;小杜\u0026#39;, \u0026#39;小帅\u0026#39;, \u0026#39;小李\u0026#39;, \u0026#39;小王\u0026#39;, \u0026#39;小刘\u0026#39;, \u0026#39;小杨\u0026#39;, \u0026#39;小宋\u0026#39;] const data: Student[] = [] let i: number for (i = 0; i \u0026lt; names.length; i++) { data.push(new Student(i + 1, names[i])) } return data } build() { Stack({ alignContent: Alignment.Bottom }) { Stack({ alignContent: Alignment.Top }) { this.Header() this.Body() }.height(\u0026#39;100%\u0026#39;) // 保证内嵌的Stack高度也铺满整个容器，防止搜索时容器变小 .backgroundColor(Color.White) this.Footer() } .height(\u0026#39;60%\u0026#39;) // 弹框最占屏幕的60%高度 } /** * 显示头部信息：包括标题和搜索框 */ @Builder Header() { Column() { Text(\u0026#39;请选择一个学生\u0026#39;).fontSize(20).margin({ top: 10, bottom: 10 }) TextInput({ placeholder: \u0026#39;请输入学生姓名进行搜索\u0026#39; }) .placeholderColor(\u0026#39;#ccc\u0026#39;) .onChange(value =\u0026gt; { if (value) { this.students = this.loadData().filter(item =\u0026gt; item.name.toLowerCase().indexOf(value.toLowerCase()) \u0026gt;= 0) } else { this.students = this.loadData() } }) }.height(100) .padding(10) .zIndex(10) // 让Header位于最上面 .backgroundColor(Color.White) } /** * 显示主体列表 */ @Builder Body() { Scroll() { Column() { ForEach(this.students, (item: Student) =\u0026gt; { StudentCard({ student: item, closeDialogFunc: () =\u0026gt; { this.controller.close() // 关闭父组件的弹框 } }) }) } .padding({ // 这里要分别留出header和footer的高度 bottom: 50, top: 100 }) } .scrollBar(BarState.Off) } /** * 显示底部按钮 */ @Builder Footer() { Button(\u0026#39;取消\u0026#39;) .width(\u0026#39;100%\u0026#39;) .height(50) .fontSize(18) .fontWeight(FontWeight.Bold) .fontColor(\u0026#39;#3CBEF5\u0026#39;) .backgroundColor(Color.White) .type(ButtonType.Normal) .onClick(() =\u0026gt; { this.controller.close() this.cancel(); }) } } /** * 封装每一行数据 */ @Component struct StudentCard { @ObjectLink student: Student @Consume selectedStudent: Student // 关闭父组件的弹框函数 closeDialogFunc?: () =\u0026gt; void build() { Row() { Text(this.student.name) // 这里可根据需要调整布局，当前默认让student.name占据除了单选按钮的剩余所有空间 .layoutWeight(1) Radio({ value: \u0026#39;\u0026#39;, group: \u0026#39;default\u0026#39; }) .checked(this.student.isChecked) .onChange(isChecked =\u0026gt; { // 每个单选按钮状态的变化都要同步到student属性isChecked上 this.student.isChecked = isChecked if (isChecked) { this.closeDialog() } }) } .border({ width: { bottom: 1, }, color: \u0026#39;#ddd\u0026#39; }) .padding(10) .justifyContent(FlexAlign.Center) .onClick(() =\u0026gt; { this.student.isChecked = true this.closeDialog() }) .width(\u0026#39;100%\u0026#39;) } closeDialog() { if (this.closeDialogFunc) { this.selectedStudent = this.student this.closeDialogFunc() } } } @Observed class Student { id: number name: string isChecked: boolean constructor(id?: number, name: string = \u0026#39;\u0026#39;, isChecked: boolean = false) { this.id = id this.name = name this.isChecked = isChecked } } ","date":"2024-04-13T23:00:00Z","permalink":"https://farb.github.io/p/arkts-customdialog/","title":"鸿蒙界面开发--自定义弹窗内置可滚动的单选列表"},{"content":"实验经历 在网上看了很多方案，最终选择了utterance，因为utterance 简单、快速、免费、开源、不需要自定义域名，这就够了。\n了解了静态博客的评论系统基本都是依赖一个动态的第三方后端系统，因为涉及到保存用户评论数据。\n我梳理了下，主要有这么几个概念：\n云服务提供方： 提供最终对博客页面暴露的接口，在你的静态博客中嵌入一段JavaScript代码就可以显示评论系统。 博客系统提供方：负责开发评论对话框的人（一般都是nodejs开发），主要就是评论的样式不同，可以以不同的社交方式登录。 数据库提供方：最终的评论内容要保存到哪里。 比较流行的云服务提供方包括：Vercel、Netlify 等等，当然还有国内的云服务提供商，基本都收费，也可以自己部署，说白了，就是部署一个nodejs服务对外提供接口。\n比较流行的博客系统提供方包括：Waline、Twikoo 等等\n比较流行的免费的数据库提供方包括：LeanCloud,Mongodb 等等\nLeanCloud和Mongodb都可以免费部署好服务，Waline和Vercel文档也都很友好，一看就知道怎么部署。我也在Vercel上部署成功了，但是最后发现部署的应用打不开，网上的解决办法是使用自己的域名就可以解决问题，但考虑到国内申请域名还要备案，免费且不用备案的域名Freenom半天打不开，于是就不考虑了。最终选择了utterance\nutterance，英文意思是言论，说话。它是Github市场的一个应用，可以直接安装，然后关联自己的一个公开仓库即可，后面评论的内容都会保存到这个仓库的issue里面。 对比上面的3个概念，你可以理解为Github的东家就是这三个提供方。只不过，utterance的开发者将上面的三个概念对应的服务给打包好了，方便博主直接使用。\nutterance官方文档\nHugo Stack中如何配置 找到配置文件： config_default\\params.toml 修改评论系统的provider以及[comments.utterances]节点下的repo为你自己的仓库名称。代码如下： 1 2 3 4 5 6 7 8 9 ## Comments [comments] enabled = true provider = \u0026#34;utterances\u0026#34; ## 修改点 [comments.utterances] repo = \u0026#34;farb/blogComment\u0026#34; ## 修改点 issueTerm = \u0026#34;pathname\u0026#34; label = \u0026#34; 最后，看下我的效果吧\n可以看到这个评论最终保存到了 farb/blogComment 这个仓库下面的issue。 每篇帖子都会开一个issue，issue的名字就是博客的slug-name(路径名)，所有的评论都在这个issue下面。 ","date":"2024-04-13T00:00:00Z","permalink":"https://farb.github.io/p/hugo_stack_utterance/","title":"Hugo+Stack主题快速集成免费的评论系统utterance"},{"content":"界面效果 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @Component @Entry struct JdLogin { build() { Column() { Row() { Image($r(\u0026#39;app.media.jd_cancel\u0026#39;)) .width(20) Text(\u0026#39;帮助\u0026#39;).fontSize(16) }.width(\u0026#39;100%\u0026#39;) .justifyContent(FlexAlign.SpaceBetween) Image($r(\u0026#39;app.media.jd_logo\u0026#39;)) .width(250) Row() { Text(\u0026#39;国家/地址\u0026#39;).fontColor(\u0026#39;#666\u0026#39;).layoutWeight(1) Text(\u0026#39;中国(+86)\u0026#39;).fontColor(\u0026#39;#666\u0026#39;) Image($r(\u0026#39;app.media.jd_right\u0026#39;)).width(20).fillColor(\u0026#39;#666\u0026#39;) } .width(\u0026#39;100%\u0026#39;) .height(40) .backgroundColor(\u0026#39;#fff\u0026#39;) .borderRadius(20) .padding({ left: 15, right: 10 }) TextInput({ placeholder: \u0026#39;请输入手机号\u0026#39; }) .placeholderColor(\u0026#39;#666\u0026#39;) .height(40) .borderRadius(20) .backgroundColor(\u0026#39;#fff\u0026#39;) .margin({ top: 20 }) Row() { Checkbox().width(10).margin({ top: 7, right: 3 }) Text() { Span(\u0026#39;我已经阅读并同意\u0026#39;) Span(\u0026#39;《京东隐私政策》\u0026#39;).fontColor(\u0026#39;#26d\u0026#39;).fontSize(12) Span(\u0026#39;《京东用户服务协议》\u0026#39;).fontColor(\u0026#39;#26d\u0026#39;).fontSize(12) Span(\u0026#39;未注册的手机号将自动创建京东账号\u0026#39;) }.fontSize(12) .fontColor(\u0026#39;#666\u0026#39;) .lineHeight(20) }.alignItems(VerticalAlign.Top) .margin({ top: 20 }) Button(\u0026#39;登录\u0026#39;) .width(\u0026#39;100%\u0026#39;) .backgroundColor(\u0026#39;#bf2838\u0026#39;) .margin({ top: 25 }) Row() { Text(\u0026#39;新用户注册\u0026#39;).fontSize(14).fontColor(\u0026#39;#666\u0026#39;) Text(\u0026#39;账户密码登录\u0026#39;).fontSize(14).fontColor(\u0026#39;#666\u0026#39;) Text(\u0026#39;无法登录\u0026#39;).fontSize(14).fontColor(\u0026#39;#666\u0026#39;) }.width(\u0026#39;100%\u0026#39;) .margin({ top: 15 }) .justifyContent(FlexAlign.SpaceEvenly) Blank() Text(\u0026#39;其他登录方式\u0026#39;) .fontColor(\u0026#39;#666\u0026#39;) .fontSize(14) .lineHeight(22) .margin({ bottom: 28 }) Row() { Image($r(\u0026#39;app.media.jd_huawei\u0026#39;)).width(34) Image($r(\u0026#39;app.media.jd_weibo\u0026#39;)).width(34).fillColor(Color.Red) Image($r(\u0026#39;app.media.jd_wechat\u0026#39;)).width(34).fillColor(Color.Green) Image($r(\u0026#39;app.media.jd_QQ\u0026#39;)).width(34).fillColor(\u0026#39;#539feb\u0026#39;) }.width(\u0026#39;100%\u0026#39;) .margin({ bottom: 30 }) .justifyContent(FlexAlign.SpaceEvenly) }.height(\u0026#39;100%\u0026#39;) .padding(20) .backgroundImage($r(\u0026#39;app.media.jd_login_bg\u0026#39;)) .backgroundImageSize(ImageSize.Cover) } } ","date":"2024-04-10T23:00:00Z","permalink":"https://farb.github.io/p/harmony-jdlogin/","title":"鸿蒙界面开发--京东登录页面"},{"content":"界面效果 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 @Entry @Component struct BliBliVideoCardPage { @State message: string = \u0026#39;Hello World\u0026#39; build() { Column() { Column() { Stack({ alignContent: Alignment.Bottom }) { Image($r(\u0026#39;app.media.bz_img\u0026#39;)) .width(\u0026#39;100%\u0026#39;) .borderRadius({ topLeft: 10, topRight: 10 }) Row() { Row({ space: 5 }) { Image($r(\u0026#39;app.media.bz_play\u0026#39;)) .width(14) .fillColor(Color.White) Text(\u0026#39;288万\u0026#39;).fontColor(Color.White) } .margin({ right: 20 }) Row({ space: 5 }) { Image($r(\u0026#39;app.media.bz_msg\u0026#39;)) .width(14) .fillColor(Color.White) Text(\u0026#39;8655\u0026#39;).fontColor(Color.White) } Blank() Text(\u0026#39;4:33\u0026#39;).fontColor(Color.White) } .padding({ left: 10, right: 10 }) .height(24) .width(\u0026#39;100%\u0026#39;) } Column() { Text(\u0026#39;【凤凰传奇新歌】欢迎来到国风统治区：唢呐一响神曲《铁衣流派推广曲》【凤凰传奇新歌】欢迎来到国风统治区：唢呐一响神曲《铁衣流派推广曲》\u0026#39;) .textOverflow({ overflow: TextOverflow.Ellipsis }) .maxLines(2) .fontSize(16) .lineHeight(26) Row() { Text(\u0026#39;19万点赞\u0026#39;) .fontColor(\u0026#39;#e5a986\u0026#39;) .fontWeight(FontWeight.Bold) .backgroundColor(\u0026#39;#fbefed\u0026#39;) .padding(5) .borderRadius(5) Image($r(\u0026#39;app.media.bz_more\u0026#39;)).width(16) } .padding(10) .width(\u0026#39;100%\u0026#39;) .backgroundColor(Color.White) .justifyContent(FlexAlign.SpaceBetween) } } .margin(10) } .width(\u0026#39;100%\u0026#39;) .height(\u0026#39;100%\u0026#39;) } } ","date":"2024-04-10T00:00:00Z","permalink":"https://farb.github.io/p/harmony-bilibili/","title":"鸿蒙界面开发--B站视频卡片"},{"content":"界面效果 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 @Entry @Component struct AliPayIndexPage { build() { Stack({ alignContent: Alignment.Bottom }) { Stack({ alignContent: Alignment.Top }) { // 顶部搜索栏 this.TopSearchBar() // 主体 this.Body() } .width(\u0026#39;100%\u0026#39;) .height(\u0026#39;100%\u0026#39;) .backgroundColor(\u0026#39;#5b73e1\u0026#39;) // 底部导航栏 this.BottomNavigation() } .height(\u0026#39;100%\u0026#39;) .width(\u0026#39;100%\u0026#39;) .backgroundColor(Color.Pink) } @Builder TopSearchBar() { Row() { Column() { Text(\u0026#39;北京\u0026#39;) .fontSize(14) .fontColor(Color.White) Text(\u0026#39;晴2°\u0026#39;) .fontSize(12) .fontColor(Color.White) Image($r(\u0026#39;app.media.zfb_head_down\u0026#39;)) .fillColor(Color.White) .width(14) .position({ x: 35 }) } Row() { Image($r(\u0026#39;app.media.zfb_head_search\u0026#39;)) .width(20) .fillColor(\u0026#39;#666\u0026#39;) Text(\u0026#39;北京交通一卡通\u0026#39;) .margin({ left: 1 }) .layoutWeight(1) Text(\u0026#39;搜索\u0026#39;) .width(55) .fontColor(\u0026#39;#5b73d1\u0026#39;) .fontSize(14) .fontWeight(FontWeight.Bold) .textAlign(TextAlign.Center) .border({ width: { left: 1, }, color: \u0026#39;#ccc\u0026#39; }) } .borderRadius(5) .height(32) .padding({ left: 5 }) .margin({ left: 32, right: 12 }) .backgroundColor(Color.White) .layoutWeight(1) Image($r(\u0026#39;app.media.zfb_head_plus\u0026#39;)) .width(25) .fillColor(Color.White) } .width(\u0026#39;100%\u0026#39;) .padding({ left: 10, right: 10 }) .height(60) .backgroundColor(\u0026#39;#5b73e1\u0026#39;) .zIndex(10) } @Builder Body() { Scroll() { Column() { this.QuickNavMenu() this.CardArea() this.ProductArea() } .width(\u0026#39;100%\u0026#39;) .padding({ top: 60, bottom: 60 }) } .scrollBar(BarState.Off) } @Builder QuickNavMenu() { Row() { Column() { Image($r(\u0026#39;app.media.zfb_top_scan\u0026#39;)) .width(36) .fillColor(Color.White) Text(\u0026#39;扫一扫\u0026#39;).quickNavTextStyleExtend() } Column() { Image($r(\u0026#39;app.media.zfb_top_pay\u0026#39;)) .width(36) .fillColor(Color.White) Text(\u0026#39;收付款\u0026#39;).quickNavTextStyleExtend() } Column() { Image($r(\u0026#39;app.media.zfb_top_travel\u0026#39;)) .width(36) .fillColor(Color.White) Text(\u0026#39;出行\u0026#39;).quickNavTextStyleExtend() } Column() { Image($r(\u0026#39;app.media.zfb_top_card\u0026#39;)) .width(36) .fillColor(Color.White) Text(\u0026#39;卡包\u0026#39;).quickNavTextStyleExtend() } } .justifyContent(FlexAlign.SpaceAround) .width(\u0026#39;100%\u0026#39;) } @Builder CardArea() { Column({ space: 10 }) { Row() { Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav1\u0026#39;)) .width(30) Text(\u0026#39;滴滴出行\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav2\u0026#39;)) .width(30) Text(\u0026#39;生活缴费\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav3\u0026#39;)) .width(30) Text(\u0026#39;股票\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav4\u0026#39;)) .width(30) Text(\u0026#39;蚂蚁森林\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav5\u0026#39;)) .width(30) Text(\u0026#39;手机充值\u0026#39;) .fontSize(12) } } .justifyContent(FlexAlign.SpaceAround) .width(\u0026#39;100%\u0026#39;) Row() { Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav6\u0026#39;)) .width(30) Text(\u0026#39;余额宝\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav7\u0026#39;)) .width(30) Text(\u0026#39;花呗\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav8\u0026#39;)) .width(30) Text(\u0026#39;飞猪旅行\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav9\u0026#39;)) .width(30) Text(\u0026#39;淘票票\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav10\u0026#39;)) .width(30) Text(\u0026#39;饿了么\u0026#39;) .fontSize(12) } } .justifyContent(FlexAlign.SpaceAround) .width(\u0026#39;100%\u0026#39;) Row() { Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav11\u0026#39;)) .width(30) Text(\u0026#39;读书听书\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav12\u0026#39;)) .width(30) Text(\u0026#39;基金\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav13\u0026#39;)) .width(30) Text(\u0026#39;直播广场\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav14\u0026#39;)) .width(30) Text(\u0026#39;医疗健康\u0026#39;) .fontSize(12) } Column({ space: 5 }) { Image($r(\u0026#39;app.media.zfb_nav15_more\u0026#39;)) .width(30) Text(\u0026#39;更多\u0026#39;) .fontSize(12) } } .justifyContent(FlexAlign.SpaceAround) .width(\u0026#39;100%\u0026#39;) }.cardAreaColumnStyleExtend() } @Builder ProductArea(){ Row({space:5}){ Image($r(\u0026#39;app.media.zfb_pro_pic1\u0026#39;)) .layoutWeight(1) Image($r(\u0026#39;app.media.zfb_pro_pic2\u0026#39;)) .layoutWeight(1) Image($r(\u0026#39;app.media.zfb_pro_pic3\u0026#39;)) .layoutWeight(1) } .padding(5) .backgroundColor(Color.White) .width(\u0026#39;100%\u0026#39;) Column(){ Image($r(\u0026#39;app.media.zfb_pro_list1\u0026#39;)) Image($r(\u0026#39;app.media.zfb_pro_list2\u0026#39;)) } } @Builder BottomNavigation() { Row() { Column() { Image($r(\u0026#39;app.media.zfb_tab_home\u0026#39;)) .width(35) } Column() { Image($r(\u0026#39;app.media.zfb_top_pay\u0026#39;)) .inactiveNavigationImage() Text(\u0026#39;理财\u0026#39;).textStyleExtend() } Column() { Image($r(\u0026#39;app.media.zfb_tab_life\u0026#39;)) .inactiveNavigationImage() Text(\u0026#39;生活\u0026#39;).textStyleExtend() } Column() { Image($r(\u0026#39;app.media.zfb_tab_chat\u0026#39;)) .inactiveNavigationImage() Text(\u0026#39;消息\u0026#39;).textStyleExtend() } Column() { Image($r(\u0026#39;app.media.zfb_tab_me\u0026#39;)) .inactiveNavigationImage() Text(\u0026#39;我的\u0026#39;).textStyleExtend() } } .justifyContent(FlexAlign.SpaceAround) .width(\u0026#39;100%\u0026#39;) .height(60) .backgroundColor(Color.White) } } @Extend(Text) function textStyleExtend() { .fontSize(12) .margin({ top: 5 }) } @Extend(Text) function quickNavTextStyleExtend() { .fontSize(14) .fontColor(Color.White) } @Extend(Image) function inactiveNavigationImage() { .width(28) } @Extend(Column) function cardAreaColumnStyleExtend() { .width(\u0026#39;100%\u0026#39;) .backgroundColor(Color.White) .borderRadius({ topLeft: 10, topRight: 10 }) .padding({ top: 5 }) .margin({ top: 10 }) } ","date":"2024-04-10T00:00:00Z","permalink":"https://farb.github.io/p/harmony-alipay/","title":"鸿蒙界面开发--支付宝首页"},{"content":"界面效果 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 @Entry @Component struct MeiTuanCartPage { @State oldPrice: number = 40.4 @State newPrice: number = 20 @State buyCount: number = 1 build() { Column() { Row() { Image($r(\u0026#39;app.media.mt_product1\u0026#39;)) .width(100) .borderRadius(10) Column({ space: 10 }) { Column({ space: 6 }) { Text(\u0026#39;冲销量1000ml缤纷八果水果捞\u0026#39;) .maxLines(2) .textOverflow({ overflow: TextOverflow.Ellipsis }) .fontWeight(FontWeight.Bold) Text(\u0026#39;含一份折扣商品\u0026#39;) } .alignItems(HorizontalAlign.Start) Row() { Row({ space: 10 }) { Text(\u0026#39;￥\u0026#39; + this.newPrice) .fontColor(Color.Red) .fontWeight(FontWeight.Bolder) .fontSize(20) Text(\u0026#39;￥\u0026#39; + this.oldPrice) .fontColor(\u0026#39;#666\u0026#39;) .decoration({ type: TextDecorationType.LineThrough }) } Row() { Text(\u0026#39;-\u0026#39;) .width(20) .textAlign(TextAlign.Center) .fontWeight(FontWeight.Bold) .border({ width: 1, color: \u0026#39;#666\u0026#39;, radius: { topLeft: 5, bottomLeft: 5 } }) .onClick(() =\u0026gt; { if (this.buyCount \u0026gt; 1) { this.buyCount-- } }) Text(this.buyCount.toString()) .width(30) .textAlign(TextAlign.Center) .border({ width: 1, color: \u0026#39;#666\u0026#39; }) Text(\u0026#39;+\u0026#39;) .width(20) .textAlign(TextAlign.Center) .fontWeight(FontWeight.Bold) .border({ width: 1, color: \u0026#39;#666\u0026#39;, radius: { topRight: 5, bottomRight: 5 } }) .onClick(() =\u0026gt; { if (this.buyCount \u0026lt; 100) { this.buyCount++ } }) }.padding({ right: 20 }) } .justifyContent(FlexAlign.SpaceBetween) .width(\u0026#39;100%\u0026#39;) .height(30) } .alignItems(HorizontalAlign.Start) .padding({ left: 10 }) .layoutWeight(1) } .width(\u0026#39;100%\u0026#39;) Row() { Blank() Column({ space: 10 }) { Text() { Span(`已选${this.buyCount}件，合计`) Span(`￥${(this.buyCount * this.newPrice).toFixed(2)}`) .fontColor(Color.Red) } Text(\u0026#39;共减￥\u0026#39; + ((this.oldPrice - this.newPrice) * this.buyCount).toFixed(2)) .fontColor(Color.Red) } .alignItems(HorizontalAlign.End) Button(\u0026#39;结算\u0026#39;) .backgroundColor(\u0026#39;#f5da46\u0026#39;) .fontColor(Color.Black) .fontSize(20) .padding(10) .width(120) .margin({ left: 15 }) } .padding(15) .width(\u0026#39;100%\u0026#39;) } .padding(10) .width(\u0026#39;100%\u0026#39;) .height(\u0026#39;100%\u0026#39;) } @Builder NumberInput() { Row() { Text(\u0026#39;-\u0026#39;) .border({ width: 1, color: \u0026#39;#666\u0026#39;, radius: { topLeft: 5, bottomLeft: 5 } }) .onClick(() =\u0026gt; { this.buyCount-- }) Text(this.buyCount.toString()) Text(\u0026#39;+\u0026#39;) .onClick(() =\u0026gt; { this.buyCount++ }) } .layoutWeight(1) .justifyContent(FlexAlign.SpaceBetween) .margin({ right: 5 }) } } ","date":"2024-04-10T00:00:00Z","permalink":"https://farb.github.io/p/harmony-meituancart/","title":"鸿蒙界面开发--美团购物车"},{"content":"参考文档 Hugo 官方文档\nStack 官方文档\n一开始按照上面两个官方文档搞好了本地环境，本地 http://localhost:1313/可以正常打开访问。但是代码提交到Github之后，并没有效果，显示的readme.md的内容，于是各种查找答案，终于通过下面这个帖子解决了。特此记录。\n参考这个帖子解决了问题\n问题的原因 上面知乎那个帖子也提到了，主要有两点： Source 要选择 Deploy from a branch 注意分支，Git仓库会触发Github Action自动新建一个gh-page的分支，会自动把content文件夹里面的内容编译到一个public文件夹，一个纯前端文件的项目，这个gh-page分支的内容就是public文件夹的内容。 修改上面的两处之后，点击图上方的Visit site 成功看到博客主页。\nGithub同步到Gitee 该指导可以提交一次代码到Github，然后同时同步到Gitee并部署。\nhttps://github.com/marketplace/actions/gitee-pages-action\n","date":"2024-04-09T00:00:00Z","image":"https://farb.github.io/p/hugo_stack/cover_hu_e95a4276bf860a84.jpg","permalink":"https://farb.github.io/p/hugo_stack/","title":"Hugo+Stack主题环境搭建部署到Github遇到的问题记录"}]